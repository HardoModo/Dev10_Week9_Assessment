{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n",
      "C:\\Users\\shirl\\AppData\\Local\\Temp\\ipykernel_34948\\541946.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[name] = X[cols].map(lambda x : x ** p)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>mean radiuspow_2</th>\n",
       "      <th>mean radiuspow_3</th>\n",
       "      <th>mean radiuspow_4</th>\n",
       "      <th>mean radiuspow_5</th>\n",
       "      <th>mean radiuspow_6</th>\n",
       "      <th>mean radiuspow_7</th>\n",
       "      <th>mean radiuspow_8</th>\n",
       "      <th>mean radiuspow_9</th>\n",
       "      <th>mean radiuspow_10</th>\n",
       "      <th>mean radiuspow_11</th>\n",
       "      <th>mean radiuspow_12</th>\n",
       "      <th>mean radiuspow_13</th>\n",
       "      <th>mean radiuspow_14</th>\n",
       "      <th>mean radiuspow_15</th>\n",
       "      <th>mean radiuspow_16</th>\n",
       "      <th>mean radiuspow_17</th>\n",
       "      <th>mean radiuspow_18</th>\n",
       "      <th>mean radiuspow_19</th>\n",
       "      <th>mean radiuspow_20</th>\n",
       "      <th>mean radiuspow_21</th>\n",
       "      <th>mean radiuspow_22</th>\n",
       "      <th>mean radiuspow_23</th>\n",
       "      <th>mean texturepow_2</th>\n",
       "      <th>mean texturepow_3</th>\n",
       "      <th>mean texturepow_4</th>\n",
       "      <th>mean texturepow_5</th>\n",
       "      <th>mean texturepow_6</th>\n",
       "      <th>mean texturepow_7</th>\n",
       "      <th>mean texturepow_8</th>\n",
       "      <th>mean texturepow_9</th>\n",
       "      <th>mean texturepow_10</th>\n",
       "      <th>mean texturepow_11</th>\n",
       "      <th>mean texturepow_12</th>\n",
       "      <th>mean texturepow_13</th>\n",
       "      <th>mean texturepow_14</th>\n",
       "      <th>mean texturepow_15</th>\n",
       "      <th>mean texturepow_16</th>\n",
       "      <th>mean texturepow_17</th>\n",
       "      <th>mean texturepow_18</th>\n",
       "      <th>mean texturepow_19</th>\n",
       "      <th>mean texturepow_20</th>\n",
       "      <th>mean texturepow_21</th>\n",
       "      <th>mean texturepow_22</th>\n",
       "      <th>mean texturepow_23</th>\n",
       "      <th>mean perimeterpow_2</th>\n",
       "      <th>mean perimeterpow_3</th>\n",
       "      <th>mean perimeterpow_4</th>\n",
       "      <th>mean perimeterpow_5</th>\n",
       "      <th>mean perimeterpow_6</th>\n",
       "      <th>mean perimeterpow_7</th>\n",
       "      <th>mean perimeterpow_8</th>\n",
       "      <th>mean perimeterpow_9</th>\n",
       "      <th>mean perimeterpow_10</th>\n",
       "      <th>mean perimeterpow_11</th>\n",
       "      <th>mean perimeterpow_12</th>\n",
       "      <th>mean perimeterpow_13</th>\n",
       "      <th>mean perimeterpow_14</th>\n",
       "      <th>mean perimeterpow_15</th>\n",
       "      <th>mean perimeterpow_16</th>\n",
       "      <th>mean perimeterpow_17</th>\n",
       "      <th>mean perimeterpow_18</th>\n",
       "      <th>mean perimeterpow_19</th>\n",
       "      <th>mean perimeterpow_20</th>\n",
       "      <th>mean perimeterpow_21</th>\n",
       "      <th>mean perimeterpow_22</th>\n",
       "      <th>mean perimeterpow_23</th>\n",
       "      <th>mean areapow_2</th>\n",
       "      <th>mean areapow_3</th>\n",
       "      <th>mean areapow_4</th>\n",
       "      <th>mean areapow_5</th>\n",
       "      <th>mean areapow_6</th>\n",
       "      <th>mean areapow_7</th>\n",
       "      <th>mean areapow_8</th>\n",
       "      <th>mean areapow_9</th>\n",
       "      <th>mean areapow_10</th>\n",
       "      <th>mean areapow_11</th>\n",
       "      <th>mean areapow_12</th>\n",
       "      <th>mean areapow_13</th>\n",
       "      <th>mean areapow_14</th>\n",
       "      <th>mean areapow_15</th>\n",
       "      <th>mean areapow_16</th>\n",
       "      <th>mean areapow_17</th>\n",
       "      <th>mean areapow_18</th>\n",
       "      <th>mean areapow_19</th>\n",
       "      <th>mean areapow_20</th>\n",
       "      <th>mean areapow_21</th>\n",
       "      <th>mean areapow_22</th>\n",
       "      <th>mean areapow_23</th>\n",
       "      <th>mean smoothnesspow_2</th>\n",
       "      <th>mean smoothnesspow_3</th>\n",
       "      <th>mean smoothnesspow_4</th>\n",
       "      <th>mean smoothnesspow_5</th>\n",
       "      <th>mean smoothnesspow_6</th>\n",
       "      <th>mean smoothnesspow_7</th>\n",
       "      <th>mean smoothnesspow_8</th>\n",
       "      <th>mean smoothnesspow_9</th>\n",
       "      <th>mean smoothnesspow_10</th>\n",
       "      <th>mean smoothnesspow_11</th>\n",
       "      <th>mean smoothnesspow_12</th>\n",
       "      <th>mean smoothnesspow_13</th>\n",
       "      <th>mean smoothnesspow_14</th>\n",
       "      <th>mean smoothnesspow_15</th>\n",
       "      <th>mean smoothnesspow_16</th>\n",
       "      <th>mean smoothnesspow_17</th>\n",
       "      <th>mean smoothnesspow_18</th>\n",
       "      <th>mean smoothnesspow_19</th>\n",
       "      <th>mean smoothnesspow_20</th>\n",
       "      <th>mean smoothnesspow_21</th>\n",
       "      <th>mean smoothnesspow_22</th>\n",
       "      <th>mean smoothnesspow_23</th>\n",
       "      <th>mean compactnesspow_2</th>\n",
       "      <th>mean compactnesspow_3</th>\n",
       "      <th>mean compactnesspow_4</th>\n",
       "      <th>mean compactnesspow_5</th>\n",
       "      <th>mean compactnesspow_6</th>\n",
       "      <th>mean compactnesspow_7</th>\n",
       "      <th>mean compactnesspow_8</th>\n",
       "      <th>mean compactnesspow_9</th>\n",
       "      <th>mean compactnesspow_10</th>\n",
       "      <th>mean compactnesspow_11</th>\n",
       "      <th>mean compactnesspow_12</th>\n",
       "      <th>mean compactnesspow_13</th>\n",
       "      <th>mean compactnesspow_14</th>\n",
       "      <th>mean compactnesspow_15</th>\n",
       "      <th>mean compactnesspow_16</th>\n",
       "      <th>mean compactnesspow_17</th>\n",
       "      <th>mean compactnesspow_18</th>\n",
       "      <th>mean compactnesspow_19</th>\n",
       "      <th>mean compactnesspow_20</th>\n",
       "      <th>mean compactnesspow_21</th>\n",
       "      <th>mean compactnesspow_22</th>\n",
       "      <th>mean compactnesspow_23</th>\n",
       "      <th>mean concavitypow_2</th>\n",
       "      <th>mean concavitypow_3</th>\n",
       "      <th>mean concavitypow_4</th>\n",
       "      <th>mean concavitypow_5</th>\n",
       "      <th>mean concavitypow_6</th>\n",
       "      <th>mean concavitypow_7</th>\n",
       "      <th>mean concavitypow_8</th>\n",
       "      <th>mean concavitypow_9</th>\n",
       "      <th>mean concavitypow_10</th>\n",
       "      <th>mean concavitypow_11</th>\n",
       "      <th>mean concavitypow_12</th>\n",
       "      <th>mean concavitypow_13</th>\n",
       "      <th>mean concavitypow_14</th>\n",
       "      <th>mean concavitypow_15</th>\n",
       "      <th>mean concavitypow_16</th>\n",
       "      <th>mean concavitypow_17</th>\n",
       "      <th>mean concavitypow_18</th>\n",
       "      <th>mean concavitypow_19</th>\n",
       "      <th>mean concavitypow_20</th>\n",
       "      <th>mean concavitypow_21</th>\n",
       "      <th>mean concavitypow_22</th>\n",
       "      <th>mean concavitypow_23</th>\n",
       "      <th>mean concave pointspow_2</th>\n",
       "      <th>mean concave pointspow_3</th>\n",
       "      <th>mean concave pointspow_4</th>\n",
       "      <th>mean concave pointspow_5</th>\n",
       "      <th>mean concave pointspow_6</th>\n",
       "      <th>mean concave pointspow_7</th>\n",
       "      <th>mean concave pointspow_8</th>\n",
       "      <th>mean concave pointspow_9</th>\n",
       "      <th>mean concave pointspow_10</th>\n",
       "      <th>mean concave pointspow_11</th>\n",
       "      <th>mean concave pointspow_12</th>\n",
       "      <th>mean concave pointspow_13</th>\n",
       "      <th>mean concave pointspow_14</th>\n",
       "      <th>mean concave pointspow_15</th>\n",
       "      <th>mean concave pointspow_16</th>\n",
       "      <th>mean concave pointspow_17</th>\n",
       "      <th>mean concave pointspow_18</th>\n",
       "      <th>mean concave pointspow_19</th>\n",
       "      <th>mean concave pointspow_20</th>\n",
       "      <th>mean concave pointspow_21</th>\n",
       "      <th>mean concave pointspow_22</th>\n",
       "      <th>mean concave pointspow_23</th>\n",
       "      <th>mean symmetrypow_2</th>\n",
       "      <th>mean symmetrypow_3</th>\n",
       "      <th>mean symmetrypow_4</th>\n",
       "      <th>mean symmetrypow_5</th>\n",
       "      <th>mean symmetrypow_6</th>\n",
       "      <th>mean symmetrypow_7</th>\n",
       "      <th>mean symmetrypow_8</th>\n",
       "      <th>mean symmetrypow_9</th>\n",
       "      <th>mean symmetrypow_10</th>\n",
       "      <th>mean symmetrypow_11</th>\n",
       "      <th>mean symmetrypow_12</th>\n",
       "      <th>mean symmetrypow_13</th>\n",
       "      <th>mean symmetrypow_14</th>\n",
       "      <th>mean symmetrypow_15</th>\n",
       "      <th>mean symmetrypow_16</th>\n",
       "      <th>mean symmetrypow_17</th>\n",
       "      <th>mean symmetrypow_18</th>\n",
       "      <th>mean symmetrypow_19</th>\n",
       "      <th>mean symmetrypow_20</th>\n",
       "      <th>mean symmetrypow_21</th>\n",
       "      <th>mean symmetrypow_22</th>\n",
       "      <th>mean symmetrypow_23</th>\n",
       "      <th>mean fractal dimensionpow_2</th>\n",
       "      <th>mean fractal dimensionpow_3</th>\n",
       "      <th>mean fractal dimensionpow_4</th>\n",
       "      <th>mean fractal dimensionpow_5</th>\n",
       "      <th>mean fractal dimensionpow_6</th>\n",
       "      <th>mean fractal dimensionpow_7</th>\n",
       "      <th>mean fractal dimensionpow_8</th>\n",
       "      <th>mean fractal dimensionpow_9</th>\n",
       "      <th>mean fractal dimensionpow_10</th>\n",
       "      <th>mean fractal dimensionpow_11</th>\n",
       "      <th>mean fractal dimensionpow_12</th>\n",
       "      <th>mean fractal dimensionpow_13</th>\n",
       "      <th>mean fractal dimensionpow_14</th>\n",
       "      <th>mean fractal dimensionpow_15</th>\n",
       "      <th>mean fractal dimensionpow_16</th>\n",
       "      <th>mean fractal dimensionpow_17</th>\n",
       "      <th>mean fractal dimensionpow_18</th>\n",
       "      <th>mean fractal dimensionpow_19</th>\n",
       "      <th>mean fractal dimensionpow_20</th>\n",
       "      <th>mean fractal dimensionpow_21</th>\n",
       "      <th>mean fractal dimensionpow_22</th>\n",
       "      <th>mean fractal dimensionpow_23</th>\n",
       "      <th>radius errorpow_2</th>\n",
       "      <th>radius errorpow_3</th>\n",
       "      <th>radius errorpow_4</th>\n",
       "      <th>radius errorpow_5</th>\n",
       "      <th>radius errorpow_6</th>\n",
       "      <th>radius errorpow_7</th>\n",
       "      <th>radius errorpow_8</th>\n",
       "      <th>radius errorpow_9</th>\n",
       "      <th>radius errorpow_10</th>\n",
       "      <th>radius errorpow_11</th>\n",
       "      <th>radius errorpow_12</th>\n",
       "      <th>radius errorpow_13</th>\n",
       "      <th>radius errorpow_14</th>\n",
       "      <th>radius errorpow_15</th>\n",
       "      <th>radius errorpow_16</th>\n",
       "      <th>radius errorpow_17</th>\n",
       "      <th>radius errorpow_18</th>\n",
       "      <th>radius errorpow_19</th>\n",
       "      <th>radius errorpow_20</th>\n",
       "      <th>radius errorpow_21</th>\n",
       "      <th>radius errorpow_22</th>\n",
       "      <th>radius errorpow_23</th>\n",
       "      <th>texture errorpow_2</th>\n",
       "      <th>texture errorpow_3</th>\n",
       "      <th>texture errorpow_4</th>\n",
       "      <th>texture errorpow_5</th>\n",
       "      <th>texture errorpow_6</th>\n",
       "      <th>texture errorpow_7</th>\n",
       "      <th>texture errorpow_8</th>\n",
       "      <th>texture errorpow_9</th>\n",
       "      <th>texture errorpow_10</th>\n",
       "      <th>texture errorpow_11</th>\n",
       "      <th>texture errorpow_12</th>\n",
       "      <th>texture errorpow_13</th>\n",
       "      <th>texture errorpow_14</th>\n",
       "      <th>texture errorpow_15</th>\n",
       "      <th>texture errorpow_16</th>\n",
       "      <th>texture errorpow_17</th>\n",
       "      <th>texture errorpow_18</th>\n",
       "      <th>texture errorpow_19</th>\n",
       "      <th>texture errorpow_20</th>\n",
       "      <th>texture errorpow_21</th>\n",
       "      <th>texture errorpow_22</th>\n",
       "      <th>texture errorpow_23</th>\n",
       "      <th>perimeter errorpow_2</th>\n",
       "      <th>perimeter errorpow_3</th>\n",
       "      <th>perimeter errorpow_4</th>\n",
       "      <th>perimeter errorpow_5</th>\n",
       "      <th>perimeter errorpow_6</th>\n",
       "      <th>perimeter errorpow_7</th>\n",
       "      <th>perimeter errorpow_8</th>\n",
       "      <th>perimeter errorpow_9</th>\n",
       "      <th>perimeter errorpow_10</th>\n",
       "      <th>perimeter errorpow_11</th>\n",
       "      <th>perimeter errorpow_12</th>\n",
       "      <th>perimeter errorpow_13</th>\n",
       "      <th>perimeter errorpow_14</th>\n",
       "      <th>perimeter errorpow_15</th>\n",
       "      <th>perimeter errorpow_16</th>\n",
       "      <th>perimeter errorpow_17</th>\n",
       "      <th>perimeter errorpow_18</th>\n",
       "      <th>perimeter errorpow_19</th>\n",
       "      <th>perimeter errorpow_20</th>\n",
       "      <th>perimeter errorpow_21</th>\n",
       "      <th>perimeter errorpow_22</th>\n",
       "      <th>perimeter errorpow_23</th>\n",
       "      <th>area errorpow_2</th>\n",
       "      <th>area errorpow_3</th>\n",
       "      <th>area errorpow_4</th>\n",
       "      <th>area errorpow_5</th>\n",
       "      <th>area errorpow_6</th>\n",
       "      <th>area errorpow_7</th>\n",
       "      <th>area errorpow_8</th>\n",
       "      <th>area errorpow_9</th>\n",
       "      <th>area errorpow_10</th>\n",
       "      <th>area errorpow_11</th>\n",
       "      <th>area errorpow_12</th>\n",
       "      <th>area errorpow_13</th>\n",
       "      <th>area errorpow_14</th>\n",
       "      <th>area errorpow_15</th>\n",
       "      <th>area errorpow_16</th>\n",
       "      <th>area errorpow_17</th>\n",
       "      <th>area errorpow_18</th>\n",
       "      <th>area errorpow_19</th>\n",
       "      <th>area errorpow_20</th>\n",
       "      <th>area errorpow_21</th>\n",
       "      <th>area errorpow_22</th>\n",
       "      <th>area errorpow_23</th>\n",
       "      <th>smoothness errorpow_2</th>\n",
       "      <th>smoothness errorpow_3</th>\n",
       "      <th>smoothness errorpow_4</th>\n",
       "      <th>smoothness errorpow_5</th>\n",
       "      <th>smoothness errorpow_6</th>\n",
       "      <th>smoothness errorpow_7</th>\n",
       "      <th>smoothness errorpow_8</th>\n",
       "      <th>smoothness errorpow_9</th>\n",
       "      <th>smoothness errorpow_10</th>\n",
       "      <th>smoothness errorpow_11</th>\n",
       "      <th>smoothness errorpow_12</th>\n",
       "      <th>smoothness errorpow_13</th>\n",
       "      <th>smoothness errorpow_14</th>\n",
       "      <th>smoothness errorpow_15</th>\n",
       "      <th>smoothness errorpow_16</th>\n",
       "      <th>smoothness errorpow_17</th>\n",
       "      <th>smoothness errorpow_18</th>\n",
       "      <th>smoothness errorpow_19</th>\n",
       "      <th>smoothness errorpow_20</th>\n",
       "      <th>smoothness errorpow_21</th>\n",
       "      <th>smoothness errorpow_22</th>\n",
       "      <th>smoothness errorpow_23</th>\n",
       "      <th>compactness errorpow_2</th>\n",
       "      <th>compactness errorpow_3</th>\n",
       "      <th>compactness errorpow_4</th>\n",
       "      <th>compactness errorpow_5</th>\n",
       "      <th>compactness errorpow_6</th>\n",
       "      <th>compactness errorpow_7</th>\n",
       "      <th>compactness errorpow_8</th>\n",
       "      <th>compactness errorpow_9</th>\n",
       "      <th>compactness errorpow_10</th>\n",
       "      <th>compactness errorpow_11</th>\n",
       "      <th>compactness errorpow_12</th>\n",
       "      <th>compactness errorpow_13</th>\n",
       "      <th>compactness errorpow_14</th>\n",
       "      <th>compactness errorpow_15</th>\n",
       "      <th>compactness errorpow_16</th>\n",
       "      <th>compactness errorpow_17</th>\n",
       "      <th>compactness errorpow_18</th>\n",
       "      <th>compactness errorpow_19</th>\n",
       "      <th>compactness errorpow_20</th>\n",
       "      <th>compactness errorpow_21</th>\n",
       "      <th>compactness errorpow_22</th>\n",
       "      <th>compactness errorpow_23</th>\n",
       "      <th>concavity errorpow_2</th>\n",
       "      <th>concavity errorpow_3</th>\n",
       "      <th>concavity errorpow_4</th>\n",
       "      <th>concavity errorpow_5</th>\n",
       "      <th>concavity errorpow_6</th>\n",
       "      <th>concavity errorpow_7</th>\n",
       "      <th>concavity errorpow_8</th>\n",
       "      <th>concavity errorpow_9</th>\n",
       "      <th>concavity errorpow_10</th>\n",
       "      <th>concavity errorpow_11</th>\n",
       "      <th>concavity errorpow_12</th>\n",
       "      <th>concavity errorpow_13</th>\n",
       "      <th>concavity errorpow_14</th>\n",
       "      <th>concavity errorpow_15</th>\n",
       "      <th>concavity errorpow_16</th>\n",
       "      <th>concavity errorpow_17</th>\n",
       "      <th>concavity errorpow_18</th>\n",
       "      <th>concavity errorpow_19</th>\n",
       "      <th>concavity errorpow_20</th>\n",
       "      <th>concavity errorpow_21</th>\n",
       "      <th>concavity errorpow_22</th>\n",
       "      <th>concavity errorpow_23</th>\n",
       "      <th>concave points errorpow_2</th>\n",
       "      <th>concave points errorpow_3</th>\n",
       "      <th>concave points errorpow_4</th>\n",
       "      <th>concave points errorpow_5</th>\n",
       "      <th>concave points errorpow_6</th>\n",
       "      <th>concave points errorpow_7</th>\n",
       "      <th>concave points errorpow_8</th>\n",
       "      <th>concave points errorpow_9</th>\n",
       "      <th>concave points errorpow_10</th>\n",
       "      <th>concave points errorpow_11</th>\n",
       "      <th>concave points errorpow_12</th>\n",
       "      <th>concave points errorpow_13</th>\n",
       "      <th>concave points errorpow_14</th>\n",
       "      <th>concave points errorpow_15</th>\n",
       "      <th>concave points errorpow_16</th>\n",
       "      <th>concave points errorpow_17</th>\n",
       "      <th>concave points errorpow_18</th>\n",
       "      <th>concave points errorpow_19</th>\n",
       "      <th>concave points errorpow_20</th>\n",
       "      <th>concave points errorpow_21</th>\n",
       "      <th>concave points errorpow_22</th>\n",
       "      <th>concave points errorpow_23</th>\n",
       "      <th>symmetry errorpow_2</th>\n",
       "      <th>symmetry errorpow_3</th>\n",
       "      <th>symmetry errorpow_4</th>\n",
       "      <th>symmetry errorpow_5</th>\n",
       "      <th>symmetry errorpow_6</th>\n",
       "      <th>symmetry errorpow_7</th>\n",
       "      <th>symmetry errorpow_8</th>\n",
       "      <th>symmetry errorpow_9</th>\n",
       "      <th>symmetry errorpow_10</th>\n",
       "      <th>symmetry errorpow_11</th>\n",
       "      <th>symmetry errorpow_12</th>\n",
       "      <th>symmetry errorpow_13</th>\n",
       "      <th>symmetry errorpow_14</th>\n",
       "      <th>symmetry errorpow_15</th>\n",
       "      <th>symmetry errorpow_16</th>\n",
       "      <th>symmetry errorpow_17</th>\n",
       "      <th>symmetry errorpow_18</th>\n",
       "      <th>symmetry errorpow_19</th>\n",
       "      <th>symmetry errorpow_20</th>\n",
       "      <th>symmetry errorpow_21</th>\n",
       "      <th>symmetry errorpow_22</th>\n",
       "      <th>symmetry errorpow_23</th>\n",
       "      <th>fractal dimension errorpow_2</th>\n",
       "      <th>fractal dimension errorpow_3</th>\n",
       "      <th>fractal dimension errorpow_4</th>\n",
       "      <th>fractal dimension errorpow_5</th>\n",
       "      <th>fractal dimension errorpow_6</th>\n",
       "      <th>fractal dimension errorpow_7</th>\n",
       "      <th>fractal dimension errorpow_8</th>\n",
       "      <th>fractal dimension errorpow_9</th>\n",
       "      <th>fractal dimension errorpow_10</th>\n",
       "      <th>fractal dimension errorpow_11</th>\n",
       "      <th>fractal dimension errorpow_12</th>\n",
       "      <th>fractal dimension errorpow_13</th>\n",
       "      <th>fractal dimension errorpow_14</th>\n",
       "      <th>fractal dimension errorpow_15</th>\n",
       "      <th>fractal dimension errorpow_16</th>\n",
       "      <th>fractal dimension errorpow_17</th>\n",
       "      <th>fractal dimension errorpow_18</th>\n",
       "      <th>fractal dimension errorpow_19</th>\n",
       "      <th>fractal dimension errorpow_20</th>\n",
       "      <th>fractal dimension errorpow_21</th>\n",
       "      <th>fractal dimension errorpow_22</th>\n",
       "      <th>fractal dimension errorpow_23</th>\n",
       "      <th>worst radiuspow_2</th>\n",
       "      <th>worst radiuspow_3</th>\n",
       "      <th>worst radiuspow_4</th>\n",
       "      <th>worst radiuspow_5</th>\n",
       "      <th>worst radiuspow_6</th>\n",
       "      <th>worst radiuspow_7</th>\n",
       "      <th>worst radiuspow_8</th>\n",
       "      <th>worst radiuspow_9</th>\n",
       "      <th>worst radiuspow_10</th>\n",
       "      <th>worst radiuspow_11</th>\n",
       "      <th>worst radiuspow_12</th>\n",
       "      <th>worst radiuspow_13</th>\n",
       "      <th>worst radiuspow_14</th>\n",
       "      <th>worst radiuspow_15</th>\n",
       "      <th>worst radiuspow_16</th>\n",
       "      <th>worst radiuspow_17</th>\n",
       "      <th>worst radiuspow_18</th>\n",
       "      <th>worst radiuspow_19</th>\n",
       "      <th>worst radiuspow_20</th>\n",
       "      <th>worst radiuspow_21</th>\n",
       "      <th>worst radiuspow_22</th>\n",
       "      <th>worst radiuspow_23</th>\n",
       "      <th>worst texturepow_2</th>\n",
       "      <th>worst texturepow_3</th>\n",
       "      <th>worst texturepow_4</th>\n",
       "      <th>worst texturepow_5</th>\n",
       "      <th>worst texturepow_6</th>\n",
       "      <th>worst texturepow_7</th>\n",
       "      <th>worst texturepow_8</th>\n",
       "      <th>worst texturepow_9</th>\n",
       "      <th>worst texturepow_10</th>\n",
       "      <th>worst texturepow_11</th>\n",
       "      <th>worst texturepow_12</th>\n",
       "      <th>worst texturepow_13</th>\n",
       "      <th>worst texturepow_14</th>\n",
       "      <th>worst texturepow_15</th>\n",
       "      <th>worst texturepow_16</th>\n",
       "      <th>worst texturepow_17</th>\n",
       "      <th>worst texturepow_18</th>\n",
       "      <th>worst texturepow_19</th>\n",
       "      <th>worst texturepow_20</th>\n",
       "      <th>worst texturepow_21</th>\n",
       "      <th>worst texturepow_22</th>\n",
       "      <th>worst texturepow_23</th>\n",
       "      <th>worst perimeterpow_2</th>\n",
       "      <th>worst perimeterpow_3</th>\n",
       "      <th>worst perimeterpow_4</th>\n",
       "      <th>worst perimeterpow_5</th>\n",
       "      <th>worst perimeterpow_6</th>\n",
       "      <th>worst perimeterpow_7</th>\n",
       "      <th>worst perimeterpow_8</th>\n",
       "      <th>worst perimeterpow_9</th>\n",
       "      <th>worst perimeterpow_10</th>\n",
       "      <th>worst perimeterpow_11</th>\n",
       "      <th>worst perimeterpow_12</th>\n",
       "      <th>worst perimeterpow_13</th>\n",
       "      <th>worst perimeterpow_14</th>\n",
       "      <th>worst perimeterpow_15</th>\n",
       "      <th>worst perimeterpow_16</th>\n",
       "      <th>worst perimeterpow_17</th>\n",
       "      <th>worst perimeterpow_18</th>\n",
       "      <th>worst perimeterpow_19</th>\n",
       "      <th>worst perimeterpow_20</th>\n",
       "      <th>worst perimeterpow_21</th>\n",
       "      <th>worst perimeterpow_22</th>\n",
       "      <th>worst perimeterpow_23</th>\n",
       "      <th>worst areapow_2</th>\n",
       "      <th>worst areapow_3</th>\n",
       "      <th>worst areapow_4</th>\n",
       "      <th>worst areapow_5</th>\n",
       "      <th>worst areapow_6</th>\n",
       "      <th>worst areapow_7</th>\n",
       "      <th>worst areapow_8</th>\n",
       "      <th>worst areapow_9</th>\n",
       "      <th>worst areapow_10</th>\n",
       "      <th>worst areapow_11</th>\n",
       "      <th>worst areapow_12</th>\n",
       "      <th>worst areapow_13</th>\n",
       "      <th>worst areapow_14</th>\n",
       "      <th>worst areapow_15</th>\n",
       "      <th>worst areapow_16</th>\n",
       "      <th>worst areapow_17</th>\n",
       "      <th>worst areapow_18</th>\n",
       "      <th>worst areapow_19</th>\n",
       "      <th>worst areapow_20</th>\n",
       "      <th>worst areapow_21</th>\n",
       "      <th>worst areapow_22</th>\n",
       "      <th>worst areapow_23</th>\n",
       "      <th>worst smoothnesspow_2</th>\n",
       "      <th>worst smoothnesspow_3</th>\n",
       "      <th>worst smoothnesspow_4</th>\n",
       "      <th>worst smoothnesspow_5</th>\n",
       "      <th>worst smoothnesspow_6</th>\n",
       "      <th>worst smoothnesspow_7</th>\n",
       "      <th>worst smoothnesspow_8</th>\n",
       "      <th>worst smoothnesspow_9</th>\n",
       "      <th>worst smoothnesspow_10</th>\n",
       "      <th>worst smoothnesspow_11</th>\n",
       "      <th>worst smoothnesspow_12</th>\n",
       "      <th>worst smoothnesspow_13</th>\n",
       "      <th>worst smoothnesspow_14</th>\n",
       "      <th>worst smoothnesspow_15</th>\n",
       "      <th>worst smoothnesspow_16</th>\n",
       "      <th>worst smoothnesspow_17</th>\n",
       "      <th>worst smoothnesspow_18</th>\n",
       "      <th>worst smoothnesspow_19</th>\n",
       "      <th>worst smoothnesspow_20</th>\n",
       "      <th>worst smoothnesspow_21</th>\n",
       "      <th>worst smoothnesspow_22</th>\n",
       "      <th>worst smoothnesspow_23</th>\n",
       "      <th>worst compactnesspow_2</th>\n",
       "      <th>worst compactnesspow_3</th>\n",
       "      <th>worst compactnesspow_4</th>\n",
       "      <th>worst compactnesspow_5</th>\n",
       "      <th>worst compactnesspow_6</th>\n",
       "      <th>worst compactnesspow_7</th>\n",
       "      <th>worst compactnesspow_8</th>\n",
       "      <th>worst compactnesspow_9</th>\n",
       "      <th>worst compactnesspow_10</th>\n",
       "      <th>worst compactnesspow_11</th>\n",
       "      <th>worst compactnesspow_12</th>\n",
       "      <th>worst compactnesspow_13</th>\n",
       "      <th>worst compactnesspow_14</th>\n",
       "      <th>worst compactnesspow_15</th>\n",
       "      <th>worst compactnesspow_16</th>\n",
       "      <th>worst compactnesspow_17</th>\n",
       "      <th>worst compactnesspow_18</th>\n",
       "      <th>worst compactnesspow_19</th>\n",
       "      <th>worst compactnesspow_20</th>\n",
       "      <th>worst compactnesspow_21</th>\n",
       "      <th>worst compactnesspow_22</th>\n",
       "      <th>worst compactnesspow_23</th>\n",
       "      <th>worst concavitypow_2</th>\n",
       "      <th>worst concavitypow_3</th>\n",
       "      <th>worst concavitypow_4</th>\n",
       "      <th>worst concavitypow_5</th>\n",
       "      <th>worst concavitypow_6</th>\n",
       "      <th>worst concavitypow_7</th>\n",
       "      <th>worst concavitypow_8</th>\n",
       "      <th>worst concavitypow_9</th>\n",
       "      <th>worst concavitypow_10</th>\n",
       "      <th>worst concavitypow_11</th>\n",
       "      <th>worst concavitypow_12</th>\n",
       "      <th>worst concavitypow_13</th>\n",
       "      <th>worst concavitypow_14</th>\n",
       "      <th>worst concavitypow_15</th>\n",
       "      <th>worst concavitypow_16</th>\n",
       "      <th>worst concavitypow_17</th>\n",
       "      <th>worst concavitypow_18</th>\n",
       "      <th>worst concavitypow_19</th>\n",
       "      <th>worst concavitypow_20</th>\n",
       "      <th>worst concavitypow_21</th>\n",
       "      <th>worst concavitypow_22</th>\n",
       "      <th>worst concavitypow_23</th>\n",
       "      <th>worst concave pointspow_2</th>\n",
       "      <th>worst concave pointspow_3</th>\n",
       "      <th>worst concave pointspow_4</th>\n",
       "      <th>worst concave pointspow_5</th>\n",
       "      <th>worst concave pointspow_6</th>\n",
       "      <th>worst concave pointspow_7</th>\n",
       "      <th>worst concave pointspow_8</th>\n",
       "      <th>worst concave pointspow_9</th>\n",
       "      <th>worst concave pointspow_10</th>\n",
       "      <th>worst concave pointspow_11</th>\n",
       "      <th>worst concave pointspow_12</th>\n",
       "      <th>worst concave pointspow_13</th>\n",
       "      <th>worst concave pointspow_14</th>\n",
       "      <th>worst concave pointspow_15</th>\n",
       "      <th>worst concave pointspow_16</th>\n",
       "      <th>worst concave pointspow_17</th>\n",
       "      <th>worst concave pointspow_18</th>\n",
       "      <th>worst concave pointspow_19</th>\n",
       "      <th>worst concave pointspow_20</th>\n",
       "      <th>worst concave pointspow_21</th>\n",
       "      <th>worst concave pointspow_22</th>\n",
       "      <th>worst concave pointspow_23</th>\n",
       "      <th>worst symmetrypow_2</th>\n",
       "      <th>worst symmetrypow_3</th>\n",
       "      <th>worst symmetrypow_4</th>\n",
       "      <th>worst symmetrypow_5</th>\n",
       "      <th>worst symmetrypow_6</th>\n",
       "      <th>worst symmetrypow_7</th>\n",
       "      <th>worst symmetrypow_8</th>\n",
       "      <th>worst symmetrypow_9</th>\n",
       "      <th>worst symmetrypow_10</th>\n",
       "      <th>worst symmetrypow_11</th>\n",
       "      <th>worst symmetrypow_12</th>\n",
       "      <th>worst symmetrypow_13</th>\n",
       "      <th>worst symmetrypow_14</th>\n",
       "      <th>worst symmetrypow_15</th>\n",
       "      <th>worst symmetrypow_16</th>\n",
       "      <th>worst symmetrypow_17</th>\n",
       "      <th>worst symmetrypow_18</th>\n",
       "      <th>worst symmetrypow_19</th>\n",
       "      <th>worst symmetrypow_20</th>\n",
       "      <th>worst symmetrypow_21</th>\n",
       "      <th>worst symmetrypow_22</th>\n",
       "      <th>worst symmetrypow_23</th>\n",
       "      <th>worst fractal dimensionpow_2</th>\n",
       "      <th>worst fractal dimensionpow_3</th>\n",
       "      <th>worst fractal dimensionpow_4</th>\n",
       "      <th>worst fractal dimensionpow_5</th>\n",
       "      <th>worst fractal dimensionpow_6</th>\n",
       "      <th>worst fractal dimensionpow_7</th>\n",
       "      <th>worst fractal dimensionpow_8</th>\n",
       "      <th>worst fractal dimensionpow_9</th>\n",
       "      <th>worst fractal dimensionpow_10</th>\n",
       "      <th>worst fractal dimensionpow_11</th>\n",
       "      <th>worst fractal dimensionpow_12</th>\n",
       "      <th>worst fractal dimensionpow_13</th>\n",
       "      <th>worst fractal dimensionpow_14</th>\n",
       "      <th>worst fractal dimensionpow_15</th>\n",
       "      <th>worst fractal dimensionpow_16</th>\n",
       "      <th>worst fractal dimensionpow_17</th>\n",
       "      <th>worst fractal dimensionpow_18</th>\n",
       "      <th>worst fractal dimensionpow_19</th>\n",
       "      <th>worst fractal dimensionpow_20</th>\n",
       "      <th>worst fractal dimensionpow_21</th>\n",
       "      <th>worst fractal dimensionpow_22</th>\n",
       "      <th>worst fractal dimensionpow_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>2.489734</td>\n",
       "      <td>-0.565265</td>\n",
       "      <td>2.833031</td>\n",
       "      <td>2.487578</td>\n",
       "      <td>-0.214002</td>\n",
       "      <td>1.316862</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.660820</td>\n",
       "      <td>1.148757</td>\n",
       "      <td>0.907083</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>0.992811</td>\n",
       "      <td>0.839412</td>\n",
       "      <td>0.659649</td>\n",
       "      <td>0.478478</td>\n",
       "      <td>0.316323</td>\n",
       "      <td>0.184622</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.060035</td>\n",
       "      <td>-0.077835</td>\n",
       "      <td>-0.087781</td>\n",
       "      <td>-0.092665</td>\n",
       "      <td>-0.094399</td>\n",
       "      <td>-0.094247</td>\n",
       "      <td>-0.093027</td>\n",
       "      <td>-0.091251</td>\n",
       "      <td>-0.089235</td>\n",
       "      <td>-0.087165</td>\n",
       "      <td>-0.085146</td>\n",
       "      <td>-0.083232</td>\n",
       "      <td>-0.081446</td>\n",
       "      <td>-1.571385</td>\n",
       "      <td>-1.179184</td>\n",
       "      <td>-0.877428</td>\n",
       "      <td>-0.647949</td>\n",
       "      <td>-0.476180</td>\n",
       "      <td>-0.350449</td>\n",
       "      <td>-0.260573</td>\n",
       "      <td>-0.197479</td>\n",
       "      <td>-0.153577</td>\n",
       "      <td>-0.123030</td>\n",
       "      <td>-0.101635</td>\n",
       "      <td>-0.086490</td>\n",
       "      <td>-0.075630</td>\n",
       "      <td>-0.067737</td>\n",
       "      <td>-0.061921</td>\n",
       "      <td>-0.057580</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>-0.051789</td>\n",
       "      <td>-0.049849</td>\n",
       "      <td>-0.048336</td>\n",
       "      <td>-0.047144</td>\n",
       "      <td>-0.046198</td>\n",
       "      <td>1.179187</td>\n",
       "      <td>1.021620</td>\n",
       "      <td>0.823233</td>\n",
       "      <td>0.615745</td>\n",
       "      <td>0.426231</td>\n",
       "      <td>0.270127</td>\n",
       "      <td>0.151148</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.032491</td>\n",
       "      <td>-0.057571</td>\n",
       "      <td>-0.073038</td>\n",
       "      <td>-0.082090</td>\n",
       "      <td>-0.086957</td>\n",
       "      <td>-0.089156</td>\n",
       "      <td>-0.089697</td>\n",
       "      <td>-0.089244</td>\n",
       "      <td>-0.088224</td>\n",
       "      <td>-0.086910</td>\n",
       "      <td>-0.085469</td>\n",
       "      <td>-0.084003</td>\n",
       "      <td>-0.082570</td>\n",
       "      <td>0.645627</td>\n",
       "      <td>0.299006</td>\n",
       "      <td>0.073012</td>\n",
       "      <td>-0.034847</td>\n",
       "      <td>-0.075354</td>\n",
       "      <td>-0.086157</td>\n",
       "      <td>-0.085947</td>\n",
       "      <td>-0.082501</td>\n",
       "      <td>-0.078665</td>\n",
       "      <td>-0.075310</td>\n",
       "      <td>-0.072590</td>\n",
       "      <td>-0.070434</td>\n",
       "      <td>-0.068726</td>\n",
       "      <td>-0.067362</td>\n",
       "      <td>-0.066257</td>\n",
       "      <td>-0.065351</td>\n",
       "      <td>-0.064596</td>\n",
       "      <td>-0.063961</td>\n",
       "      <td>-0.063420</td>\n",
       "      <td>-0.062956</td>\n",
       "      <td>-0.062554</td>\n",
       "      <td>-0.062204</td>\n",
       "      <td>1.610613</td>\n",
       "      <td>1.606685</td>\n",
       "      <td>1.550142</td>\n",
       "      <td>1.439774</td>\n",
       "      <td>1.282793</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>0.897147</td>\n",
       "      <td>0.707987</td>\n",
       "      <td>0.540456</td>\n",
       "      <td>0.400348</td>\n",
       "      <td>0.288010</td>\n",
       "      <td>0.200655</td>\n",
       "      <td>0.134230</td>\n",
       "      <td>0.084556</td>\n",
       "      <td>0.047884</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>-0.012228</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.029138</td>\n",
       "      <td>-0.034025</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>4.253180</td>\n",
       "      <td>4.854248</td>\n",
       "      <td>5.012855</td>\n",
       "      <td>4.816130</td>\n",
       "      <td>4.397126</td>\n",
       "      <td>3.871756</td>\n",
       "      <td>3.321508</td>\n",
       "      <td>2.795972</td>\n",
       "      <td>2.320972</td>\n",
       "      <td>1.906650</td>\n",
       "      <td>1.553787</td>\n",
       "      <td>1.258169</td>\n",
       "      <td>1.013342</td>\n",
       "      <td>0.812224</td>\n",
       "      <td>0.647977</td>\n",
       "      <td>0.514407</td>\n",
       "      <td>0.406123</td>\n",
       "      <td>0.318543</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.190819</td>\n",
       "      <td>0.144899</td>\n",
       "      <td>0.107946</td>\n",
       "      <td>3.068456</td>\n",
       "      <td>2.869591</td>\n",
       "      <td>2.387799</td>\n",
       "      <td>1.859265</td>\n",
       "      <td>1.388716</td>\n",
       "      <td>1.006878</td>\n",
       "      <td>0.712186</td>\n",
       "      <td>0.491548</td>\n",
       "      <td>0.329576</td>\n",
       "      <td>0.212262</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.068208</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>-0.004003</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>-0.039382</td>\n",
       "      <td>-0.049401</td>\n",
       "      <td>-0.056257</td>\n",
       "      <td>-0.060892</td>\n",
       "      <td>-0.063975</td>\n",
       "      <td>-0.065977</td>\n",
       "      <td>-0.067230</td>\n",
       "      <td>3.016780</td>\n",
       "      <td>3.008991</td>\n",
       "      <td>2.695776</td>\n",
       "      <td>2.264764</td>\n",
       "      <td>1.826500</td>\n",
       "      <td>1.431952</td>\n",
       "      <td>1.098730</td>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.612995</td>\n",
       "      <td>0.445483</td>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.218139</td>\n",
       "      <td>0.143749</td>\n",
       "      <td>0.087897</td>\n",
       "      <td>0.046261</td>\n",
       "      <td>0.015447</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>-0.023637</td>\n",
       "      <td>-0.035478</td>\n",
       "      <td>-0.043878</td>\n",
       "      <td>-0.049725</td>\n",
       "      <td>-0.053689</td>\n",
       "      <td>2.366655</td>\n",
       "      <td>2.457679</td>\n",
       "      <td>2.477865</td>\n",
       "      <td>2.422410</td>\n",
       "      <td>2.296459</td>\n",
       "      <td>2.114066</td>\n",
       "      <td>1.894525</td>\n",
       "      <td>1.657852</td>\n",
       "      <td>1.421215</td>\n",
       "      <td>1.197153</td>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.658678</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.417684</td>\n",
       "      <td>0.326949</td>\n",
       "      <td>0.252530</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.142771</td>\n",
       "      <td>0.103144</td>\n",
       "      <td>0.071306</td>\n",
       "      <td>0.045818</td>\n",
       "      <td>2.305800</td>\n",
       "      <td>2.310406</td>\n",
       "      <td>2.262748</td>\n",
       "      <td>2.161831</td>\n",
       "      <td>2.013695</td>\n",
       "      <td>1.830364</td>\n",
       "      <td>1.626859</td>\n",
       "      <td>1.417777</td>\n",
       "      <td>1.214863</td>\n",
       "      <td>1.026079</td>\n",
       "      <td>0.855854</td>\n",
       "      <td>0.705880</td>\n",
       "      <td>0.576006</td>\n",
       "      <td>0.464983</td>\n",
       "      <td>0.371002</td>\n",
       "      <td>0.292050</td>\n",
       "      <td>0.226121</td>\n",
       "      <td>0.171334</td>\n",
       "      <td>0.125991</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.032648</td>\n",
       "      <td>1.838274</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.328606</td>\n",
       "      <td>0.096865</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>-0.031859</td>\n",
       "      <td>-0.045250</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>-0.050986</td>\n",
       "      <td>-0.050875</td>\n",
       "      <td>-0.050309</td>\n",
       "      <td>-0.049608</td>\n",
       "      <td>-0.048892</td>\n",
       "      <td>-0.048210</td>\n",
       "      <td>-0.047576</td>\n",
       "      <td>-0.046994</td>\n",
       "      <td>-0.046466</td>\n",
       "      <td>-0.045987</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.044506</td>\n",
       "      <td>-0.494328</td>\n",
       "      <td>-0.344461</td>\n",
       "      <td>-0.216954</td>\n",
       "      <td>-0.140127</td>\n",
       "      <td>-0.098995</td>\n",
       "      <td>-0.077033</td>\n",
       "      <td>-0.064746</td>\n",
       "      <td>-0.057444</td>\n",
       "      <td>-0.052848</td>\n",
       "      <td>-0.049813</td>\n",
       "      <td>-0.04773</td>\n",
       "      <td>-0.04626</td>\n",
       "      <td>-0.045198</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>-0.043837</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>-0.042625</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042362</td>\n",
       "      <td>-0.042274</td>\n",
       "      <td>2.114772</td>\n",
       "      <td>1.018757</td>\n",
       "      <td>0.401959</td>\n",
       "      <td>0.131759</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>-0.022894</td>\n",
       "      <td>-0.039681</td>\n",
       "      <td>-0.045648</td>\n",
       "      <td>-0.047383</td>\n",
       "      <td>-0.047516</td>\n",
       "      <td>-0.047087</td>\n",
       "      <td>-0.046499</td>\n",
       "      <td>-0.045904</td>\n",
       "      <td>-0.045356</td>\n",
       "      <td>-0.044871</td>\n",
       "      <td>-0.044448</td>\n",
       "      <td>-0.044083</td>\n",
       "      <td>-0.04377</td>\n",
       "      <td>-0.043501</td>\n",
       "      <td>-0.043272</td>\n",
       "      <td>-0.043076</td>\n",
       "      <td>-0.042909</td>\n",
       "      <td>1.122429</td>\n",
       "      <td>0.307163</td>\n",
       "      <td>0.047173</td>\n",
       "      <td>-0.028782</td>\n",
       "      <td>-0.050521</td>\n",
       "      <td>-0.056632</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>-0.058644</td>\n",
       "      <td>-0.058648</td>\n",
       "      <td>-0.058543</td>\n",
       "      <td>-0.058400</td>\n",
       "      <td>-0.058240</td>\n",
       "      <td>-0.058069</td>\n",
       "      <td>-0.057887</td>\n",
       "      <td>-0.057696</td>\n",
       "      <td>-0.057498</td>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.057078</td>\n",
       "      <td>-0.056858</td>\n",
       "      <td>-0.056632</td>\n",
       "      <td>-0.056402</td>\n",
       "      <td>-0.056167</td>\n",
       "      <td>-0.261577</td>\n",
       "      <td>-0.210715</td>\n",
       "      <td>-0.143048</td>\n",
       "      <td>-0.098239</td>\n",
       "      <td>-0.073777</td>\n",
       "      <td>-0.060812</td>\n",
       "      <td>-0.053703</td>\n",
       "      <td>-0.049587</td>\n",
       "      <td>-0.047073</td>\n",
       "      <td>-0.045467</td>\n",
       "      <td>-0.044406</td>\n",
       "      <td>-0.043687</td>\n",
       "      <td>-0.043190</td>\n",
       "      <td>-0.042842</td>\n",
       "      <td>-0.042596</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.042294</td>\n",
       "      <td>-0.042204</td>\n",
       "      <td>-0.042138</td>\n",
       "      <td>-0.04209</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>-0.04203</td>\n",
       "      <td>0.880017</td>\n",
       "      <td>0.410043</td>\n",
       "      <td>0.121611</td>\n",
       "      <td>-0.007938</td>\n",
       "      <td>-0.053169</td>\n",
       "      <td>-0.063647</td>\n",
       "      <td>-0.062411</td>\n",
       "      <td>-0.058323</td>\n",
       "      <td>-0.054292</td>\n",
       "      <td>-0.051045</td>\n",
       "      <td>-0.048606</td>\n",
       "      <td>-0.046822</td>\n",
       "      <td>-0.045528</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>-0.043908</td>\n",
       "      <td>-0.043409</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>-0.042571</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042309</td>\n",
       "      <td>-0.042225</td>\n",
       "      <td>0.120716</td>\n",
       "      <td>-0.036389</td>\n",
       "      <td>-0.053806</td>\n",
       "      <td>-0.052445</td>\n",
       "      <td>-0.050007</td>\n",
       "      <td>-0.048136</td>\n",
       "      <td>-0.046734</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>-0.044175</td>\n",
       "      <td>-0.04367</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.04274</td>\n",
       "      <td>-0.04256</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042314</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>-0.042168</td>\n",
       "      <td>-0.04212</td>\n",
       "      <td>-0.042082</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>0.343497</td>\n",
       "      <td>0.079206</td>\n",
       "      <td>-0.039885</td>\n",
       "      <td>-0.070927</td>\n",
       "      <td>-0.070982</td>\n",
       "      <td>-0.064285</td>\n",
       "      <td>-0.057924</td>\n",
       "      <td>-0.053192</td>\n",
       "      <td>-0.049895</td>\n",
       "      <td>-0.047627</td>\n",
       "      <td>-0.046054</td>\n",
       "      <td>-0.044949</td>\n",
       "      <td>-0.044161</td>\n",
       "      <td>-0.043592</td>\n",
       "      <td>-0.043177</td>\n",
       "      <td>-0.042872</td>\n",
       "      <td>-0.042646</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042351</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>-0.042131</td>\n",
       "      <td>0.803879</td>\n",
       "      <td>0.420721</td>\n",
       "      <td>0.152619</td>\n",
       "      <td>0.016348</td>\n",
       "      <td>-0.038466</td>\n",
       "      <td>-0.055502</td>\n",
       "      <td>-0.057971</td>\n",
       "      <td>-0.055842</td>\n",
       "      <td>-0.052837</td>\n",
       "      <td>-0.050142</td>\n",
       "      <td>-0.048015</td>\n",
       "      <td>-0.046418</td>\n",
       "      <td>-0.045242</td>\n",
       "      <td>-0.044382</td>\n",
       "      <td>-0.043753</td>\n",
       "      <td>-0.043292</td>\n",
       "      <td>-0.042953</td>\n",
       "      <td>-0.042703</td>\n",
       "      <td>-0.042517</td>\n",
       "      <td>-0.042379</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>-0.042199</td>\n",
       "      <td>0.316620</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>-0.050581</td>\n",
       "      <td>-0.060641</td>\n",
       "      <td>-0.057979</td>\n",
       "      <td>-0.054115</td>\n",
       "      <td>-0.050990</td>\n",
       "      <td>-0.048672</td>\n",
       "      <td>-0.046967</td>\n",
       "      <td>-0.045707</td>\n",
       "      <td>-0.044771</td>\n",
       "      <td>-0.044072</td>\n",
       "      <td>-0.043549</td>\n",
       "      <td>-0.043157</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>-0.04264</td>\n",
       "      <td>-0.042473</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>-0.042253</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.042127</td>\n",
       "      <td>-0.042086</td>\n",
       "      <td>1.921784</td>\n",
       "      <td>1.847893</td>\n",
       "      <td>1.677322</td>\n",
       "      <td>1.441883</td>\n",
       "      <td>1.180547</td>\n",
       "      <td>0.926443</td>\n",
       "      <td>0.700411</td>\n",
       "      <td>0.511443</td>\n",
       "      <td>0.360330</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.155250</td>\n",
       "      <td>0.090159</td>\n",
       "      <td>0.042985</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>-0.014114</td>\n",
       "      <td>-0.030232</td>\n",
       "      <td>-0.041024</td>\n",
       "      <td>-0.048023</td>\n",
       "      <td>-0.052356</td>\n",
       "      <td>-0.054841</td>\n",
       "      <td>-0.056065</td>\n",
       "      <td>-0.056445</td>\n",
       "      <td>-1.172777</td>\n",
       "      <td>-0.979019</td>\n",
       "      <td>-0.796102</td>\n",
       "      <td>-0.635755</td>\n",
       "      <td>-0.503246</td>\n",
       "      <td>-0.398567</td>\n",
       "      <td>-0.318409</td>\n",
       "      <td>-0.258136</td>\n",
       "      <td>-0.213145</td>\n",
       "      <td>-0.179533</td>\n",
       "      <td>-0.154254</td>\n",
       "      <td>-0.135045</td>\n",
       "      <td>-0.120262</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>-0.099597</td>\n",
       "      <td>-0.092266</td>\n",
       "      <td>-0.086296</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.077251</td>\n",
       "      <td>-0.073768</td>\n",
       "      <td>-0.070790</td>\n",
       "      <td>-0.068219</td>\n",
       "      <td>2.492689</td>\n",
       "      <td>2.543999</td>\n",
       "      <td>2.445668</td>\n",
       "      <td>2.222294</td>\n",
       "      <td>1.921809</td>\n",
       "      <td>1.594595</td>\n",
       "      <td>1.279107</td>\n",
       "      <td>0.997964</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.567601</td>\n",
       "      <td>0.415048</td>\n",
       "      <td>0.296902</td>\n",
       "      <td>0.206825</td>\n",
       "      <td>0.138982</td>\n",
       "      <td>0.088385</td>\n",
       "      <td>0.050959</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>-0.011086</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.028975</td>\n",
       "      <td>-0.034237</td>\n",
       "      <td>1.757224</td>\n",
       "      <td>1.213453</td>\n",
       "      <td>0.689612</td>\n",
       "      <td>0.335015</td>\n",
       "      <td>0.134830</td>\n",
       "      <td>0.032932</td>\n",
       "      <td>-0.015311</td>\n",
       "      <td>-0.036591</td>\n",
       "      <td>-0.045060</td>\n",
       "      <td>-0.047748</td>\n",
       "      <td>-0.047996</td>\n",
       "      <td>-0.047336</td>\n",
       "      <td>-0.046434</td>\n",
       "      <td>-0.045561</td>\n",
       "      <td>-0.044808</td>\n",
       "      <td>-0.044192</td>\n",
       "      <td>-0.043701</td>\n",
       "      <td>-0.043317</td>\n",
       "      <td>-0.043017</td>\n",
       "      <td>-0.042784</td>\n",
       "      <td>-0.042603</td>\n",
       "      <td>-0.042463</td>\n",
       "      <td>1.311147</td>\n",
       "      <td>1.267484</td>\n",
       "      <td>1.178654</td>\n",
       "      <td>1.052959</td>\n",
       "      <td>0.903565</td>\n",
       "      <td>0.745462</td>\n",
       "      <td>0.592110</td>\n",
       "      <td>0.453158</td>\n",
       "      <td>0.333811</td>\n",
       "      <td>0.235502</td>\n",
       "      <td>0.157129</td>\n",
       "      <td>0.096238</td>\n",
       "      <td>0.049903</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>-0.010259</td>\n",
       "      <td>-0.028770</td>\n",
       "      <td>-0.041996</td>\n",
       "      <td>-0.051284</td>\n",
       "      <td>-0.057671</td>\n",
       "      <td>-0.061940</td>\n",
       "      <td>-0.064680</td>\n",
       "      <td>-0.066327</td>\n",
       "      <td>2.863740</td>\n",
       "      <td>2.553610</td>\n",
       "      <td>1.990057</td>\n",
       "      <td>1.427492</td>\n",
       "      <td>0.969235</td>\n",
       "      <td>0.630439</td>\n",
       "      <td>0.393303</td>\n",
       "      <td>0.233041</td>\n",
       "      <td>0.127406</td>\n",
       "      <td>0.059144</td>\n",
       "      <td>0.015796</td>\n",
       "      <td>-0.011252</td>\n",
       "      <td>-0.027798</td>\n",
       "      <td>-0.037665</td>\n",
       "      <td>-0.043338</td>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.047902</td>\n",
       "      <td>-0.048448</td>\n",
       "      <td>-0.048448</td>\n",
       "      <td>-0.048147</td>\n",
       "      <td>-0.047696</td>\n",
       "      <td>-0.047184</td>\n",
       "      <td>2.212144</td>\n",
       "      <td>1.811126</td>\n",
       "      <td>1.260063</td>\n",
       "      <td>0.788724</td>\n",
       "      <td>0.457020</td>\n",
       "      <td>0.244441</td>\n",
       "      <td>0.114780</td>\n",
       "      <td>0.038065</td>\n",
       "      <td>-0.006273</td>\n",
       "      <td>-0.031308</td>\n",
       "      <td>-0.045029</td>\n",
       "      <td>-0.052213</td>\n",
       "      <td>-0.055672</td>\n",
       "      <td>-0.057043</td>\n",
       "      <td>-0.057270</td>\n",
       "      <td>-0.056892</td>\n",
       "      <td>-0.056213</td>\n",
       "      <td>-0.055401</td>\n",
       "      <td>-0.054549</td>\n",
       "      <td>-0.053706</td>\n",
       "      <td>-0.052896</td>\n",
       "      <td>-0.052131</td>\n",
       "      <td>2.973647</td>\n",
       "      <td>3.488012</td>\n",
       "      <td>3.855071</td>\n",
       "      <td>4.087752</td>\n",
       "      <td>4.207423</td>\n",
       "      <td>4.236912</td>\n",
       "      <td>4.196573</td>\n",
       "      <td>4.103310</td>\n",
       "      <td>3.970828</td>\n",
       "      <td>3.810177</td>\n",
       "      <td>3.630261</td>\n",
       "      <td>3.438237</td>\n",
       "      <td>3.239823</td>\n",
       "      <td>3.039532</td>\n",
       "      <td>2.840869</td>\n",
       "      <td>2.646498</td>\n",
       "      <td>2.458384</td>\n",
       "      <td>2.277920</td>\n",
       "      <td>2.106040</td>\n",
       "      <td>1.943305</td>\n",
       "      <td>1.789992</td>\n",
       "      <td>1.646154</td>\n",
       "      <td>2.939826</td>\n",
       "      <td>2.909341</td>\n",
       "      <td>2.653515</td>\n",
       "      <td>2.242743</td>\n",
       "      <td>1.779484</td>\n",
       "      <td>1.345154</td>\n",
       "      <td>0.980702</td>\n",
       "      <td>0.695227</td>\n",
       "      <td>0.481115</td>\n",
       "      <td>0.324951</td>\n",
       "      <td>0.213136</td>\n",
       "      <td>0.134083</td>\n",
       "      <td>0.078699</td>\n",
       "      <td>0.040167</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>-0.004831</td>\n",
       "      <td>-0.017391</td>\n",
       "      <td>-0.025945</td>\n",
       "      <td>-0.031733</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>-0.038208</td>\n",
       "      <td>-0.039908</td>\n",
       "      <td>1.861001</td>\n",
       "      <td>1.621831</td>\n",
       "      <td>1.253440</td>\n",
       "      <td>0.860256</td>\n",
       "      <td>0.535568</td>\n",
       "      <td>0.307886</td>\n",
       "      <td>0.162516</td>\n",
       "      <td>0.074439</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>-0.023838</td>\n",
       "      <td>-0.033157</td>\n",
       "      <td>-0.038209</td>\n",
       "      <td>-0.040862</td>\n",
       "      <td>-0.042183</td>\n",
       "      <td>-0.042781</td>\n",
       "      <td>-0.042994</td>\n",
       "      <td>-0.043014</td>\n",
       "      <td>-0.042942</td>\n",
       "      <td>-0.042833</td>\n",
       "      <td>-0.042716</td>\n",
       "      <td>-0.042604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>-0.876244</td>\n",
       "      <td>0.263327</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>-0.605351</td>\n",
       "      <td>-0.692926</td>\n",
       "      <td>-0.440780</td>\n",
       "      <td>0.260162</td>\n",
       "      <td>-0.805450</td>\n",
       "      <td>-0.099444</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>1.877346</td>\n",
       "      <td>1.832171</td>\n",
       "      <td>1.698831</td>\n",
       "      <td>1.498134</td>\n",
       "      <td>1.261325</td>\n",
       "      <td>1.019710</td>\n",
       "      <td>0.796273</td>\n",
       "      <td>0.603219</td>\n",
       "      <td>0.444050</td>\n",
       "      <td>0.316996</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.084082</td>\n",
       "      <td>0.040804</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>-0.032456</td>\n",
       "      <td>-0.045010</td>\n",
       "      <td>-0.053990</td>\n",
       "      <td>-0.060318</td>\n",
       "      <td>-0.064689</td>\n",
       "      <td>-0.067623</td>\n",
       "      <td>-0.415521</td>\n",
       "      <td>-0.441227</td>\n",
       "      <td>-0.431399</td>\n",
       "      <td>-0.393286</td>\n",
       "      <td>-0.338623</td>\n",
       "      <td>-0.279711</td>\n",
       "      <td>-0.225603</td>\n",
       "      <td>-0.180685</td>\n",
       "      <td>-0.145672</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.099945</td>\n",
       "      <td>-0.085716</td>\n",
       "      <td>-0.075278</td>\n",
       "      <td>-0.067577</td>\n",
       "      <td>-0.061848</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.054283</td>\n",
       "      <td>-0.051782</td>\n",
       "      <td>-0.049846</td>\n",
       "      <td>-0.048334</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>-0.046197</td>\n",
       "      <td>1.684038</td>\n",
       "      <td>1.585903</td>\n",
       "      <td>1.406382</td>\n",
       "      <td>1.176830</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.707471</td>\n",
       "      <td>0.513681</td>\n",
       "      <td>0.357474</td>\n",
       "      <td>0.236581</td>\n",
       "      <td>0.145630</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>-0.004824</td>\n",
       "      <td>-0.029408</td>\n",
       "      <td>-0.046545</td>\n",
       "      <td>-0.058304</td>\n",
       "      <td>-0.066216</td>\n",
       "      <td>-0.071395</td>\n",
       "      <td>-0.074651</td>\n",
       "      <td>-0.076565</td>\n",
       "      <td>-0.077551</td>\n",
       "      <td>-0.077907</td>\n",
       "      <td>1.731892</td>\n",
       "      <td>1.272819</td>\n",
       "      <td>0.785139</td>\n",
       "      <td>0.424558</td>\n",
       "      <td>0.200706</td>\n",
       "      <td>0.073042</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>-0.032996</td>\n",
       "      <td>-0.051592</td>\n",
       "      <td>-0.060621</td>\n",
       "      <td>-0.064665</td>\n",
       "      <td>-0.066176</td>\n",
       "      <td>-0.066446</td>\n",
       "      <td>-0.066143</td>\n",
       "      <td>-0.065607</td>\n",
       "      <td>-0.065004</td>\n",
       "      <td>-0.064412</td>\n",
       "      <td>-0.063863</td>\n",
       "      <td>-0.063368</td>\n",
       "      <td>-0.062928</td>\n",
       "      <td>-0.062539</td>\n",
       "      <td>-0.062196</td>\n",
       "      <td>-0.817374</td>\n",
       "      <td>-0.783359</td>\n",
       "      <td>-0.727240</td>\n",
       "      <td>-0.653213</td>\n",
       "      <td>-0.567683</td>\n",
       "      <td>-0.478598</td>\n",
       "      <td>-0.393688</td>\n",
       "      <td>-0.318580</td>\n",
       "      <td>-0.255957</td>\n",
       "      <td>-0.205966</td>\n",
       "      <td>-0.167225</td>\n",
       "      <td>-0.137747</td>\n",
       "      <td>-0.115534</td>\n",
       "      <td>-0.098850</td>\n",
       "      <td>-0.086305</td>\n",
       "      <td>-0.076830</td>\n",
       "      <td>-0.069627</td>\n",
       "      <td>-0.064108</td>\n",
       "      <td>-0.059841</td>\n",
       "      <td>-0.056512</td>\n",
       "      <td>-0.053892</td>\n",
       "      <td>-0.051810</td>\n",
       "      <td>-0.502345</td>\n",
       "      <td>-0.428450</td>\n",
       "      <td>-0.336153</td>\n",
       "      <td>-0.259174</td>\n",
       "      <td>-0.203011</td>\n",
       "      <td>-0.163495</td>\n",
       "      <td>-0.135538</td>\n",
       "      <td>-0.115342</td>\n",
       "      <td>-0.100401</td>\n",
       "      <td>-0.089104</td>\n",
       "      <td>-0.080400</td>\n",
       "      <td>-0.073588</td>\n",
       "      <td>-0.068188</td>\n",
       "      <td>-0.063859</td>\n",
       "      <td>-0.060355</td>\n",
       "      <td>-0.057496</td>\n",
       "      <td>-0.055145</td>\n",
       "      <td>-0.053201</td>\n",
       "      <td>-0.051583</td>\n",
       "      <td>-0.050229</td>\n",
       "      <td>-0.049091</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>-0.270214</td>\n",
       "      <td>-0.292609</td>\n",
       "      <td>-0.247424</td>\n",
       "      <td>-0.201610</td>\n",
       "      <td>-0.167804</td>\n",
       "      <td>-0.144247</td>\n",
       "      <td>-0.127650</td>\n",
       "      <td>-0.115611</td>\n",
       "      <td>-0.106614</td>\n",
       "      <td>-0.099714</td>\n",
       "      <td>-0.094308</td>\n",
       "      <td>-0.089999</td>\n",
       "      <td>-0.086514</td>\n",
       "      <td>-0.083660</td>\n",
       "      <td>-0.081296</td>\n",
       "      <td>-0.079319</td>\n",
       "      <td>-0.077649</td>\n",
       "      <td>-0.076225</td>\n",
       "      <td>-0.075002</td>\n",
       "      <td>-0.073941</td>\n",
       "      <td>-0.073013</td>\n",
       "      <td>-0.072196</td>\n",
       "      <td>0.174748</td>\n",
       "      <td>-0.065228</td>\n",
       "      <td>-0.164433</td>\n",
       "      <td>-0.187168</td>\n",
       "      <td>-0.179775</td>\n",
       "      <td>-0.164054</td>\n",
       "      <td>-0.148186</td>\n",
       "      <td>-0.134539</td>\n",
       "      <td>-0.123373</td>\n",
       "      <td>-0.114329</td>\n",
       "      <td>-0.106956</td>\n",
       "      <td>-0.100864</td>\n",
       "      <td>-0.095749</td>\n",
       "      <td>-0.091384</td>\n",
       "      <td>-0.087601</td>\n",
       "      <td>-0.084277</td>\n",
       "      <td>-0.081320</td>\n",
       "      <td>-0.078661</td>\n",
       "      <td>-0.076248</td>\n",
       "      <td>-0.074043</td>\n",
       "      <td>-0.072015</td>\n",
       "      <td>-0.070140</td>\n",
       "      <td>-0.069864</td>\n",
       "      <td>-0.132200</td>\n",
       "      <td>-0.181362</td>\n",
       "      <td>-0.215000</td>\n",
       "      <td>-0.233026</td>\n",
       "      <td>-0.237370</td>\n",
       "      <td>-0.231230</td>\n",
       "      <td>-0.218169</td>\n",
       "      <td>-0.201390</td>\n",
       "      <td>-0.183354</td>\n",
       "      <td>-0.165709</td>\n",
       "      <td>-0.149409</td>\n",
       "      <td>-0.134898</td>\n",
       "      <td>-0.122288</td>\n",
       "      <td>-0.111498</td>\n",
       "      <td>-0.102350</td>\n",
       "      <td>-0.094632</td>\n",
       "      <td>-0.088132</td>\n",
       "      <td>-0.082652</td>\n",
       "      <td>-0.078022</td>\n",
       "      <td>-0.074096</td>\n",
       "      <td>-0.070753</td>\n",
       "      <td>-0.818680</td>\n",
       "      <td>-0.757722</td>\n",
       "      <td>-0.688064</td>\n",
       "      <td>-0.613145</td>\n",
       "      <td>-0.537124</td>\n",
       "      <td>-0.464112</td>\n",
       "      <td>-0.397382</td>\n",
       "      <td>-0.338916</td>\n",
       "      <td>-0.289403</td>\n",
       "      <td>-0.248539</td>\n",
       "      <td>-0.215429</td>\n",
       "      <td>-0.188923</td>\n",
       "      <td>-0.167852</td>\n",
       "      <td>-0.151146</td>\n",
       "      <td>-0.137894</td>\n",
       "      <td>-0.127347</td>\n",
       "      <td>-0.118907</td>\n",
       "      <td>-0.112106</td>\n",
       "      <td>-0.106578</td>\n",
       "      <td>-0.102042</td>\n",
       "      <td>-0.098280</td>\n",
       "      <td>-0.095127</td>\n",
       "      <td>0.104493</td>\n",
       "      <td>-0.051786</td>\n",
       "      <td>-0.071901</td>\n",
       "      <td>-0.066442</td>\n",
       "      <td>-0.060795</td>\n",
       "      <td>-0.057306</td>\n",
       "      <td>-0.055152</td>\n",
       "      <td>-0.053651</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>-0.051444</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>-0.049691</td>\n",
       "      <td>-0.048924</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>-0.047580</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>-0.046467</td>\n",
       "      <td>-0.045988</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.044506</td>\n",
       "      <td>-0.638260</td>\n",
       "      <td>-0.393326</td>\n",
       "      <td>-0.230047</td>\n",
       "      <td>-0.143167</td>\n",
       "      <td>-0.099646</td>\n",
       "      <td>-0.077166</td>\n",
       "      <td>-0.064772</td>\n",
       "      <td>-0.057449</td>\n",
       "      <td>-0.052849</td>\n",
       "      <td>-0.049813</td>\n",
       "      <td>-0.04773</td>\n",
       "      <td>-0.04626</td>\n",
       "      <td>-0.045198</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>-0.043837</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>-0.042625</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042362</td>\n",
       "      <td>-0.042274</td>\n",
       "      <td>-0.025752</td>\n",
       "      <td>-0.088904</td>\n",
       "      <td>-0.078015</td>\n",
       "      <td>-0.065405</td>\n",
       "      <td>-0.058344</td>\n",
       "      <td>-0.054529</td>\n",
       "      <td>-0.052215</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.049329</td>\n",
       "      <td>-0.048281</td>\n",
       "      <td>-0.047387</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-0.045374</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>-0.044451</td>\n",
       "      <td>-0.044084</td>\n",
       "      <td>-0.04377</td>\n",
       "      <td>-0.043501</td>\n",
       "      <td>-0.043272</td>\n",
       "      <td>-0.043076</td>\n",
       "      <td>-0.042909</td>\n",
       "      <td>0.101556</td>\n",
       "      <td>-0.046248</td>\n",
       "      <td>-0.061306</td>\n",
       "      <td>-0.060825</td>\n",
       "      <td>-0.059833</td>\n",
       "      <td>-0.059317</td>\n",
       "      <td>-0.059045</td>\n",
       "      <td>-0.058865</td>\n",
       "      <td>-0.058711</td>\n",
       "      <td>-0.058561</td>\n",
       "      <td>-0.058406</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>-0.058069</td>\n",
       "      <td>-0.057887</td>\n",
       "      <td>-0.057696</td>\n",
       "      <td>-0.057498</td>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.057078</td>\n",
       "      <td>-0.056858</td>\n",
       "      <td>-0.056632</td>\n",
       "      <td>-0.056402</td>\n",
       "      <td>-0.056167</td>\n",
       "      <td>-0.464082</td>\n",
       "      <td>-0.284819</td>\n",
       "      <td>-0.164210</td>\n",
       "      <td>-0.103528</td>\n",
       "      <td>-0.075011</td>\n",
       "      <td>-0.061089</td>\n",
       "      <td>-0.053763</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>-0.047076</td>\n",
       "      <td>-0.045468</td>\n",
       "      <td>-0.044406</td>\n",
       "      <td>-0.043687</td>\n",
       "      <td>-0.043190</td>\n",
       "      <td>-0.042842</td>\n",
       "      <td>-0.042596</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.042294</td>\n",
       "      <td>-0.042204</td>\n",
       "      <td>-0.042138</td>\n",
       "      <td>-0.04209</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>-0.04203</td>\n",
       "      <td>-0.489270</td>\n",
       "      <td>-0.308102</td>\n",
       "      <td>-0.198994</td>\n",
       "      <td>-0.138166</td>\n",
       "      <td>-0.103331</td>\n",
       "      <td>-0.082421</td>\n",
       "      <td>-0.069331</td>\n",
       "      <td>-0.060853</td>\n",
       "      <td>-0.055213</td>\n",
       "      <td>-0.051379</td>\n",
       "      <td>-0.048727</td>\n",
       "      <td>-0.046866</td>\n",
       "      <td>-0.045544</td>\n",
       "      <td>-0.044596</td>\n",
       "      <td>-0.043910</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.042772</td>\n",
       "      <td>-0.042571</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042309</td>\n",
       "      <td>-0.042225</td>\n",
       "      <td>-0.198763</td>\n",
       "      <td>-0.088319</td>\n",
       "      <td>-0.061344</td>\n",
       "      <td>-0.053501</td>\n",
       "      <td>-0.050153</td>\n",
       "      <td>-0.048156</td>\n",
       "      <td>-0.046737</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>-0.044175</td>\n",
       "      <td>-0.04367</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.04274</td>\n",
       "      <td>-0.04256</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042314</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>-0.042168</td>\n",
       "      <td>-0.04212</td>\n",
       "      <td>-0.042082</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>-0.108024</td>\n",
       "      <td>-0.121472</td>\n",
       "      <td>-0.101715</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>-0.067874</td>\n",
       "      <td>-0.059089</td>\n",
       "      <td>-0.053563</td>\n",
       "      <td>-0.050012</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>-0.046066</td>\n",
       "      <td>-0.044952</td>\n",
       "      <td>-0.044162</td>\n",
       "      <td>-0.043593</td>\n",
       "      <td>-0.043177</td>\n",
       "      <td>-0.042872</td>\n",
       "      <td>-0.042646</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042351</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>-0.042131</td>\n",
       "      <td>-0.580577</td>\n",
       "      <td>-0.370481</td>\n",
       "      <td>-0.228466</td>\n",
       "      <td>-0.148382</td>\n",
       "      <td>-0.105495</td>\n",
       "      <td>-0.081916</td>\n",
       "      <td>-0.068207</td>\n",
       "      <td>-0.059775</td>\n",
       "      <td>-0.054341</td>\n",
       "      <td>-0.050716</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>-0.046501</td>\n",
       "      <td>-0.045273</td>\n",
       "      <td>-0.044394</td>\n",
       "      <td>-0.043758</td>\n",
       "      <td>-0.043294</td>\n",
       "      <td>-0.042954</td>\n",
       "      <td>-0.042703</td>\n",
       "      <td>-0.042517</td>\n",
       "      <td>-0.042379</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>-0.042199</td>\n",
       "      <td>-0.166418</td>\n",
       "      <td>-0.121644</td>\n",
       "      <td>-0.086413</td>\n",
       "      <td>-0.068804</td>\n",
       "      <td>-0.059764</td>\n",
       "      <td>-0.054496</td>\n",
       "      <td>-0.051071</td>\n",
       "      <td>-0.048688</td>\n",
       "      <td>-0.046970</td>\n",
       "      <td>-0.045708</td>\n",
       "      <td>-0.044771</td>\n",
       "      <td>-0.044072</td>\n",
       "      <td>-0.043549</td>\n",
       "      <td>-0.043157</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>-0.04264</td>\n",
       "      <td>-0.042473</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>-0.042253</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.042127</td>\n",
       "      <td>-0.042086</td>\n",
       "      <td>1.815780</td>\n",
       "      <td>1.720680</td>\n",
       "      <td>1.536875</td>\n",
       "      <td>1.297951</td>\n",
       "      <td>1.042112</td>\n",
       "      <td>0.800044</td>\n",
       "      <td>0.589707</td>\n",
       "      <td>0.417638</td>\n",
       "      <td>0.282911</td>\n",
       "      <td>0.180860</td>\n",
       "      <td>0.105573</td>\n",
       "      <td>0.051265</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>-0.013664</td>\n",
       "      <td>-0.031626</td>\n",
       "      <td>-0.043440</td>\n",
       "      <td>-0.050925</td>\n",
       "      <td>-0.055406</td>\n",
       "      <td>-0.057836</td>\n",
       "      <td>-0.058893</td>\n",
       "      <td>-0.059050</td>\n",
       "      <td>-0.058638</td>\n",
       "      <td>-0.440498</td>\n",
       "      <td>-0.472761</td>\n",
       "      <td>-0.468127</td>\n",
       "      <td>-0.435678</td>\n",
       "      <td>-0.387476</td>\n",
       "      <td>-0.334470</td>\n",
       "      <td>-0.284149</td>\n",
       "      <td>-0.240315</td>\n",
       "      <td>-0.204065</td>\n",
       "      <td>-0.174978</td>\n",
       "      <td>-0.151996</td>\n",
       "      <td>-0.133935</td>\n",
       "      <td>-0.119721</td>\n",
       "      <td>-0.108465</td>\n",
       "      <td>-0.099471</td>\n",
       "      <td>-0.092205</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>-0.081355</td>\n",
       "      <td>-0.077244</td>\n",
       "      <td>-0.073765</td>\n",
       "      <td>-0.070789</td>\n",
       "      <td>-0.068218</td>\n",
       "      <td>1.462870</td>\n",
       "      <td>1.293632</td>\n",
       "      <td>1.060699</td>\n",
       "      <td>0.808032</td>\n",
       "      <td>0.573302</td>\n",
       "      <td>0.378247</td>\n",
       "      <td>0.229063</td>\n",
       "      <td>0.121982</td>\n",
       "      <td>0.048953</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>-0.028400</td>\n",
       "      <td>-0.046032</td>\n",
       "      <td>-0.055781</td>\n",
       "      <td>-0.060558</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>-0.062282</td>\n",
       "      <td>-0.061288</td>\n",
       "      <td>-0.059815</td>\n",
       "      <td>-0.058158</td>\n",
       "      <td>-0.056487</td>\n",
       "      <td>-0.054894</td>\n",
       "      <td>-0.053425</td>\n",
       "      <td>1.609423</td>\n",
       "      <td>1.070798</td>\n",
       "      <td>0.580768</td>\n",
       "      <td>0.263443</td>\n",
       "      <td>0.091857</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>-0.028633</td>\n",
       "      <td>-0.043692</td>\n",
       "      <td>-0.048778</td>\n",
       "      <td>-0.049669</td>\n",
       "      <td>-0.048979</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>-0.046686</td>\n",
       "      <td>-0.045687</td>\n",
       "      <td>-0.044871</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.043717</td>\n",
       "      <td>-0.043324</td>\n",
       "      <td>-0.043021</td>\n",
       "      <td>-0.042786</td>\n",
       "      <td>-0.042604</td>\n",
       "      <td>-0.042463</td>\n",
       "      <td>-0.430664</td>\n",
       "      <td>-0.462378</td>\n",
       "      <td>-0.470044</td>\n",
       "      <td>-0.456249</td>\n",
       "      <td>-0.426126</td>\n",
       "      <td>-0.385987</td>\n",
       "      <td>-0.341856</td>\n",
       "      <td>-0.298417</td>\n",
       "      <td>-0.258645</td>\n",
       "      <td>-0.223979</td>\n",
       "      <td>-0.194751</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.135153</td>\n",
       "      <td>-0.122367</td>\n",
       "      <td>-0.112051</td>\n",
       "      <td>-0.103702</td>\n",
       "      <td>-0.096911</td>\n",
       "      <td>-0.091352</td>\n",
       "      <td>-0.086771</td>\n",
       "      <td>-0.082967</td>\n",
       "      <td>-0.079782</td>\n",
       "      <td>-0.441652</td>\n",
       "      <td>-0.347011</td>\n",
       "      <td>-0.253305</td>\n",
       "      <td>-0.188844</td>\n",
       "      <td>-0.148147</td>\n",
       "      <td>-0.122127</td>\n",
       "      <td>-0.104701</td>\n",
       "      <td>-0.092411</td>\n",
       "      <td>-0.083340</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.070924</td>\n",
       "      <td>-0.066520</td>\n",
       "      <td>-0.062916</td>\n",
       "      <td>-0.059928</td>\n",
       "      <td>-0.057427</td>\n",
       "      <td>-0.055316</td>\n",
       "      <td>-0.053524</td>\n",
       "      <td>-0.051994</td>\n",
       "      <td>-0.050683</td>\n",
       "      <td>-0.049556</td>\n",
       "      <td>-0.048583</td>\n",
       "      <td>-0.047743</td>\n",
       "      <td>-0.336217</td>\n",
       "      <td>-0.319082</td>\n",
       "      <td>-0.245823</td>\n",
       "      <td>-0.183034</td>\n",
       "      <td>-0.141025</td>\n",
       "      <td>-0.114510</td>\n",
       "      <td>-0.097640</td>\n",
       "      <td>-0.086547</td>\n",
       "      <td>-0.078946</td>\n",
       "      <td>-0.073508</td>\n",
       "      <td>-0.069454</td>\n",
       "      <td>-0.066312</td>\n",
       "      <td>-0.063793</td>\n",
       "      <td>-0.061712</td>\n",
       "      <td>-0.059951</td>\n",
       "      <td>-0.058429</td>\n",
       "      <td>-0.057093</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>-0.054837</td>\n",
       "      <td>-0.053870</td>\n",
       "      <td>-0.052990</td>\n",
       "      <td>-0.052184</td>\n",
       "      <td>0.962322</td>\n",
       "      <td>0.741098</td>\n",
       "      <td>0.510748</td>\n",
       "      <td>0.310799</td>\n",
       "      <td>0.154067</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>-0.040461</td>\n",
       "      <td>-0.093248</td>\n",
       "      <td>-0.126343</td>\n",
       "      <td>-0.145595</td>\n",
       "      <td>-0.155422</td>\n",
       "      <td>-0.159031</td>\n",
       "      <td>-0.158674</td>\n",
       "      <td>-0.155901</td>\n",
       "      <td>-0.151748</td>\n",
       "      <td>-0.146897</td>\n",
       "      <td>-0.141783</td>\n",
       "      <td>-0.136678</td>\n",
       "      <td>-0.131742</td>\n",
       "      <td>-0.127063</td>\n",
       "      <td>-0.122684</td>\n",
       "      <td>-0.118620</td>\n",
       "      <td>-0.293198</td>\n",
       "      <td>-0.305249</td>\n",
       "      <td>-0.284855</td>\n",
       "      <td>-0.245668</td>\n",
       "      <td>-0.202073</td>\n",
       "      <td>-0.163165</td>\n",
       "      <td>-0.132238</td>\n",
       "      <td>-0.109112</td>\n",
       "      <td>-0.092297</td>\n",
       "      <td>-0.080164</td>\n",
       "      <td>-0.071368</td>\n",
       "      <td>-0.064917</td>\n",
       "      <td>-0.060114</td>\n",
       "      <td>-0.056481</td>\n",
       "      <td>-0.053692</td>\n",
       "      <td>-0.051519</td>\n",
       "      <td>-0.049805</td>\n",
       "      <td>-0.048438</td>\n",
       "      <td>-0.047337</td>\n",
       "      <td>-0.046444</td>\n",
       "      <td>-0.045713</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>0.151865</td>\n",
       "      <td>0.035986</td>\n",
       "      <td>-0.045181</td>\n",
       "      <td>-0.084802</td>\n",
       "      <td>-0.094018</td>\n",
       "      <td>-0.088561</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.069571</td>\n",
       "      <td>-0.062133</td>\n",
       "      <td>-0.056608</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>-0.049829</td>\n",
       "      <td>-0.047833</td>\n",
       "      <td>-0.046406</td>\n",
       "      <td>-0.045373</td>\n",
       "      <td>-0.044613</td>\n",
       "      <td>-0.044047</td>\n",
       "      <td>-0.043618</td>\n",
       "      <td>-0.043288</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>-0.042669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>1.228676</td>\n",
       "      <td>-0.780083</td>\n",
       "      <td>0.850928</td>\n",
       "      <td>1.181336</td>\n",
       "      <td>-0.297005</td>\n",
       "      <td>0.814974</td>\n",
       "      <td>0.213076</td>\n",
       "      <td>1.424827</td>\n",
       "      <td>0.237036</td>\n",
       "      <td>0.293559</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>1.562343</td>\n",
       "      <td>1.463532</td>\n",
       "      <td>1.297010</td>\n",
       "      <td>1.088113</td>\n",
       "      <td>0.866659</td>\n",
       "      <td>0.657956</td>\n",
       "      <td>0.477420</td>\n",
       "      <td>0.330613</td>\n",
       "      <td>0.216391</td>\n",
       "      <td>0.130297</td>\n",
       "      <td>0.066914</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>-0.011467</td>\n",
       "      <td>-0.034286</td>\n",
       "      <td>-0.050011</td>\n",
       "      <td>-0.060638</td>\n",
       "      <td>-0.067640</td>\n",
       "      <td>-0.072087</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.076185</td>\n",
       "      <td>-0.076779</td>\n",
       "      <td>-0.076811</td>\n",
       "      <td>0.338964</td>\n",
       "      <td>0.213212</td>\n",
       "      <td>0.096099</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>-0.062965</td>\n",
       "      <td>-0.098881</td>\n",
       "      <td>-0.112802</td>\n",
       "      <td>-0.112959</td>\n",
       "      <td>-0.106123</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>-0.087163</td>\n",
       "      <td>-0.078573</td>\n",
       "      <td>-0.071315</td>\n",
       "      <td>-0.065390</td>\n",
       "      <td>-0.060647</td>\n",
       "      <td>-0.056889</td>\n",
       "      <td>-0.053923</td>\n",
       "      <td>-0.051586</td>\n",
       "      <td>-0.049740</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>-0.047112</td>\n",
       "      <td>-0.046180</td>\n",
       "      <td>1.534999</td>\n",
       "      <td>1.414711</td>\n",
       "      <td>1.224659</td>\n",
       "      <td>0.997317</td>\n",
       "      <td>0.767293</td>\n",
       "      <td>0.560191</td>\n",
       "      <td>0.388515</td>\n",
       "      <td>0.254192</td>\n",
       "      <td>0.153248</td>\n",
       "      <td>0.079547</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>-0.010030</td>\n",
       "      <td>-0.035501</td>\n",
       "      <td>-0.052757</td>\n",
       "      <td>-0.064204</td>\n",
       "      <td>-0.071588</td>\n",
       "      <td>-0.076160</td>\n",
       "      <td>-0.078809</td>\n",
       "      <td>-0.080158</td>\n",
       "      <td>-0.080642</td>\n",
       "      <td>-0.080561</td>\n",
       "      <td>-0.080122</td>\n",
       "      <td>1.285095</td>\n",
       "      <td>0.839977</td>\n",
       "      <td>0.444987</td>\n",
       "      <td>0.190014</td>\n",
       "      <td>0.050845</td>\n",
       "      <td>-0.018395</td>\n",
       "      <td>-0.050575</td>\n",
       "      <td>-0.064387</td>\n",
       "      <td>-0.069515</td>\n",
       "      <td>-0.070735</td>\n",
       "      <td>-0.070319</td>\n",
       "      <td>-0.069314</td>\n",
       "      <td>-0.068177</td>\n",
       "      <td>-0.067093</td>\n",
       "      <td>-0.066126</td>\n",
       "      <td>-0.065287</td>\n",
       "      <td>-0.064565</td>\n",
       "      <td>-0.063946</td>\n",
       "      <td>-0.063413</td>\n",
       "      <td>-0.062952</td>\n",
       "      <td>-0.062552</td>\n",
       "      <td>-0.062203</td>\n",
       "      <td>0.898163</td>\n",
       "      <td>0.826294</td>\n",
       "      <td>0.729590</td>\n",
       "      <td>0.614294</td>\n",
       "      <td>0.489982</td>\n",
       "      <td>0.367941</td>\n",
       "      <td>0.258214</td>\n",
       "      <td>0.167056</td>\n",
       "      <td>0.096276</td>\n",
       "      <td>0.044313</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>-0.016563</td>\n",
       "      <td>-0.032362</td>\n",
       "      <td>-0.042106</td>\n",
       "      <td>-0.047759</td>\n",
       "      <td>-0.050729</td>\n",
       "      <td>-0.051995</td>\n",
       "      <td>-0.052218</td>\n",
       "      <td>-0.051833</td>\n",
       "      <td>-0.051125</td>\n",
       "      <td>-0.050270</td>\n",
       "      <td>-0.049376</td>\n",
       "      <td>0.798208</td>\n",
       "      <td>0.481731</td>\n",
       "      <td>0.221821</td>\n",
       "      <td>0.053954</td>\n",
       "      <td>-0.037289</td>\n",
       "      <td>-0.079180</td>\n",
       "      <td>-0.093787</td>\n",
       "      <td>-0.095055</td>\n",
       "      <td>-0.090674</td>\n",
       "      <td>-0.084483</td>\n",
       "      <td>-0.078220</td>\n",
       "      <td>-0.072565</td>\n",
       "      <td>-0.067709</td>\n",
       "      <td>-0.063635</td>\n",
       "      <td>-0.060251</td>\n",
       "      <td>-0.057447</td>\n",
       "      <td>-0.055123</td>\n",
       "      <td>-0.053190</td>\n",
       "      <td>-0.051578</td>\n",
       "      <td>-0.050227</td>\n",
       "      <td>-0.049090</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>1.000988</td>\n",
       "      <td>0.551075</td>\n",
       "      <td>0.230745</td>\n",
       "      <td>0.048483</td>\n",
       "      <td>-0.042569</td>\n",
       "      <td>-0.083101</td>\n",
       "      <td>-0.098256</td>\n",
       "      <td>-0.101623</td>\n",
       "      <td>-0.100001</td>\n",
       "      <td>-0.096602</td>\n",
       "      <td>-0.092849</td>\n",
       "      <td>-0.089316</td>\n",
       "      <td>-0.086195</td>\n",
       "      <td>-0.083511</td>\n",
       "      <td>-0.081227</td>\n",
       "      <td>-0.079287</td>\n",
       "      <td>-0.077634</td>\n",
       "      <td>-0.076218</td>\n",
       "      <td>-0.074998</td>\n",
       "      <td>-0.073939</td>\n",
       "      <td>-0.073013</td>\n",
       "      <td>-0.072196</td>\n",
       "      <td>2.119005</td>\n",
       "      <td>1.827226</td>\n",
       "      <td>1.403311</td>\n",
       "      <td>1.000015</td>\n",
       "      <td>0.673477</td>\n",
       "      <td>0.429884</td>\n",
       "      <td>0.256843</td>\n",
       "      <td>0.137895</td>\n",
       "      <td>0.058122</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>-0.027955</td>\n",
       "      <td>-0.049104</td>\n",
       "      <td>-0.061956</td>\n",
       "      <td>-0.069387</td>\n",
       "      <td>-0.073320</td>\n",
       "      <td>-0.075027</td>\n",
       "      <td>-0.075340</td>\n",
       "      <td>-0.074802</td>\n",
       "      <td>-0.073762</td>\n",
       "      <td>-0.072444</td>\n",
       "      <td>-0.070987</td>\n",
       "      <td>-0.069481</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.785477</td>\n",
       "      <td>0.673811</td>\n",
       "      <td>0.550886</td>\n",
       "      <td>0.427059</td>\n",
       "      <td>0.311518</td>\n",
       "      <td>0.210714</td>\n",
       "      <td>0.127801</td>\n",
       "      <td>0.063055</td>\n",
       "      <td>0.014792</td>\n",
       "      <td>-0.019652</td>\n",
       "      <td>-0.043177</td>\n",
       "      <td>-0.058468</td>\n",
       "      <td>-0.067783</td>\n",
       "      <td>-0.072907</td>\n",
       "      <td>-0.075188</td>\n",
       "      <td>-0.075607</td>\n",
       "      <td>-0.074859</td>\n",
       "      <td>-0.073424</td>\n",
       "      <td>-0.071624</td>\n",
       "      <td>-0.069671</td>\n",
       "      <td>-0.067698</td>\n",
       "      <td>-0.413104</td>\n",
       "      <td>-0.417446</td>\n",
       "      <td>-0.410757</td>\n",
       "      <td>-0.393930</td>\n",
       "      <td>-0.369024</td>\n",
       "      <td>-0.338880</td>\n",
       "      <td>-0.306495</td>\n",
       "      <td>-0.274439</td>\n",
       "      <td>-0.244532</td>\n",
       "      <td>-0.217805</td>\n",
       "      <td>-0.194651</td>\n",
       "      <td>-0.175026</td>\n",
       "      <td>-0.158638</td>\n",
       "      <td>-0.145083</td>\n",
       "      <td>-0.133928</td>\n",
       "      <td>-0.124767</td>\n",
       "      <td>-0.117237</td>\n",
       "      <td>-0.111028</td>\n",
       "      <td>-0.105885</td>\n",
       "      <td>-0.101598</td>\n",
       "      <td>-0.097997</td>\n",
       "      <td>-0.094946</td>\n",
       "      <td>0.604361</td>\n",
       "      <td>0.151155</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>-0.046868</td>\n",
       "      <td>-0.055214</td>\n",
       "      <td>-0.055756</td>\n",
       "      <td>-0.054729</td>\n",
       "      <td>-0.053538</td>\n",
       "      <td>-0.052434</td>\n",
       "      <td>-0.051436</td>\n",
       "      <td>-0.050526</td>\n",
       "      <td>-0.049691</td>\n",
       "      <td>-0.048924</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>-0.047580</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>-0.046467</td>\n",
       "      <td>-0.045988</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.044506</td>\n",
       "      <td>-0.596968</td>\n",
       "      <td>-0.380362</td>\n",
       "      <td>-0.226845</td>\n",
       "      <td>-0.142484</td>\n",
       "      <td>-0.099512</td>\n",
       "      <td>-0.077141</td>\n",
       "      <td>-0.064768</td>\n",
       "      <td>-0.057448</td>\n",
       "      <td>-0.052849</td>\n",
       "      <td>-0.049813</td>\n",
       "      <td>-0.04773</td>\n",
       "      <td>-0.04626</td>\n",
       "      <td>-0.045198</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>-0.043837</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>-0.042625</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042362</td>\n",
       "      <td>-0.042274</td>\n",
       "      <td>0.300216</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>-0.050113</td>\n",
       "      <td>-0.058704</td>\n",
       "      <td>-0.056805</td>\n",
       "      <td>-0.054185</td>\n",
       "      <td>-0.052140</td>\n",
       "      <td>-0.050578</td>\n",
       "      <td>-0.049326</td>\n",
       "      <td>-0.048280</td>\n",
       "      <td>-0.047387</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-0.045374</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>-0.044451</td>\n",
       "      <td>-0.044084</td>\n",
       "      <td>-0.04377</td>\n",
       "      <td>-0.043501</td>\n",
       "      <td>-0.043272</td>\n",
       "      <td>-0.043076</td>\n",
       "      <td>-0.042909</td>\n",
       "      <td>0.291306</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>-0.051350</td>\n",
       "      <td>-0.058841</td>\n",
       "      <td>-0.059452</td>\n",
       "      <td>-0.059245</td>\n",
       "      <td>-0.059032</td>\n",
       "      <td>-0.058862</td>\n",
       "      <td>-0.058711</td>\n",
       "      <td>-0.058561</td>\n",
       "      <td>-0.058406</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>-0.058069</td>\n",
       "      <td>-0.057887</td>\n",
       "      <td>-0.057696</td>\n",
       "      <td>-0.057498</td>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.057078</td>\n",
       "      <td>-0.056858</td>\n",
       "      <td>-0.056632</td>\n",
       "      <td>-0.056402</td>\n",
       "      <td>-0.056167</td>\n",
       "      <td>-0.307945</td>\n",
       "      <td>-0.228973</td>\n",
       "      <td>-0.148640</td>\n",
       "      <td>-0.099733</td>\n",
       "      <td>-0.074149</td>\n",
       "      <td>-0.060901</td>\n",
       "      <td>-0.053723</td>\n",
       "      <td>-0.049591</td>\n",
       "      <td>-0.047074</td>\n",
       "      <td>-0.045468</td>\n",
       "      <td>-0.044406</td>\n",
       "      <td>-0.043687</td>\n",
       "      <td>-0.043190</td>\n",
       "      <td>-0.042842</td>\n",
       "      <td>-0.042596</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.042294</td>\n",
       "      <td>-0.042204</td>\n",
       "      <td>-0.042138</td>\n",
       "      <td>-0.04209</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>-0.04203</td>\n",
       "      <td>0.389564</td>\n",
       "      <td>0.077045</td>\n",
       "      <td>-0.057137</td>\n",
       "      <td>-0.090908</td>\n",
       "      <td>-0.088438</td>\n",
       "      <td>-0.077866</td>\n",
       "      <td>-0.067959</td>\n",
       "      <td>-0.060443</td>\n",
       "      <td>-0.055091</td>\n",
       "      <td>-0.051343</td>\n",
       "      <td>-0.048717</td>\n",
       "      <td>-0.046863</td>\n",
       "      <td>-0.045543</td>\n",
       "      <td>-0.044596</td>\n",
       "      <td>-0.043910</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.042772</td>\n",
       "      <td>-0.042571</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042309</td>\n",
       "      <td>-0.042225</td>\n",
       "      <td>-0.057633</td>\n",
       "      <td>-0.070913</td>\n",
       "      <td>-0.059475</td>\n",
       "      <td>-0.053310</td>\n",
       "      <td>-0.050134</td>\n",
       "      <td>-0.048154</td>\n",
       "      <td>-0.046736</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>-0.044175</td>\n",
       "      <td>-0.04367</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.04274</td>\n",
       "      <td>-0.04256</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042314</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>-0.042168</td>\n",
       "      <td>-0.04212</td>\n",
       "      <td>-0.042082</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>1.132912</td>\n",
       "      <td>0.634639</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>0.072932</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>-0.037566</td>\n",
       "      <td>-0.046928</td>\n",
       "      <td>-0.048738</td>\n",
       "      <td>-0.048111</td>\n",
       "      <td>-0.046917</td>\n",
       "      <td>-0.045773</td>\n",
       "      <td>-0.044838</td>\n",
       "      <td>-0.044118</td>\n",
       "      <td>-0.043575</td>\n",
       "      <td>-0.043171</td>\n",
       "      <td>-0.042869</td>\n",
       "      <td>-0.042645</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042351</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>-0.042131</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>-0.088036</td>\n",
       "      <td>-0.120888</td>\n",
       "      <td>-0.112208</td>\n",
       "      <td>-0.094182</td>\n",
       "      <td>-0.078519</td>\n",
       "      <td>-0.067210</td>\n",
       "      <td>-0.059485</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>-0.050692</td>\n",
       "      <td>-0.048227</td>\n",
       "      <td>-0.046499</td>\n",
       "      <td>-0.045273</td>\n",
       "      <td>-0.044394</td>\n",
       "      <td>-0.043758</td>\n",
       "      <td>-0.043294</td>\n",
       "      <td>-0.042954</td>\n",
       "      <td>-0.042703</td>\n",
       "      <td>-0.042517</td>\n",
       "      <td>-0.042379</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>-0.042199</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>-0.083129</td>\n",
       "      <td>-0.078760</td>\n",
       "      <td>-0.067425</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.054457</td>\n",
       "      <td>-0.051064</td>\n",
       "      <td>-0.048687</td>\n",
       "      <td>-0.046970</td>\n",
       "      <td>-0.045708</td>\n",
       "      <td>-0.044771</td>\n",
       "      <td>-0.044072</td>\n",
       "      <td>-0.043549</td>\n",
       "      <td>-0.043157</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>-0.04264</td>\n",
       "      <td>-0.042473</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>-0.042253</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.042127</td>\n",
       "      <td>-0.042086</td>\n",
       "      <td>1.443686</td>\n",
       "      <td>1.290070</td>\n",
       "      <td>1.078309</td>\n",
       "      <td>0.844533</td>\n",
       "      <td>0.621236</td>\n",
       "      <td>0.429078</td>\n",
       "      <td>0.275983</td>\n",
       "      <td>0.160884</td>\n",
       "      <td>0.078193</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>-0.017129</td>\n",
       "      <td>-0.041618</td>\n",
       "      <td>-0.056608</td>\n",
       "      <td>-0.065167</td>\n",
       "      <td>-0.069482</td>\n",
       "      <td>-0.071075</td>\n",
       "      <td>-0.070980</td>\n",
       "      <td>-0.069887</td>\n",
       "      <td>-0.068248</td>\n",
       "      <td>-0.066350</td>\n",
       "      <td>-0.064375</td>\n",
       "      <td>-0.062429</td>\n",
       "      <td>-0.133771</td>\n",
       "      <td>-0.219743</td>\n",
       "      <td>-0.273838</td>\n",
       "      <td>-0.296086</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.273551</td>\n",
       "      <td>-0.246463</td>\n",
       "      <td>-0.217744</td>\n",
       "      <td>-0.190887</td>\n",
       "      <td>-0.167436</td>\n",
       "      <td>-0.147748</td>\n",
       "      <td>-0.131573</td>\n",
       "      <td>-0.118421</td>\n",
       "      <td>-0.107756</td>\n",
       "      <td>-0.099086</td>\n",
       "      <td>-0.091998</td>\n",
       "      <td>-0.086155</td>\n",
       "      <td>-0.081295</td>\n",
       "      <td>-0.077212</td>\n",
       "      <td>-0.073748</td>\n",
       "      <td>-0.070780</td>\n",
       "      <td>-0.068214</td>\n",
       "      <td>1.234909</td>\n",
       "      <td>1.043160</td>\n",
       "      <td>0.810070</td>\n",
       "      <td>0.577228</td>\n",
       "      <td>0.375171</td>\n",
       "      <td>0.217623</td>\n",
       "      <td>0.104640</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>-0.018611</td>\n",
       "      <td>-0.046690</td>\n",
       "      <td>-0.061927</td>\n",
       "      <td>-0.069116</td>\n",
       "      <td>-0.071497</td>\n",
       "      <td>-0.071160</td>\n",
       "      <td>-0.069404</td>\n",
       "      <td>-0.067006</td>\n",
       "      <td>-0.064415</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.059511</td>\n",
       "      <td>-0.057372</td>\n",
       "      <td>-0.055472</td>\n",
       "      <td>-0.053801</td>\n",
       "      <td>1.075141</td>\n",
       "      <td>0.594656</td>\n",
       "      <td>0.244852</td>\n",
       "      <td>0.058910</td>\n",
       "      <td>-0.022014</td>\n",
       "      <td>-0.051414</td>\n",
       "      <td>-0.059111</td>\n",
       "      <td>-0.058816</td>\n",
       "      <td>-0.056161</td>\n",
       "      <td>-0.053230</td>\n",
       "      <td>-0.050682</td>\n",
       "      <td>-0.048643</td>\n",
       "      <td>-0.047068</td>\n",
       "      <td>-0.045867</td>\n",
       "      <td>-0.044955</td>\n",
       "      <td>-0.044262</td>\n",
       "      <td>-0.043735</td>\n",
       "      <td>-0.043333</td>\n",
       "      <td>-0.043025</td>\n",
       "      <td>-0.042788</td>\n",
       "      <td>-0.042605</td>\n",
       "      <td>-0.042463</td>\n",
       "      <td>0.445589</td>\n",
       "      <td>0.350423</td>\n",
       "      <td>0.250649</td>\n",
       "      <td>0.155176</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>-0.046938</td>\n",
       "      <td>-0.081399</td>\n",
       "      <td>-0.102654</td>\n",
       "      <td>-0.113952</td>\n",
       "      <td>-0.118302</td>\n",
       "      <td>-0.118148</td>\n",
       "      <td>-0.115308</td>\n",
       "      <td>-0.111045</td>\n",
       "      <td>-0.106185</td>\n",
       "      <td>-0.101242</td>\n",
       "      <td>-0.096509</td>\n",
       "      <td>-0.092140</td>\n",
       "      <td>-0.088196</td>\n",
       "      <td>-0.084687</td>\n",
       "      <td>-0.081594</td>\n",
       "      <td>-0.078879</td>\n",
       "      <td>0.735554</td>\n",
       "      <td>0.357051</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>-0.020801</td>\n",
       "      <td>-0.073458</td>\n",
       "      <td>-0.089926</td>\n",
       "      <td>-0.091088</td>\n",
       "      <td>-0.086733</td>\n",
       "      <td>-0.080994</td>\n",
       "      <td>-0.075433</td>\n",
       "      <td>-0.070531</td>\n",
       "      <td>-0.066361</td>\n",
       "      <td>-0.062851</td>\n",
       "      <td>-0.059902</td>\n",
       "      <td>-0.057416</td>\n",
       "      <td>-0.055312</td>\n",
       "      <td>-0.053522</td>\n",
       "      <td>-0.051993</td>\n",
       "      <td>-0.050683</td>\n",
       "      <td>-0.049556</td>\n",
       "      <td>-0.048583</td>\n",
       "      <td>-0.047743</td>\n",
       "      <td>0.484894</td>\n",
       "      <td>0.155672</td>\n",
       "      <td>-0.021550</td>\n",
       "      <td>-0.088479</td>\n",
       "      <td>-0.103528</td>\n",
       "      <td>-0.100124</td>\n",
       "      <td>-0.092223</td>\n",
       "      <td>-0.084531</td>\n",
       "      <td>-0.078200</td>\n",
       "      <td>-0.073234</td>\n",
       "      <td>-0.069353</td>\n",
       "      <td>-0.066275</td>\n",
       "      <td>-0.063780</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.059949</td>\n",
       "      <td>-0.058429</td>\n",
       "      <td>-0.057093</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>-0.054837</td>\n",
       "      <td>-0.053870</td>\n",
       "      <td>-0.052990</td>\n",
       "      <td>-0.052184</td>\n",
       "      <td>2.334569</td>\n",
       "      <td>2.514401</td>\n",
       "      <td>2.545055</td>\n",
       "      <td>2.467157</td>\n",
       "      <td>2.318299</td>\n",
       "      <td>2.128547</td>\n",
       "      <td>1.919724</td>\n",
       "      <td>1.706768</td>\n",
       "      <td>1.499452</td>\n",
       "      <td>1.303848</td>\n",
       "      <td>1.123423</td>\n",
       "      <td>0.959837</td>\n",
       "      <td>0.813517</td>\n",
       "      <td>0.684070</td>\n",
       "      <td>0.570587</td>\n",
       "      <td>0.471854</td>\n",
       "      <td>0.386508</td>\n",
       "      <td>0.313144</td>\n",
       "      <td>0.250383</td>\n",
       "      <td>0.196920</td>\n",
       "      <td>0.151549</td>\n",
       "      <td>0.113176</td>\n",
       "      <td>1.011557</td>\n",
       "      <td>0.801203</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.353222</td>\n",
       "      <td>0.190087</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>-0.024798</td>\n",
       "      <td>-0.044230</td>\n",
       "      <td>-0.053116</td>\n",
       "      <td>-0.056287</td>\n",
       "      <td>-0.056562</td>\n",
       "      <td>-0.055507</td>\n",
       "      <td>-0.053950</td>\n",
       "      <td>-0.052304</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>-0.049390</td>\n",
       "      <td>-0.048211</td>\n",
       "      <td>-0.047214</td>\n",
       "      <td>-0.046376</td>\n",
       "      <td>-0.045676</td>\n",
       "      <td>-0.045092</td>\n",
       "      <td>0.081905</td>\n",
       "      <td>-0.018774</td>\n",
       "      <td>-0.082756</td>\n",
       "      <td>-0.107567</td>\n",
       "      <td>-0.106564</td>\n",
       "      <td>-0.095058</td>\n",
       "      <td>-0.082089</td>\n",
       "      <td>-0.071140</td>\n",
       "      <td>-0.062881</td>\n",
       "      <td>-0.056960</td>\n",
       "      <td>-0.052806</td>\n",
       "      <td>-0.049904</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.046422</td>\n",
       "      <td>-0.045380</td>\n",
       "      <td>-0.044617</td>\n",
       "      <td>-0.044048</td>\n",
       "      <td>-0.043619</td>\n",
       "      <td>-0.043288</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>-0.042669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>0.326373</td>\n",
       "      <td>-0.110409</td>\n",
       "      <td>0.286593</td>\n",
       "      <td>-0.288378</td>\n",
       "      <td>0.689702</td>\n",
       "      <td>2.744280</td>\n",
       "      <td>0.819518</td>\n",
       "      <td>1.115007</td>\n",
       "      <td>4.732680</td>\n",
       "      <td>2.047511</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>-0.725173</td>\n",
       "      <td>-0.653462</td>\n",
       "      <td>-0.567568</td>\n",
       "      <td>-0.479758</td>\n",
       "      <td>-0.398966</td>\n",
       "      <td>-0.330044</td>\n",
       "      <td>-0.274256</td>\n",
       "      <td>-0.230566</td>\n",
       "      <td>-0.196948</td>\n",
       "      <td>-0.171241</td>\n",
       "      <td>-0.151555</td>\n",
       "      <td>-0.136383</td>\n",
       "      <td>-0.124578</td>\n",
       "      <td>-0.115288</td>\n",
       "      <td>-0.107888</td>\n",
       "      <td>-0.101917</td>\n",
       "      <td>-0.097036</td>\n",
       "      <td>-0.092995</td>\n",
       "      <td>-0.089606</td>\n",
       "      <td>-0.086729</td>\n",
       "      <td>-0.084257</td>\n",
       "      <td>-0.082111</td>\n",
       "      <td>0.137726</td>\n",
       "      <td>0.027448</td>\n",
       "      <td>-0.062853</td>\n",
       "      <td>-0.124360</td>\n",
       "      <td>-0.155893</td>\n",
       "      <td>-0.163128</td>\n",
       "      <td>-0.154942</td>\n",
       "      <td>-0.139502</td>\n",
       "      <td>-0.122349</td>\n",
       "      <td>-0.106420</td>\n",
       "      <td>-0.092873</td>\n",
       "      <td>-0.081893</td>\n",
       "      <td>-0.073227</td>\n",
       "      <td>-0.066484</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>-0.057240</td>\n",
       "      <td>-0.054122</td>\n",
       "      <td>-0.051697</td>\n",
       "      <td>-0.049802</td>\n",
       "      <td>-0.048311</td>\n",
       "      <td>-0.047131</td>\n",
       "      <td>-0.046191</td>\n",
       "      <td>-0.592131</td>\n",
       "      <td>-0.555405</td>\n",
       "      <td>-0.495193</td>\n",
       "      <td>-0.425392</td>\n",
       "      <td>-0.357384</td>\n",
       "      <td>-0.297950</td>\n",
       "      <td>-0.249471</td>\n",
       "      <td>-0.211510</td>\n",
       "      <td>-0.182395</td>\n",
       "      <td>-0.160223</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>-0.130307</td>\n",
       "      <td>-0.120205</td>\n",
       "      <td>-0.112254</td>\n",
       "      <td>-0.105909</td>\n",
       "      <td>-0.100773</td>\n",
       "      <td>-0.096556</td>\n",
       "      <td>-0.093046</td>\n",
       "      <td>-0.090087</td>\n",
       "      <td>-0.087560</td>\n",
       "      <td>-0.085378</td>\n",
       "      <td>-0.083474</td>\n",
       "      <td>-0.579465</td>\n",
       "      <td>-0.394036</td>\n",
       "      <td>-0.261908</td>\n",
       "      <td>-0.182783</td>\n",
       "      <td>-0.137842</td>\n",
       "      <td>-0.111978</td>\n",
       "      <td>-0.096495</td>\n",
       "      <td>-0.086782</td>\n",
       "      <td>-0.080396</td>\n",
       "      <td>-0.076009</td>\n",
       "      <td>-0.072871</td>\n",
       "      <td>-0.070547</td>\n",
       "      <td>-0.068772</td>\n",
       "      <td>-0.067380</td>\n",
       "      <td>-0.066265</td>\n",
       "      <td>-0.065354</td>\n",
       "      <td>-0.064597</td>\n",
       "      <td>-0.063961</td>\n",
       "      <td>-0.063420</td>\n",
       "      <td>-0.062956</td>\n",
       "      <td>-0.062554</td>\n",
       "      <td>-0.062204</td>\n",
       "      <td>3.843300</td>\n",
       "      <td>4.411750</td>\n",
       "      <td>4.940936</td>\n",
       "      <td>5.370392</td>\n",
       "      <td>5.642512</td>\n",
       "      <td>5.723061</td>\n",
       "      <td>5.614041</td>\n",
       "      <td>5.349596</td>\n",
       "      <td>4.979493</td>\n",
       "      <td>4.552477</td>\n",
       "      <td>4.107039</td>\n",
       "      <td>3.669411</td>\n",
       "      <td>3.255402</td>\n",
       "      <td>2.873283</td>\n",
       "      <td>2.526373</td>\n",
       "      <td>2.214962</td>\n",
       "      <td>1.937602</td>\n",
       "      <td>1.691933</td>\n",
       "      <td>1.475198</td>\n",
       "      <td>1.284537</td>\n",
       "      <td>1.117167</td>\n",
       "      <td>0.970471</td>\n",
       "      <td>4.490525</td>\n",
       "      <td>5.230695</td>\n",
       "      <td>5.518465</td>\n",
       "      <td>5.419880</td>\n",
       "      <td>5.060489</td>\n",
       "      <td>4.558237</td>\n",
       "      <td>4.001367</td>\n",
       "      <td>3.447556</td>\n",
       "      <td>2.930148</td>\n",
       "      <td>2.465434</td>\n",
       "      <td>2.058808</td>\n",
       "      <td>1.709292</td>\n",
       "      <td>1.412561</td>\n",
       "      <td>1.162830</td>\n",
       "      <td>0.953957</td>\n",
       "      <td>0.780039</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.516198</td>\n",
       "      <td>0.417438</td>\n",
       "      <td>0.335932</td>\n",
       "      <td>0.268735</td>\n",
       "      <td>0.213382</td>\n",
       "      <td>1.782246</td>\n",
       "      <td>1.315557</td>\n",
       "      <td>0.845051</td>\n",
       "      <td>0.489679</td>\n",
       "      <td>0.253206</td>\n",
       "      <td>0.106453</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>-0.030005</td>\n",
       "      <td>-0.057140</td>\n",
       "      <td>-0.071249</td>\n",
       "      <td>-0.077984</td>\n",
       "      <td>-0.080659</td>\n",
       "      <td>-0.081179</td>\n",
       "      <td>-0.080617</td>\n",
       "      <td>-0.079562</td>\n",
       "      <td>-0.078332</td>\n",
       "      <td>-0.077087</td>\n",
       "      <td>-0.075906</td>\n",
       "      <td>-0.074820</td>\n",
       "      <td>-0.073838</td>\n",
       "      <td>-0.072955</td>\n",
       "      <td>-0.072163</td>\n",
       "      <td>1.219297</td>\n",
       "      <td>0.821822</td>\n",
       "      <td>0.468424</td>\n",
       "      <td>0.221047</td>\n",
       "      <td>0.067921</td>\n",
       "      <td>-0.019506</td>\n",
       "      <td>-0.065987</td>\n",
       "      <td>-0.088616</td>\n",
       "      <td>-0.098036</td>\n",
       "      <td>-0.100476</td>\n",
       "      <td>-0.099434</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.093564</td>\n",
       "      <td>-0.090213</td>\n",
       "      <td>-0.086975</td>\n",
       "      <td>-0.083943</td>\n",
       "      <td>-0.081142</td>\n",
       "      <td>-0.078567</td>\n",
       "      <td>-0.076198</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.072001</td>\n",
       "      <td>-0.070133</td>\n",
       "      <td>3.213718</td>\n",
       "      <td>3.518282</td>\n",
       "      <td>3.752626</td>\n",
       "      <td>3.893384</td>\n",
       "      <td>3.928255</td>\n",
       "      <td>3.858837</td>\n",
       "      <td>3.699122</td>\n",
       "      <td>3.470813</td>\n",
       "      <td>3.197880</td>\n",
       "      <td>2.902328</td>\n",
       "      <td>2.601905</td>\n",
       "      <td>2.309490</td>\n",
       "      <td>2.033516</td>\n",
       "      <td>1.778843</td>\n",
       "      <td>1.547700</td>\n",
       "      <td>1.340510</td>\n",
       "      <td>1.156536</td>\n",
       "      <td>0.994358</td>\n",
       "      <td>0.852196</td>\n",
       "      <td>0.728127</td>\n",
       "      <td>0.620229</td>\n",
       "      <td>0.526659</td>\n",
       "      <td>5.760674</td>\n",
       "      <td>6.702479</td>\n",
       "      <td>7.704943</td>\n",
       "      <td>8.725247</td>\n",
       "      <td>9.717738</td>\n",
       "      <td>10.644172</td>\n",
       "      <td>11.480753</td>\n",
       "      <td>12.219357</td>\n",
       "      <td>12.864032</td>\n",
       "      <td>13.425793</td>\n",
       "      <td>13.918119</td>\n",
       "      <td>14.354104</td>\n",
       "      <td>14.745089</td>\n",
       "      <td>15.100281</td>\n",
       "      <td>15.426875</td>\n",
       "      <td>15.730371</td>\n",
       "      <td>16.014932</td>\n",
       "      <td>16.283696</td>\n",
       "      <td>16.539036</td>\n",
       "      <td>16.782757</td>\n",
       "      <td>17.016241</td>\n",
       "      <td>17.240563</td>\n",
       "      <td>0.008994</td>\n",
       "      <td>-0.082806</td>\n",
       "      <td>-0.079888</td>\n",
       "      <td>-0.068316</td>\n",
       "      <td>-0.061214</td>\n",
       "      <td>-0.057397</td>\n",
       "      <td>-0.055171</td>\n",
       "      <td>-0.053655</td>\n",
       "      <td>-0.052466</td>\n",
       "      <td>-0.051444</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>-0.049691</td>\n",
       "      <td>-0.048924</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>-0.047580</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>-0.046467</td>\n",
       "      <td>-0.045988</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.044506</td>\n",
       "      <td>-0.229595</td>\n",
       "      <td>-0.231297</td>\n",
       "      <td>-0.178729</td>\n",
       "      <td>-0.128925</td>\n",
       "      <td>-0.095962</td>\n",
       "      <td>-0.076248</td>\n",
       "      <td>-0.064548</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.052836</td>\n",
       "      <td>-0.049810</td>\n",
       "      <td>-0.04773</td>\n",
       "      <td>-0.04626</td>\n",
       "      <td>-0.045197</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>-0.043837</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>-0.042625</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042362</td>\n",
       "      <td>-0.042274</td>\n",
       "      <td>-0.014688</td>\n",
       "      <td>-0.085827</td>\n",
       "      <td>-0.077334</td>\n",
       "      <td>-0.065268</td>\n",
       "      <td>-0.058317</td>\n",
       "      <td>-0.054524</td>\n",
       "      <td>-0.052214</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.049329</td>\n",
       "      <td>-0.048281</td>\n",
       "      <td>-0.047387</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-0.045374</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>-0.044451</td>\n",
       "      <td>-0.044084</td>\n",
       "      <td>-0.04377</td>\n",
       "      <td>-0.043501</td>\n",
       "      <td>-0.043272</td>\n",
       "      <td>-0.043076</td>\n",
       "      <td>-0.042909</td>\n",
       "      <td>-0.166984</td>\n",
       "      <td>-0.088874</td>\n",
       "      <td>-0.067431</td>\n",
       "      <td>-0.061683</td>\n",
       "      <td>-0.059952</td>\n",
       "      <td>-0.059333</td>\n",
       "      <td>-0.059048</td>\n",
       "      <td>-0.058865</td>\n",
       "      <td>-0.058711</td>\n",
       "      <td>-0.058561</td>\n",
       "      <td>-0.058406</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>-0.058069</td>\n",
       "      <td>-0.057887</td>\n",
       "      <td>-0.057696</td>\n",
       "      <td>-0.057498</td>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.057078</td>\n",
       "      <td>-0.056858</td>\n",
       "      <td>-0.056632</td>\n",
       "      <td>-0.056402</td>\n",
       "      <td>-0.056167</td>\n",
       "      <td>0.362335</td>\n",
       "      <td>0.095963</td>\n",
       "      <td>-0.024644</td>\n",
       "      <td>-0.057979</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>-0.056848</td>\n",
       "      <td>-0.052503</td>\n",
       "      <td>-0.049228</td>\n",
       "      <td>-0.046966</td>\n",
       "      <td>-0.045436</td>\n",
       "      <td>-0.044397</td>\n",
       "      <td>-0.043684</td>\n",
       "      <td>-0.043189</td>\n",
       "      <td>-0.042842</td>\n",
       "      <td>-0.042596</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.042294</td>\n",
       "      <td>-0.042204</td>\n",
       "      <td>-0.042138</td>\n",
       "      <td>-0.04209</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>-0.04203</td>\n",
       "      <td>2.815338</td>\n",
       "      <td>2.252833</td>\n",
       "      <td>1.523076</td>\n",
       "      <td>0.922499</td>\n",
       "      <td>0.517459</td>\n",
       "      <td>0.270843</td>\n",
       "      <td>0.128691</td>\n",
       "      <td>0.049261</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>-0.017700</td>\n",
       "      <td>-0.030146</td>\n",
       "      <td>-0.036622</td>\n",
       "      <td>-0.039899</td>\n",
       "      <td>-0.041486</td>\n",
       "      <td>-0.042196</td>\n",
       "      <td>-0.042466</td>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.042485</td>\n",
       "      <td>-0.042413</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>-0.042261</td>\n",
       "      <td>-0.042198</td>\n",
       "      <td>0.160671</td>\n",
       "      <td>-0.027202</td>\n",
       "      <td>-0.052030</td>\n",
       "      <td>-0.052128</td>\n",
       "      <td>-0.049953</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>-0.046732</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>-0.044175</td>\n",
       "      <td>-0.04367</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.04274</td>\n",
       "      <td>-0.04256</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042314</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>-0.042168</td>\n",
       "      <td>-0.04212</td>\n",
       "      <td>-0.042082</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>0.788197</td>\n",
       "      <td>0.374707</td>\n",
       "      <td>0.112009</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.043151</td>\n",
       "      <td>-0.053329</td>\n",
       "      <td>-0.053730</td>\n",
       "      <td>-0.051616</td>\n",
       "      <td>-0.049311</td>\n",
       "      <td>-0.047412</td>\n",
       "      <td>-0.045976</td>\n",
       "      <td>-0.044921</td>\n",
       "      <td>-0.044151</td>\n",
       "      <td>-0.043589</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>-0.042872</td>\n",
       "      <td>-0.042646</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042351</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>-0.042131</td>\n",
       "      <td>5.987146</td>\n",
       "      <td>6.417572</td>\n",
       "      <td>5.962052</td>\n",
       "      <td>5.043404</td>\n",
       "      <td>4.043356</td>\n",
       "      <td>3.147704</td>\n",
       "      <td>2.410992</td>\n",
       "      <td>1.829285</td>\n",
       "      <td>1.379334</td>\n",
       "      <td>1.035009</td>\n",
       "      <td>0.773018</td>\n",
       "      <td>0.574295</td>\n",
       "      <td>0.423825</td>\n",
       "      <td>0.310004</td>\n",
       "      <td>0.223954</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>0.109784</td>\n",
       "      <td>0.072661</td>\n",
       "      <td>0.044617</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>-0.004656</td>\n",
       "      <td>1.183350</td>\n",
       "      <td>0.429878</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>-0.039864</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>-0.049129</td>\n",
       "      <td>-0.048086</td>\n",
       "      <td>-0.046784</td>\n",
       "      <td>-0.045651</td>\n",
       "      <td>-0.044754</td>\n",
       "      <td>-0.044067</td>\n",
       "      <td>-0.043548</td>\n",
       "      <td>-0.043156</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>-0.04264</td>\n",
       "      <td>-0.042473</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>-0.042253</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.042127</td>\n",
       "      <td>-0.042086</td>\n",
       "      <td>-0.354515</td>\n",
       "      <td>-0.386317</td>\n",
       "      <td>-0.382477</td>\n",
       "      <td>-0.354740</td>\n",
       "      <td>-0.315531</td>\n",
       "      <td>-0.274235</td>\n",
       "      <td>-0.236206</td>\n",
       "      <td>-0.203597</td>\n",
       "      <td>-0.176670</td>\n",
       "      <td>-0.154822</td>\n",
       "      <td>-0.137189</td>\n",
       "      <td>-0.122927</td>\n",
       "      <td>-0.111318</td>\n",
       "      <td>-0.101788</td>\n",
       "      <td>-0.093893</td>\n",
       "      <td>-0.087292</td>\n",
       "      <td>-0.081723</td>\n",
       "      <td>-0.076988</td>\n",
       "      <td>-0.072933</td>\n",
       "      <td>-0.069436</td>\n",
       "      <td>-0.066405</td>\n",
       "      <td>-0.063764</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>-0.088962</td>\n",
       "      <td>-0.167180</td>\n",
       "      <td>-0.214741</td>\n",
       "      <td>-0.234473</td>\n",
       "      <td>-0.233610</td>\n",
       "      <td>-0.220274</td>\n",
       "      <td>-0.201127</td>\n",
       "      <td>-0.180614</td>\n",
       "      <td>-0.161214</td>\n",
       "      <td>-0.144041</td>\n",
       "      <td>-0.129393</td>\n",
       "      <td>-0.117153</td>\n",
       "      <td>-0.107025</td>\n",
       "      <td>-0.098668</td>\n",
       "      <td>-0.091760</td>\n",
       "      <td>-0.086021</td>\n",
       "      <td>-0.081220</td>\n",
       "      <td>-0.077170</td>\n",
       "      <td>-0.073724</td>\n",
       "      <td>-0.070767</td>\n",
       "      <td>-0.068207</td>\n",
       "      <td>-0.332068</td>\n",
       "      <td>-0.367998</td>\n",
       "      <td>-0.363894</td>\n",
       "      <td>-0.333727</td>\n",
       "      <td>-0.291987</td>\n",
       "      <td>-0.249090</td>\n",
       "      <td>-0.210548</td>\n",
       "      <td>-0.178276</td>\n",
       "      <td>-0.152228</td>\n",
       "      <td>-0.131557</td>\n",
       "      <td>-0.115236</td>\n",
       "      <td>-0.102328</td>\n",
       "      <td>-0.092061</td>\n",
       "      <td>-0.083834</td>\n",
       "      <td>-0.077188</td>\n",
       "      <td>-0.071774</td>\n",
       "      <td>-0.067330</td>\n",
       "      <td>-0.063655</td>\n",
       "      <td>-0.060596</td>\n",
       "      <td>-0.058033</td>\n",
       "      <td>-0.055874</td>\n",
       "      <td>-0.054046</td>\n",
       "      <td>-0.458432</td>\n",
       "      <td>-0.324060</td>\n",
       "      <td>-0.218619</td>\n",
       "      <td>-0.152411</td>\n",
       "      <td>-0.113148</td>\n",
       "      <td>-0.089530</td>\n",
       "      <td>-0.074782</td>\n",
       "      <td>-0.065198</td>\n",
       "      <td>-0.058745</td>\n",
       "      <td>-0.054273</td>\n",
       "      <td>-0.051102</td>\n",
       "      <td>-0.048812</td>\n",
       "      <td>-0.047136</td>\n",
       "      <td>-0.045894</td>\n",
       "      <td>-0.044966</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.043737</td>\n",
       "      <td>-0.043334</td>\n",
       "      <td>-0.043025</td>\n",
       "      <td>-0.042788</td>\n",
       "      <td>-0.042605</td>\n",
       "      <td>-0.042463</td>\n",
       "      <td>4.119513</td>\n",
       "      <td>4.893276</td>\n",
       "      <td>5.668602</td>\n",
       "      <td>6.390467</td>\n",
       "      <td>7.007684</td>\n",
       "      <td>7.484511</td>\n",
       "      <td>7.806672</td>\n",
       "      <td>7.979895</td>\n",
       "      <td>8.023386</td>\n",
       "      <td>7.962280</td>\n",
       "      <td>7.821877</td>\n",
       "      <td>7.624445</td>\n",
       "      <td>7.388057</td>\n",
       "      <td>7.126642</td>\n",
       "      <td>6.850579</td>\n",
       "      <td>6.567429</td>\n",
       "      <td>6.282608</td>\n",
       "      <td>5.999950</td>\n",
       "      <td>5.722128</td>\n",
       "      <td>5.450984</td>\n",
       "      <td>5.187753</td>\n",
       "      <td>4.933236</td>\n",
       "      <td>5.353306</td>\n",
       "      <td>6.126952</td>\n",
       "      <td>6.210295</td>\n",
       "      <td>5.855624</td>\n",
       "      <td>5.285596</td>\n",
       "      <td>4.639764</td>\n",
       "      <td>3.996275</td>\n",
       "      <td>3.395664</td>\n",
       "      <td>2.856417</td>\n",
       "      <td>2.384358</td>\n",
       "      <td>1.978263</td>\n",
       "      <td>1.633249</td>\n",
       "      <td>1.342798</td>\n",
       "      <td>1.099938</td>\n",
       "      <td>0.897906</td>\n",
       "      <td>0.730489</td>\n",
       "      <td>0.592166</td>\n",
       "      <td>0.478140</td>\n",
       "      <td>0.384308</td>\n",
       "      <td>0.307197</td>\n",
       "      <td>0.243897</td>\n",
       "      <td>0.191976</td>\n",
       "      <td>2.013415</td>\n",
       "      <td>1.585682</td>\n",
       "      <td>1.056719</td>\n",
       "      <td>0.628947</td>\n",
       "      <td>0.341391</td>\n",
       "      <td>0.164933</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>-0.028117</td>\n",
       "      <td>-0.045029</td>\n",
       "      <td>-0.053549</td>\n",
       "      <td>-0.057453</td>\n",
       "      <td>-0.058870</td>\n",
       "      <td>-0.058981</td>\n",
       "      <td>-0.058438</td>\n",
       "      <td>-0.057592</td>\n",
       "      <td>-0.056630</td>\n",
       "      <td>-0.055649</td>\n",
       "      <td>-0.054696</td>\n",
       "      <td>-0.053792</td>\n",
       "      <td>-0.052947</td>\n",
       "      <td>-0.052161</td>\n",
       "      <td>2.741830</td>\n",
       "      <td>3.124981</td>\n",
       "      <td>3.353247</td>\n",
       "      <td>3.450339</td>\n",
       "      <td>3.444936</td>\n",
       "      <td>3.364143</td>\n",
       "      <td>3.230465</td>\n",
       "      <td>3.061538</td>\n",
       "      <td>2.870852</td>\n",
       "      <td>2.668611</td>\n",
       "      <td>2.462451</td>\n",
       "      <td>2.258007</td>\n",
       "      <td>2.059340</td>\n",
       "      <td>1.869278</td>\n",
       "      <td>1.689675</td>\n",
       "      <td>1.521638</td>\n",
       "      <td>1.365697</td>\n",
       "      <td>1.221953</td>\n",
       "      <td>1.090196</td>\n",
       "      <td>0.969995</td>\n",
       "      <td>0.860774</td>\n",
       "      <td>0.761865</td>\n",
       "      <td>8.379523</td>\n",
       "      <td>11.096233</td>\n",
       "      <td>13.878178</td>\n",
       "      <td>16.387452</td>\n",
       "      <td>18.426565</td>\n",
       "      <td>19.968341</td>\n",
       "      <td>21.085868</td>\n",
       "      <td>21.879452</td>\n",
       "      <td>22.439050</td>\n",
       "      <td>22.833782</td>\n",
       "      <td>23.113291</td>\n",
       "      <td>23.312237</td>\n",
       "      <td>23.454612</td>\n",
       "      <td>23.557026</td>\n",
       "      <td>23.631041</td>\n",
       "      <td>23.684756</td>\n",
       "      <td>23.723882</td>\n",
       "      <td>23.752476</td>\n",
       "      <td>23.773435</td>\n",
       "      <td>23.788837</td>\n",
       "      <td>23.800183</td>\n",
       "      <td>23.808559</td>\n",
       "      <td>6.205415</td>\n",
       "      <td>7.306666</td>\n",
       "      <td>7.846732</td>\n",
       "      <td>7.683086</td>\n",
       "      <td>7.022125</td>\n",
       "      <td>6.155694</td>\n",
       "      <td>5.274238</td>\n",
       "      <td>4.463781</td>\n",
       "      <td>3.752088</td>\n",
       "      <td>3.141055</td>\n",
       "      <td>2.622602</td>\n",
       "      <td>2.185586</td>\n",
       "      <td>1.818635</td>\n",
       "      <td>1.511249</td>\n",
       "      <td>1.254150</td>\n",
       "      <td>1.039325</td>\n",
       "      <td>0.859944</td>\n",
       "      <td>0.710226</td>\n",
       "      <td>0.585307</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>0.321702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>1.270543</td>\n",
       "      <td>-0.790244</td>\n",
       "      <td>1.273189</td>\n",
       "      <td>1.190357</td>\n",
       "      <td>1.483067</td>\n",
       "      <td>-0.048520</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>1.144205</td>\n",
       "      <td>-0.361092</td>\n",
       "      <td>0.499328</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "      <td>1.775624</td>\n",
       "      <td>1.711372</td>\n",
       "      <td>1.565235</td>\n",
       "      <td>1.359839</td>\n",
       "      <td>1.126303</td>\n",
       "      <td>0.894193</td>\n",
       "      <td>0.684089</td>\n",
       "      <td>0.505975</td>\n",
       "      <td>0.361723</td>\n",
       "      <td>0.248564</td>\n",
       "      <td>0.161786</td>\n",
       "      <td>0.096346</td>\n",
       "      <td>0.047642</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>-0.014323</td>\n",
       "      <td>-0.033153</td>\n",
       "      <td>-0.046575</td>\n",
       "      <td>-0.056011</td>\n",
       "      <td>-0.062529</td>\n",
       "      <td>-0.066924</td>\n",
       "      <td>-0.069783</td>\n",
       "      <td>-0.071540</td>\n",
       "      <td>-1.027474</td>\n",
       "      <td>-0.878537</td>\n",
       "      <td>-0.722123</td>\n",
       "      <td>-0.573020</td>\n",
       "      <td>-0.442310</td>\n",
       "      <td>-0.335990</td>\n",
       "      <td>-0.254678</td>\n",
       "      <td>-0.195156</td>\n",
       "      <td>-0.152683</td>\n",
       "      <td>-0.122692</td>\n",
       "      <td>-0.101509</td>\n",
       "      <td>-0.086443</td>\n",
       "      <td>-0.075613</td>\n",
       "      <td>-0.067731</td>\n",
       "      <td>-0.061919</td>\n",
       "      <td>-0.057579</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>-0.051789</td>\n",
       "      <td>-0.049849</td>\n",
       "      <td>-0.048336</td>\n",
       "      <td>-0.047144</td>\n",
       "      <td>-0.046198</td>\n",
       "      <td>1.799296</td>\n",
       "      <td>1.720859</td>\n",
       "      <td>1.552414</td>\n",
       "      <td>1.323876</td>\n",
       "      <td>1.073205</td>\n",
       "      <td>0.832820</td>\n",
       "      <td>0.622264</td>\n",
       "      <td>0.448798</td>\n",
       "      <td>0.311684</td>\n",
       "      <td>0.206333</td>\n",
       "      <td>0.126996</td>\n",
       "      <td>0.068141</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.028707</td>\n",
       "      <td>-0.044630</td>\n",
       "      <td>-0.055783</td>\n",
       "      <td>-0.063469</td>\n",
       "      <td>-0.068651</td>\n",
       "      <td>-0.072038</td>\n",
       "      <td>-0.074146</td>\n",
       "      <td>-0.075352</td>\n",
       "      <td>1.622634</td>\n",
       "      <td>1.163121</td>\n",
       "      <td>0.695861</td>\n",
       "      <td>0.360854</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.046504</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>-0.042703</td>\n",
       "      <td>-0.057307</td>\n",
       "      <td>-0.063944</td>\n",
       "      <td>-0.066578</td>\n",
       "      <td>-0.067268</td>\n",
       "      <td>-0.067065</td>\n",
       "      <td>-0.066493</td>\n",
       "      <td>-0.065803</td>\n",
       "      <td>-0.065114</td>\n",
       "      <td>-0.064473</td>\n",
       "      <td>-0.063897</td>\n",
       "      <td>-0.063387</td>\n",
       "      <td>-0.062939</td>\n",
       "      <td>-0.062545</td>\n",
       "      <td>-0.062199</td>\n",
       "      <td>0.205005</td>\n",
       "      <td>0.127199</td>\n",
       "      <td>0.052660</td>\n",
       "      <td>-0.012937</td>\n",
       "      <td>-0.064950</td>\n",
       "      <td>-0.100981</td>\n",
       "      <td>-0.121473</td>\n",
       "      <td>-0.129195</td>\n",
       "      <td>-0.127953</td>\n",
       "      <td>-0.121380</td>\n",
       "      <td>-0.112280</td>\n",
       "      <td>-0.102513</td>\n",
       "      <td>-0.093157</td>\n",
       "      <td>-0.084743</td>\n",
       "      <td>-0.077460</td>\n",
       "      <td>-0.071309</td>\n",
       "      <td>-0.066192</td>\n",
       "      <td>-0.061976</td>\n",
       "      <td>-0.058521</td>\n",
       "      <td>-0.055696</td>\n",
       "      <td>-0.053388</td>\n",
       "      <td>-0.051499</td>\n",
       "      <td>0.265999</td>\n",
       "      <td>0.040466</td>\n",
       "      <td>-0.088861</td>\n",
       "      <td>-0.141056</td>\n",
       "      <td>-0.150224</td>\n",
       "      <td>-0.140945</td>\n",
       "      <td>-0.126198</td>\n",
       "      <td>-0.111556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.088506</td>\n",
       "      <td>-0.080165</td>\n",
       "      <td>-0.073497</td>\n",
       "      <td>-0.068153</td>\n",
       "      <td>-0.063845</td>\n",
       "      <td>-0.060350</td>\n",
       "      <td>-0.057494</td>\n",
       "      <td>-0.055145</td>\n",
       "      <td>-0.053201</td>\n",
       "      <td>-0.051583</td>\n",
       "      <td>-0.050229</td>\n",
       "      <td>-0.049091</td>\n",
       "      <td>-0.048129</td>\n",
       "      <td>1.010588</td>\n",
       "      <td>0.559512</td>\n",
       "      <td>0.236813</td>\n",
       "      <td>0.052372</td>\n",
       "      <td>-0.040251</td>\n",
       "      <td>-0.081784</td>\n",
       "      <td>-0.097533</td>\n",
       "      <td>-0.101235</td>\n",
       "      <td>-0.099798</td>\n",
       "      <td>-0.096496</td>\n",
       "      <td>-0.092795</td>\n",
       "      <td>-0.089289</td>\n",
       "      <td>-0.086181</td>\n",
       "      <td>-0.083504</td>\n",
       "      <td>-0.081224</td>\n",
       "      <td>-0.079285</td>\n",
       "      <td>-0.077633</td>\n",
       "      <td>-0.076218</td>\n",
       "      <td>-0.074998</td>\n",
       "      <td>-0.073939</td>\n",
       "      <td>-0.073013</td>\n",
       "      <td>-0.072196</td>\n",
       "      <td>1.187238</td>\n",
       "      <td>0.789724</td>\n",
       "      <td>0.441767</td>\n",
       "      <td>0.201271</td>\n",
       "      <td>0.054273</td>\n",
       "      <td>-0.028469</td>\n",
       "      <td>-0.071670</td>\n",
       "      <td>-0.092125</td>\n",
       "      <td>-0.100159</td>\n",
       "      <td>-0.101740</td>\n",
       "      <td>-0.100177</td>\n",
       "      <td>-0.097233</td>\n",
       "      <td>-0.093812</td>\n",
       "      <td>-0.090355</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>-0.083989</td>\n",
       "      <td>-0.081168</td>\n",
       "      <td>-0.078581</td>\n",
       "      <td>-0.076206</td>\n",
       "      <td>-0.074021</td>\n",
       "      <td>-0.072003</td>\n",
       "      <td>-0.070134</td>\n",
       "      <td>-0.080170</td>\n",
       "      <td>-0.141512</td>\n",
       "      <td>-0.189434</td>\n",
       "      <td>-0.221716</td>\n",
       "      <td>-0.238396</td>\n",
       "      <td>-0.241506</td>\n",
       "      <td>-0.234310</td>\n",
       "      <td>-0.220397</td>\n",
       "      <td>-0.202961</td>\n",
       "      <td>-0.184438</td>\n",
       "      <td>-0.166444</td>\n",
       "      <td>-0.149900</td>\n",
       "      <td>-0.135222</td>\n",
       "      <td>-0.122500</td>\n",
       "      <td>-0.111635</td>\n",
       "      <td>-0.102438</td>\n",
       "      <td>-0.094689</td>\n",
       "      <td>-0.088168</td>\n",
       "      <td>-0.082675</td>\n",
       "      <td>-0.078037</td>\n",
       "      <td>-0.074106</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>-0.557435</td>\n",
       "      <td>-0.540751</td>\n",
       "      <td>-0.513057</td>\n",
       "      <td>-0.476238</td>\n",
       "      <td>-0.433247</td>\n",
       "      <td>-0.387554</td>\n",
       "      <td>-0.342423</td>\n",
       "      <td>-0.300356</td>\n",
       "      <td>-0.262867</td>\n",
       "      <td>-0.230569</td>\n",
       "      <td>-0.203419</td>\n",
       "      <td>-0.180984</td>\n",
       "      <td>-0.162650</td>\n",
       "      <td>-0.147763</td>\n",
       "      <td>-0.135708</td>\n",
       "      <td>-0.125942</td>\n",
       "      <td>-0.118009</td>\n",
       "      <td>-0.111534</td>\n",
       "      <td>-0.106215</td>\n",
       "      <td>-0.101812</td>\n",
       "      <td>-0.098135</td>\n",
       "      <td>-0.095036</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.166857</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.044890</td>\n",
       "      <td>-0.054577</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.054669</td>\n",
       "      <td>-0.053520</td>\n",
       "      <td>-0.052429</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.050525</td>\n",
       "      <td>-0.049691</td>\n",
       "      <td>-0.048924</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>-0.047580</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>-0.046467</td>\n",
       "      <td>-0.045988</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.044506</td>\n",
       "      <td>-0.601467</td>\n",
       "      <td>-0.381818</td>\n",
       "      <td>-0.227216</td>\n",
       "      <td>-0.142565</td>\n",
       "      <td>-0.099529</td>\n",
       "      <td>-0.077144</td>\n",
       "      <td>-0.064768</td>\n",
       "      <td>-0.057448</td>\n",
       "      <td>-0.052849</td>\n",
       "      <td>-0.049813</td>\n",
       "      <td>-0.04773</td>\n",
       "      <td>-0.04626</td>\n",
       "      <td>-0.045198</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>-0.043837</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>-0.042625</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042362</td>\n",
       "      <td>-0.042274</td>\n",
       "      <td>0.594323</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>-0.011005</td>\n",
       "      <td>-0.047079</td>\n",
       "      <td>-0.053517</td>\n",
       "      <td>-0.053285</td>\n",
       "      <td>-0.051898</td>\n",
       "      <td>-0.050514</td>\n",
       "      <td>-0.049309</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>-0.047386</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-0.045374</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>-0.044451</td>\n",
       "      <td>-0.044084</td>\n",
       "      <td>-0.04377</td>\n",
       "      <td>-0.043501</td>\n",
       "      <td>-0.043272</td>\n",
       "      <td>-0.043076</td>\n",
       "      <td>-0.042909</td>\n",
       "      <td>0.295678</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>-0.051065</td>\n",
       "      <td>-0.058779</td>\n",
       "      <td>-0.059439</td>\n",
       "      <td>-0.059243</td>\n",
       "      <td>-0.059032</td>\n",
       "      <td>-0.058862</td>\n",
       "      <td>-0.058711</td>\n",
       "      <td>-0.058561</td>\n",
       "      <td>-0.058406</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>-0.058069</td>\n",
       "      <td>-0.057887</td>\n",
       "      <td>-0.057696</td>\n",
       "      <td>-0.057498</td>\n",
       "      <td>-0.057291</td>\n",
       "      <td>-0.057078</td>\n",
       "      <td>-0.056858</td>\n",
       "      <td>-0.056632</td>\n",
       "      <td>-0.056402</td>\n",
       "      <td>-0.056167</td>\n",
       "      <td>1.089872</td>\n",
       "      <td>0.568271</td>\n",
       "      <td>0.214881</td>\n",
       "      <td>0.048451</td>\n",
       "      <td>-0.016753</td>\n",
       "      <td>-0.039197</td>\n",
       "      <td>-0.045612</td>\n",
       "      <td>-0.046578</td>\n",
       "      <td>-0.045958</td>\n",
       "      <td>-0.045055</td>\n",
       "      <td>-0.044254</td>\n",
       "      <td>-0.043631</td>\n",
       "      <td>-0.043169</td>\n",
       "      <td>-0.042834</td>\n",
       "      <td>-0.042593</td>\n",
       "      <td>-0.042419</td>\n",
       "      <td>-0.042294</td>\n",
       "      <td>-0.042203</td>\n",
       "      <td>-0.042138</td>\n",
       "      <td>-0.04209</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>-0.04203</td>\n",
       "      <td>-0.222892</td>\n",
       "      <td>-0.229476</td>\n",
       "      <td>-0.180188</td>\n",
       "      <td>-0.134192</td>\n",
       "      <td>-0.102547</td>\n",
       "      <td>-0.082273</td>\n",
       "      <td>-0.069303</td>\n",
       "      <td>-0.060848</td>\n",
       "      <td>-0.055212</td>\n",
       "      <td>-0.051379</td>\n",
       "      <td>-0.048727</td>\n",
       "      <td>-0.046866</td>\n",
       "      <td>-0.045544</td>\n",
       "      <td>-0.044596</td>\n",
       "      <td>-0.043910</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.042772</td>\n",
       "      <td>-0.042571</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042309</td>\n",
       "      <td>-0.042225</td>\n",
       "      <td>0.164524</td>\n",
       "      <td>-0.026291</td>\n",
       "      <td>-0.051849</td>\n",
       "      <td>-0.052095</td>\n",
       "      <td>-0.049947</td>\n",
       "      <td>-0.048126</td>\n",
       "      <td>-0.046732</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>-0.044175</td>\n",
       "      <td>-0.04367</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.04274</td>\n",
       "      <td>-0.04256</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>-0.042314</td>\n",
       "      <td>-0.042231</td>\n",
       "      <td>-0.042168</td>\n",
       "      <td>-0.04212</td>\n",
       "      <td>-0.042082</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>0.819252</td>\n",
       "      <td>0.397074</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.040502</td>\n",
       "      <td>-0.052209</td>\n",
       "      <td>-0.053270</td>\n",
       "      <td>-0.051431</td>\n",
       "      <td>-0.049238</td>\n",
       "      <td>-0.047384</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.044916</td>\n",
       "      <td>-0.044149</td>\n",
       "      <td>-0.043588</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>-0.042871</td>\n",
       "      <td>-0.042646</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.042351</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>-0.042131</td>\n",
       "      <td>-0.355153</td>\n",
       "      <td>-0.281804</td>\n",
       "      <td>-0.200053</td>\n",
       "      <td>-0.140440</td>\n",
       "      <td>-0.103452</td>\n",
       "      <td>-0.081415</td>\n",
       "      <td>-0.068089</td>\n",
       "      <td>-0.059747</td>\n",
       "      <td>-0.054335</td>\n",
       "      <td>-0.050714</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>-0.046501</td>\n",
       "      <td>-0.045273</td>\n",
       "      <td>-0.044394</td>\n",
       "      <td>-0.043758</td>\n",
       "      <td>-0.043294</td>\n",
       "      <td>-0.042954</td>\n",
       "      <td>-0.042703</td>\n",
       "      <td>-0.042517</td>\n",
       "      <td>-0.042379</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>-0.042199</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>-0.054440</td>\n",
       "      <td>-0.072005</td>\n",
       "      <td>-0.065989</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>-0.054402</td>\n",
       "      <td>-0.051054</td>\n",
       "      <td>-0.048685</td>\n",
       "      <td>-0.046970</td>\n",
       "      <td>-0.045708</td>\n",
       "      <td>-0.044771</td>\n",
       "      <td>-0.044072</td>\n",
       "      <td>-0.043549</td>\n",
       "      <td>-0.043157</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>-0.04264</td>\n",
       "      <td>-0.042473</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>-0.042253</td>\n",
       "      <td>-0.042181</td>\n",
       "      <td>-0.042127</td>\n",
       "      <td>-0.042086</td>\n",
       "      <td>1.187404</td>\n",
       "      <td>1.008481</td>\n",
       "      <td>0.793636</td>\n",
       "      <td>0.577353</td>\n",
       "      <td>0.385856</td>\n",
       "      <td>0.232194</td>\n",
       "      <td>0.117992</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>-0.014599</td>\n",
       "      <td>-0.047709</td>\n",
       "      <td>-0.067163</td>\n",
       "      <td>-0.077535</td>\n",
       "      <td>-0.082092</td>\n",
       "      <td>-0.083072</td>\n",
       "      <td>-0.081959</td>\n",
       "      <td>-0.079708</td>\n",
       "      <td>-0.076918</td>\n",
       "      <td>-0.073951</td>\n",
       "      <td>-0.071016</td>\n",
       "      <td>-0.068229</td>\n",
       "      <td>-0.065645</td>\n",
       "      <td>-0.063286</td>\n",
       "      <td>-1.239117</td>\n",
       "      <td>-1.017018</td>\n",
       "      <td>-0.816354</td>\n",
       "      <td>-0.645848</td>\n",
       "      <td>-0.507986</td>\n",
       "      <td>-0.400683</td>\n",
       "      <td>-0.319316</td>\n",
       "      <td>-0.258512</td>\n",
       "      <td>-0.213297</td>\n",
       "      <td>-0.179593</td>\n",
       "      <td>-0.154278</td>\n",
       "      <td>-0.135054</td>\n",
       "      <td>-0.120266</td>\n",
       "      <td>-0.108729</td>\n",
       "      <td>-0.099598</td>\n",
       "      <td>-0.092266</td>\n",
       "      <td>-0.086296</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.077251</td>\n",
       "      <td>-0.073768</td>\n",
       "      <td>-0.070790</td>\n",
       "      <td>-0.068219</td>\n",
       "      <td>1.224283</td>\n",
       "      <td>1.031734</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.567149</td>\n",
       "      <td>0.366707</td>\n",
       "      <td>0.210911</td>\n",
       "      <td>0.099555</td>\n",
       "      <td>0.025279</td>\n",
       "      <td>-0.021251</td>\n",
       "      <td>-0.048524</td>\n",
       "      <td>-0.063178</td>\n",
       "      <td>-0.069959</td>\n",
       "      <td>-0.072058</td>\n",
       "      <td>-0.071530</td>\n",
       "      <td>-0.069646</td>\n",
       "      <td>-0.067163</td>\n",
       "      <td>-0.064517</td>\n",
       "      <td>-0.061941</td>\n",
       "      <td>-0.059553</td>\n",
       "      <td>-0.057399</td>\n",
       "      <td>-0.055489</td>\n",
       "      <td>-0.053812</td>\n",
       "      <td>0.815420</td>\n",
       "      <td>0.387458</td>\n",
       "      <td>0.114120</td>\n",
       "      <td>-0.012212</td>\n",
       "      <td>-0.057360</td>\n",
       "      <td>-0.068015</td>\n",
       "      <td>-0.066628</td>\n",
       "      <td>-0.062138</td>\n",
       "      <td>-0.057603</td>\n",
       "      <td>-0.053848</td>\n",
       "      <td>-0.050944</td>\n",
       "      <td>-0.048754</td>\n",
       "      <td>-0.047114</td>\n",
       "      <td>-0.045886</td>\n",
       "      <td>-0.044963</td>\n",
       "      <td>-0.044266</td>\n",
       "      <td>-0.043737</td>\n",
       "      <td>-0.043333</td>\n",
       "      <td>-0.043025</td>\n",
       "      <td>-0.042788</td>\n",
       "      <td>-0.042605</td>\n",
       "      <td>-0.042463</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>-0.031931</td>\n",
       "      <td>-0.095401</td>\n",
       "      <td>-0.141399</td>\n",
       "      <td>-0.169978</td>\n",
       "      <td>-0.183555</td>\n",
       "      <td>-0.185775</td>\n",
       "      <td>-0.180425</td>\n",
       "      <td>-0.170726</td>\n",
       "      <td>-0.159068</td>\n",
       "      <td>-0.147032</td>\n",
       "      <td>-0.135553</td>\n",
       "      <td>-0.125110</td>\n",
       "      <td>-0.115887</td>\n",
       "      <td>-0.107893</td>\n",
       "      <td>-0.101046</td>\n",
       "      <td>-0.095220</td>\n",
       "      <td>-0.090280</td>\n",
       "      <td>-0.086093</td>\n",
       "      <td>-0.082539</td>\n",
       "      <td>-0.079513</td>\n",
       "      <td>-0.383307</td>\n",
       "      <td>-0.325709</td>\n",
       "      <td>-0.246937</td>\n",
       "      <td>-0.187160</td>\n",
       "      <td>-0.147735</td>\n",
       "      <td>-0.122032</td>\n",
       "      <td>-0.104680</td>\n",
       "      <td>-0.092407</td>\n",
       "      <td>-0.083339</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.070924</td>\n",
       "      <td>-0.066520</td>\n",
       "      <td>-0.062916</td>\n",
       "      <td>-0.059928</td>\n",
       "      <td>-0.057427</td>\n",
       "      <td>-0.055316</td>\n",
       "      <td>-0.053524</td>\n",
       "      <td>-0.051994</td>\n",
       "      <td>-0.050683</td>\n",
       "      <td>-0.049556</td>\n",
       "      <td>-0.048583</td>\n",
       "      <td>-0.047743</td>\n",
       "      <td>0.241326</td>\n",
       "      <td>-0.012490</td>\n",
       "      <td>-0.113958</td>\n",
       "      <td>-0.132762</td>\n",
       "      <td>-0.123093</td>\n",
       "      <td>-0.108347</td>\n",
       "      <td>-0.095567</td>\n",
       "      <td>-0.085859</td>\n",
       "      <td>-0.078719</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>-0.069429</td>\n",
       "      <td>-0.066304</td>\n",
       "      <td>-0.063790</td>\n",
       "      <td>-0.061712</td>\n",
       "      <td>-0.059951</td>\n",
       "      <td>-0.058429</td>\n",
       "      <td>-0.057093</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>-0.054837</td>\n",
       "      <td>-0.053870</td>\n",
       "      <td>-0.052990</td>\n",
       "      <td>-0.052184</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>0.066918</td>\n",
       "      <td>-0.066542</td>\n",
       "      <td>-0.148489</td>\n",
       "      <td>-0.193167</td>\n",
       "      <td>-0.213414</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>-0.215670</td>\n",
       "      <td>-0.208156</td>\n",
       "      <td>-0.198668</td>\n",
       "      <td>-0.188601</td>\n",
       "      <td>-0.178710</td>\n",
       "      <td>-0.169372</td>\n",
       "      <td>-0.160746</td>\n",
       "      <td>-0.152874</td>\n",
       "      <td>-0.145735</td>\n",
       "      <td>-0.139280</td>\n",
       "      <td>-0.133449</td>\n",
       "      <td>-0.128179</td>\n",
       "      <td>-0.123412</td>\n",
       "      <td>-0.119094</td>\n",
       "      <td>-0.762231</td>\n",
       "      <td>-0.623577</td>\n",
       "      <td>-0.479973</td>\n",
       "      <td>-0.354692</td>\n",
       "      <td>-0.258533</td>\n",
       "      <td>-0.190760</td>\n",
       "      <td>-0.145170</td>\n",
       "      <td>-0.114992</td>\n",
       "      <td>-0.094914</td>\n",
       "      <td>-0.081310</td>\n",
       "      <td>-0.071864</td>\n",
       "      <td>-0.065129</td>\n",
       "      <td>-0.060204</td>\n",
       "      <td>-0.056520</td>\n",
       "      <td>-0.053708</td>\n",
       "      <td>-0.051525</td>\n",
       "      <td>-0.049808</td>\n",
       "      <td>-0.048439</td>\n",
       "      <td>-0.047338</td>\n",
       "      <td>-0.046444</td>\n",
       "      <td>-0.045713</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>-0.406433</td>\n",
       "      <td>-0.375019</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.236755</td>\n",
       "      <td>-0.173203</td>\n",
       "      <td>-0.127398</td>\n",
       "      <td>-0.097198</td>\n",
       "      <td>-0.078029</td>\n",
       "      <td>-0.065971</td>\n",
       "      <td>-0.058330</td>\n",
       "      <td>-0.053408</td>\n",
       "      <td>-0.050167</td>\n",
       "      <td>-0.047982</td>\n",
       "      <td>-0.046471</td>\n",
       "      <td>-0.045401</td>\n",
       "      <td>-0.044626</td>\n",
       "      <td>-0.044052</td>\n",
       "      <td>-0.043620</td>\n",
       "      <td>-0.043289</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>-0.042669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          3.283515        2.652874             2.532475       2.217515   \n",
       "1         -0.487072       -0.023846             0.548144       0.001392   \n",
       "2          1.052926        1.363478             2.037231       0.939685   \n",
       "3          3.402909        1.915897             1.451707       2.867383   \n",
       "4          0.539340        1.371011             1.428493      -0.009560   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                2.255747      2.489734      -0.565265         2.833031   \n",
       "1               -0.868652      0.499255      -0.876244         0.263327   \n",
       "2               -0.398008      1.228676      -0.780083         0.850928   \n",
       "3                4.910919      0.326373      -0.110409         0.286593   \n",
       "4               -0.562450      1.270543      -0.790244         1.273189   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0    2.487578         -0.214002           1.316862         0.724026   \n",
       "1    0.742402         -0.605351          -0.692926        -0.440780   \n",
       "2    1.181336         -0.297005           0.814974         0.213076   \n",
       "3   -0.288378          0.689702           2.744280         0.819518   \n",
       "4    1.190357          1.483067          -0.048520         0.828471   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0              0.660820        1.148757                 0.907083   \n",
       "1              0.260162       -0.805450                -0.099444   \n",
       "2              1.424827        0.237036                 0.293559   \n",
       "3              1.115007        4.732680                 2.047511   \n",
       "4              1.144205       -0.361092                 0.499328   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0      1.886690      -1.359293         2.303601    2.001237          1.307686   \n",
       "1      1.805927      -0.369203         1.535126    1.890489         -0.375612   \n",
       "2      1.511870      -0.023974         1.347475    1.456285          0.527407   \n",
       "3     -0.281464       0.133984        -0.249939   -0.550021          3.394275   \n",
       "4      1.298575      -1.466770         1.338539    1.220724          0.220556   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0           2.616665         2.109526              2.296076        2.750622   \n",
       "1          -0.430444        -0.146749              1.087084       -0.243890   \n",
       "2           1.082932         0.854974              1.955000        1.152255   \n",
       "3           3.893397         1.989588              2.175786        6.046041   \n",
       "4          -0.313395         0.613179              0.729259       -0.868353   \n",
       "\n",
       "   worst fractal dimension  mean radiuspow_2  mean radiuspow_3  \\\n",
       "0                 1.937015          0.992811          0.839412   \n",
       "1                 0.281190          1.877346          1.832171   \n",
       "2                 0.201391          1.562343          1.463532   \n",
       "3                 4.935010         -0.725173         -0.653462   \n",
       "4                -0.397100          1.775624          1.711372   \n",
       "\n",
       "   mean radiuspow_4  mean radiuspow_5  mean radiuspow_6  mean radiuspow_7  \\\n",
       "0          0.659649          0.478478          0.316323          0.184622   \n",
       "1          1.698831          1.498134          1.261325          1.019710   \n",
       "2          1.297010          1.088113          0.866659          0.657956   \n",
       "3         -0.567568         -0.479758         -0.398966         -0.330044   \n",
       "4          1.565235          1.359839          1.126303          0.894193   \n",
       "\n",
       "   mean radiuspow_8  mean radiuspow_9  mean radiuspow_10  mean radiuspow_11  \\\n",
       "0          0.085747          0.016082          -0.030455          -0.060035   \n",
       "1          0.796273          0.603219           0.444050           0.316996   \n",
       "2          0.477420          0.330613           0.216391           0.130297   \n",
       "3         -0.274256         -0.230566          -0.196948          -0.171241   \n",
       "4          0.684089          0.505975           0.361723           0.248564   \n",
       "\n",
       "   mean radiuspow_12  mean radiuspow_13  mean radiuspow_14  mean radiuspow_15  \\\n",
       "0          -0.077835          -0.087781          -0.092665          -0.094399   \n",
       "1           0.217857           0.141761           0.084082           0.040804   \n",
       "2           0.066914           0.021110          -0.011467          -0.034286   \n",
       "3          -0.151555          -0.136383          -0.124578          -0.115288   \n",
       "4           0.161786           0.096346           0.047642           0.011794   \n",
       "\n",
       "   mean radiuspow_16  mean radiuspow_17  mean radiuspow_18  mean radiuspow_19  \\\n",
       "0          -0.094247          -0.093027          -0.091251          -0.089235   \n",
       "1           0.008621          -0.015110          -0.032456          -0.045010   \n",
       "2          -0.050011          -0.060638          -0.067640          -0.072087   \n",
       "3          -0.107888          -0.101917          -0.097036          -0.092995   \n",
       "4          -0.014323          -0.033153          -0.046575          -0.056011   \n",
       "\n",
       "   mean radiuspow_20  mean radiuspow_21  mean radiuspow_22  mean radiuspow_23  \\\n",
       "0          -0.087165          -0.085146          -0.083232          -0.081446   \n",
       "1          -0.053990          -0.060318          -0.064689          -0.067623   \n",
       "2          -0.074751          -0.076185          -0.076779          -0.076811   \n",
       "3          -0.089606          -0.086729          -0.084257          -0.082111   \n",
       "4          -0.062529          -0.066924          -0.069783          -0.071540   \n",
       "\n",
       "   mean texturepow_2  mean texturepow_3  mean texturepow_4  mean texturepow_5  \\\n",
       "0          -1.571385          -1.179184          -0.877428          -0.647949   \n",
       "1          -0.415521          -0.441227          -0.431399          -0.393286   \n",
       "2           0.338964           0.213212           0.096099           0.001674   \n",
       "3           0.137726           0.027448          -0.062853          -0.124360   \n",
       "4          -1.027474          -0.878537          -0.722123          -0.573020   \n",
       "\n",
       "   mean texturepow_6  mean texturepow_7  mean texturepow_8  mean texturepow_9  \\\n",
       "0          -0.476180          -0.350449          -0.260573          -0.197479   \n",
       "1          -0.338623          -0.279711          -0.225603          -0.180685   \n",
       "2          -0.062965          -0.098881          -0.112802          -0.112959   \n",
       "3          -0.155893          -0.163128          -0.154942          -0.139502   \n",
       "4          -0.442310          -0.335990          -0.254678          -0.195156   \n",
       "\n",
       "   mean texturepow_10  mean texturepow_11  mean texturepow_12  \\\n",
       "0           -0.153577           -0.123030           -0.101635   \n",
       "1           -0.145672           -0.119359           -0.099945   \n",
       "2           -0.106123           -0.096717           -0.087163   \n",
       "3           -0.122349           -0.106420           -0.092873   \n",
       "4           -0.152683           -0.122692           -0.101509   \n",
       "\n",
       "   mean texturepow_13  mean texturepow_14  mean texturepow_15  \\\n",
       "0           -0.086490           -0.075630           -0.067737   \n",
       "1           -0.085716           -0.075278           -0.067577   \n",
       "2           -0.078573           -0.071315           -0.065390   \n",
       "3           -0.081893           -0.073227           -0.066484   \n",
       "4           -0.086443           -0.075613           -0.067731   \n",
       "\n",
       "   mean texturepow_16  mean texturepow_17  mean texturepow_18  \\\n",
       "0           -0.061921           -0.057580           -0.054298   \n",
       "1           -0.061848           -0.057547           -0.054283   \n",
       "2           -0.060647           -0.056889           -0.053923   \n",
       "3           -0.061269           -0.057240           -0.054122   \n",
       "4           -0.061919           -0.057579           -0.054298   \n",
       "\n",
       "   mean texturepow_19  mean texturepow_20  mean texturepow_21  \\\n",
       "0           -0.051789           -0.049849           -0.048336   \n",
       "1           -0.051782           -0.049846           -0.048334   \n",
       "2           -0.051586           -0.049740           -0.048276   \n",
       "3           -0.051697           -0.049802           -0.048311   \n",
       "4           -0.051789           -0.049849           -0.048336   \n",
       "\n",
       "   mean texturepow_22  mean texturepow_23  mean perimeterpow_2  \\\n",
       "0           -0.047144           -0.046198             1.179187   \n",
       "1           -0.047143           -0.046197             1.684038   \n",
       "2           -0.047112           -0.046180             1.534999   \n",
       "3           -0.047131           -0.046191            -0.592131   \n",
       "4           -0.047144           -0.046198             1.799296   \n",
       "\n",
       "   mean perimeterpow_3  mean perimeterpow_4  mean perimeterpow_5  \\\n",
       "0             1.021620             0.823233             0.615745   \n",
       "1             1.585903             1.406382             1.176830   \n",
       "2             1.414711             1.224659             0.997317   \n",
       "3            -0.555405            -0.495193            -0.425392   \n",
       "4             1.720859             1.552414             1.323876   \n",
       "\n",
       "   mean perimeterpow_6  mean perimeterpow_7  mean perimeterpow_8  \\\n",
       "0             0.426231             0.270127             0.151148   \n",
       "1             0.934006             0.707471             0.513681   \n",
       "2             0.767293             0.560191             0.388515   \n",
       "3            -0.357384            -0.297950            -0.249471   \n",
       "4             1.073205             0.832820             0.622264   \n",
       "\n",
       "   mean perimeterpow_9  mean perimeterpow_10  mean perimeterpow_11  \\\n",
       "0             0.065550              0.006623             -0.032491   \n",
       "1             0.357474              0.236581              0.145630   \n",
       "2             0.254192              0.153248              0.079547   \n",
       "3            -0.211510             -0.182395             -0.160223   \n",
       "4             0.448798              0.311684              0.206333   \n",
       "\n",
       "   mean perimeterpow_12  mean perimeterpow_13  mean perimeterpow_14  \\\n",
       "0             -0.057571             -0.073038             -0.082090   \n",
       "1              0.078596              0.029972             -0.004824   \n",
       "2              0.026900             -0.010030             -0.035501   \n",
       "3             -0.143308             -0.130307             -0.120205   \n",
       "4              0.126996              0.068141              0.025008   \n",
       "\n",
       "   mean perimeterpow_15  mean perimeterpow_16  mean perimeterpow_17  \\\n",
       "0             -0.086957             -0.089156             -0.089697   \n",
       "1             -0.029408             -0.046545             -0.058304   \n",
       "2             -0.052757             -0.064204             -0.071588   \n",
       "3             -0.112254             -0.105909             -0.100773   \n",
       "4             -0.006266             -0.028707             -0.044630   \n",
       "\n",
       "   mean perimeterpow_18  mean perimeterpow_19  mean perimeterpow_20  \\\n",
       "0             -0.089244             -0.088224             -0.086910   \n",
       "1             -0.066216             -0.071395             -0.074651   \n",
       "2             -0.076160             -0.078809             -0.080158   \n",
       "3             -0.096556             -0.093046             -0.090087   \n",
       "4             -0.055783             -0.063469             -0.068651   \n",
       "\n",
       "   mean perimeterpow_21  mean perimeterpow_22  mean perimeterpow_23  \\\n",
       "0             -0.085469             -0.084003             -0.082570   \n",
       "1             -0.076565             -0.077551             -0.077907   \n",
       "2             -0.080642             -0.080561             -0.080122   \n",
       "3             -0.087560             -0.085378             -0.083474   \n",
       "4             -0.072038             -0.074146             -0.075352   \n",
       "\n",
       "   mean areapow_2  mean areapow_3  mean areapow_4  mean areapow_5  \\\n",
       "0        0.645627        0.299006        0.073012       -0.034847   \n",
       "1        1.731892        1.272819        0.785139        0.424558   \n",
       "2        1.285095        0.839977        0.444987        0.190014   \n",
       "3       -0.579465       -0.394036       -0.261908       -0.182783   \n",
       "4        1.622634        1.163121        0.695861        0.360854   \n",
       "\n",
       "   mean areapow_6  mean areapow_7  mean areapow_8  mean areapow_9  \\\n",
       "0       -0.075354       -0.086157       -0.085947       -0.082501   \n",
       "1        0.200706        0.073042        0.003564       -0.032996   \n",
       "2        0.050845       -0.018395       -0.050575       -0.064387   \n",
       "3       -0.137842       -0.111978       -0.096495       -0.086782   \n",
       "4        0.158615        0.046504       -0.012660       -0.042703   \n",
       "\n",
       "   mean areapow_10  mean areapow_11  mean areapow_12  mean areapow_13  \\\n",
       "0        -0.078665        -0.075310        -0.072590        -0.070434   \n",
       "1        -0.051592        -0.060621        -0.064665        -0.066176   \n",
       "2        -0.069515        -0.070735        -0.070319        -0.069314   \n",
       "3        -0.080396        -0.076009        -0.072871        -0.070547   \n",
       "4        -0.057307        -0.063944        -0.066578        -0.067268   \n",
       "\n",
       "   mean areapow_14  mean areapow_15  mean areapow_16  mean areapow_17  \\\n",
       "0        -0.068726        -0.067362        -0.066257        -0.065351   \n",
       "1        -0.066446        -0.066143        -0.065607        -0.065004   \n",
       "2        -0.068177        -0.067093        -0.066126        -0.065287   \n",
       "3        -0.068772        -0.067380        -0.066265        -0.065354   \n",
       "4        -0.067065        -0.066493        -0.065803        -0.065114   \n",
       "\n",
       "   mean areapow_18  mean areapow_19  mean areapow_20  mean areapow_21  \\\n",
       "0        -0.064596        -0.063961        -0.063420        -0.062956   \n",
       "1        -0.064412        -0.063863        -0.063368        -0.062928   \n",
       "2        -0.064565        -0.063946        -0.063413        -0.062952   \n",
       "3        -0.064597        -0.063961        -0.063420        -0.062956   \n",
       "4        -0.064473        -0.063897        -0.063387        -0.062939   \n",
       "\n",
       "   mean areapow_22  mean areapow_23  mean smoothnesspow_2  \\\n",
       "0        -0.062554        -0.062204              1.610613   \n",
       "1        -0.062539        -0.062196             -0.817374   \n",
       "2        -0.062552        -0.062203              0.898163   \n",
       "3        -0.062554        -0.062204              3.843300   \n",
       "4        -0.062545        -0.062199              0.205005   \n",
       "\n",
       "   mean smoothnesspow_3  mean smoothnesspow_4  mean smoothnesspow_5  \\\n",
       "0              1.606685              1.550142              1.439774   \n",
       "1             -0.783359             -0.727240             -0.653213   \n",
       "2              0.826294              0.729590              0.614294   \n",
       "3              4.411750              4.940936              5.370392   \n",
       "4              0.127199              0.052660             -0.012937   \n",
       "\n",
       "   mean smoothnesspow_6  mean smoothnesspow_7  mean smoothnesspow_8  \\\n",
       "0              1.282793              1.095072              0.897147   \n",
       "1             -0.567683             -0.478598             -0.393688   \n",
       "2              0.489982              0.367941              0.258214   \n",
       "3              5.642512              5.723061              5.614041   \n",
       "4             -0.064950             -0.100981             -0.121473   \n",
       "\n",
       "   mean smoothnesspow_9  mean smoothnesspow_10  mean smoothnesspow_11  \\\n",
       "0              0.707987               0.540456               0.400348   \n",
       "1             -0.318580              -0.255957              -0.205966   \n",
       "2              0.167056               0.096276               0.044313   \n",
       "3              5.349596               4.979493               4.552477   \n",
       "4             -0.129195              -0.127953              -0.121380   \n",
       "\n",
       "   mean smoothnesspow_12  mean smoothnesspow_13  mean smoothnesspow_14  \\\n",
       "0               0.288010               0.200655               0.134230   \n",
       "1              -0.167225              -0.137747              -0.115534   \n",
       "2               0.007909              -0.016563              -0.032362   \n",
       "3               4.107039               3.669411               3.255402   \n",
       "4              -0.112280              -0.102513              -0.093157   \n",
       "\n",
       "   mean smoothnesspow_15  mean smoothnesspow_16  mean smoothnesspow_17  \\\n",
       "0               0.084556               0.047884               0.021094   \n",
       "1              -0.098850              -0.086305              -0.076830   \n",
       "2              -0.042106              -0.047759              -0.050729   \n",
       "3               2.873283               2.526373               2.214962   \n",
       "4              -0.084743              -0.077460              -0.071309   \n",
       "\n",
       "   mean smoothnesspow_18  mean smoothnesspow_19  mean smoothnesspow_20  \\\n",
       "0               0.001698              -0.012228              -0.022142   \n",
       "1              -0.069627              -0.064108              -0.059841   \n",
       "2              -0.051995              -0.052218              -0.051833   \n",
       "3               1.937602               1.691933               1.475198   \n",
       "4              -0.066192              -0.061976              -0.058521   \n",
       "\n",
       "   mean smoothnesspow_21  mean smoothnesspow_22  mean smoothnesspow_23  \\\n",
       "0              -0.029138              -0.034025              -0.037398   \n",
       "1              -0.056512              -0.053892              -0.051810   \n",
       "2              -0.051125              -0.050270              -0.049376   \n",
       "3               1.284537               1.117167               0.970471   \n",
       "4              -0.055696              -0.053388              -0.051499   \n",
       "\n",
       "   mean compactnesspow_2  mean compactnesspow_3  mean compactnesspow_4  \\\n",
       "0               4.253180               4.854248               5.012855   \n",
       "1              -0.502345              -0.428450              -0.336153   \n",
       "2               0.798208               0.481731               0.221821   \n",
       "3               4.490525               5.230695               5.518465   \n",
       "4               0.265999               0.040466              -0.088861   \n",
       "\n",
       "   mean compactnesspow_5  mean compactnesspow_6  mean compactnesspow_7  \\\n",
       "0               4.816130               4.397126               3.871756   \n",
       "1              -0.259174              -0.203011              -0.163495   \n",
       "2               0.053954              -0.037289              -0.079180   \n",
       "3               5.419880               5.060489               4.558237   \n",
       "4              -0.141056              -0.150224              -0.140945   \n",
       "\n",
       "   mean compactnesspow_8  mean compactnesspow_9  mean compactnesspow_10  \\\n",
       "0               3.321508               2.795972                2.320972   \n",
       "1              -0.135538              -0.115342               -0.100401   \n",
       "2              -0.093787              -0.095055               -0.090674   \n",
       "3               4.001367               3.447556                2.930148   \n",
       "4              -0.126198              -0.111556               -0.098889   \n",
       "\n",
       "   mean compactnesspow_11  mean compactnesspow_12  mean compactnesspow_13  \\\n",
       "0                1.906650                1.553787                1.258169   \n",
       "1               -0.089104               -0.080400               -0.073588   \n",
       "2               -0.084483               -0.078220               -0.072565   \n",
       "3                2.465434                2.058808                1.709292   \n",
       "4               -0.088506               -0.080165               -0.073497   \n",
       "\n",
       "   mean compactnesspow_14  mean compactnesspow_15  mean compactnesspow_16  \\\n",
       "0                1.013342                0.812224                0.647977   \n",
       "1               -0.068188               -0.063859               -0.060355   \n",
       "2               -0.067709               -0.063635               -0.060251   \n",
       "3                1.412561                1.162830                0.953957   \n",
       "4               -0.068153               -0.063845               -0.060350   \n",
       "\n",
       "   mean compactnesspow_17  mean compactnesspow_18  mean compactnesspow_19  \\\n",
       "0                0.514407                0.406123                0.318543   \n",
       "1               -0.057496               -0.055145               -0.053201   \n",
       "2               -0.057447               -0.055123               -0.053190   \n",
       "3                0.780039                0.635700                0.516198   \n",
       "4               -0.057494               -0.055145               -0.053201   \n",
       "\n",
       "   mean compactnesspow_20  mean compactnesspow_21  mean compactnesspow_22  \\\n",
       "0                0.247832                0.190819                0.144899   \n",
       "1               -0.051583               -0.050229               -0.049091   \n",
       "2               -0.051578               -0.050227               -0.049090   \n",
       "3                0.417438                0.335932                0.268735   \n",
       "4               -0.051583               -0.050229               -0.049091   \n",
       "\n",
       "   mean compactnesspow_23  mean concavitypow_2  mean concavitypow_3  \\\n",
       "0                0.107946             3.068456             2.869591   \n",
       "1               -0.048129            -0.270214            -0.292609   \n",
       "2               -0.048129             1.000988             0.551075   \n",
       "3                0.213382             1.782246             1.315557   \n",
       "4               -0.048129             1.010588             0.559512   \n",
       "\n",
       "   mean concavitypow_4  mean concavitypow_5  mean concavitypow_6  \\\n",
       "0             2.387799             1.859265             1.388716   \n",
       "1            -0.247424            -0.201610            -0.167804   \n",
       "2             0.230745             0.048483            -0.042569   \n",
       "3             0.845051             0.489679             0.253206   \n",
       "4             0.236813             0.052372            -0.040251   \n",
       "\n",
       "   mean concavitypow_7  mean concavitypow_8  mean concavitypow_9  \\\n",
       "0             1.006878             0.712186             0.491548   \n",
       "1            -0.144247            -0.127650            -0.115611   \n",
       "2            -0.083101            -0.098256            -0.101623   \n",
       "3             0.106453             0.019535            -0.030005   \n",
       "4            -0.081784            -0.097533            -0.101235   \n",
       "\n",
       "   mean concavitypow_10  mean concavitypow_11  mean concavitypow_12  \\\n",
       "0              0.329576              0.212262              0.128115   \n",
       "1             -0.106614             -0.099714             -0.094308   \n",
       "2             -0.100001             -0.096602             -0.092849   \n",
       "3             -0.057140             -0.071249             -0.077984   \n",
       "4             -0.099798             -0.096496             -0.092795   \n",
       "\n",
       "   mean concavitypow_13  mean concavitypow_14  mean concavitypow_15  \\\n",
       "0              0.068208              0.025820             -0.004003   \n",
       "1             -0.089999             -0.086514             -0.083660   \n",
       "2             -0.089316             -0.086195             -0.083511   \n",
       "3             -0.080659             -0.081179             -0.080617   \n",
       "4             -0.089289             -0.086181             -0.083504   \n",
       "\n",
       "   mean concavitypow_16  mean concavitypow_17  mean concavitypow_18  \\\n",
       "0             -0.024870             -0.039382             -0.049401   \n",
       "1             -0.081296             -0.079319             -0.077649   \n",
       "2             -0.081227             -0.079287             -0.077634   \n",
       "3             -0.079562             -0.078332             -0.077087   \n",
       "4             -0.081224             -0.079285             -0.077633   \n",
       "\n",
       "   mean concavitypow_19  mean concavitypow_20  mean concavitypow_21  \\\n",
       "0             -0.056257             -0.060892             -0.063975   \n",
       "1             -0.076225             -0.075002             -0.073941   \n",
       "2             -0.076218             -0.074998             -0.073939   \n",
       "3             -0.075906             -0.074820             -0.073838   \n",
       "4             -0.076218             -0.074998             -0.073939   \n",
       "\n",
       "   mean concavitypow_22  mean concavitypow_23  mean concave pointspow_2  \\\n",
       "0             -0.065977             -0.067230                  3.016780   \n",
       "1             -0.073013             -0.072196                  0.174748   \n",
       "2             -0.073013             -0.072196                  2.119005   \n",
       "3             -0.072955             -0.072163                  1.219297   \n",
       "4             -0.073013             -0.072196                  1.187238   \n",
       "\n",
       "   mean concave pointspow_3  mean concave pointspow_4  \\\n",
       "0                  3.008991                  2.695776   \n",
       "1                 -0.065228                 -0.164433   \n",
       "2                  1.827226                  1.403311   \n",
       "3                  0.821822                  0.468424   \n",
       "4                  0.789724                  0.441767   \n",
       "\n",
       "   mean concave pointspow_5  mean concave pointspow_6  \\\n",
       "0                  2.264764                  1.826500   \n",
       "1                 -0.187168                 -0.179775   \n",
       "2                  1.000015                  0.673477   \n",
       "3                  0.221047                  0.067921   \n",
       "4                  0.201271                  0.054273   \n",
       "\n",
       "   mean concave pointspow_7  mean concave pointspow_8  \\\n",
       "0                  1.431952                  1.098730   \n",
       "1                 -0.164054                 -0.148186   \n",
       "2                  0.429884                  0.256843   \n",
       "3                 -0.019506                 -0.065987   \n",
       "4                 -0.028469                 -0.071670   \n",
       "\n",
       "   mean concave pointspow_9  mean concave pointspow_10  \\\n",
       "0                  0.827839                   0.612995   \n",
       "1                 -0.134539                  -0.123373   \n",
       "2                  0.137895                   0.058122   \n",
       "3                 -0.088616                  -0.098036   \n",
       "4                 -0.092125                  -0.100159   \n",
       "\n",
       "   mean concave pointspow_11  mean concave pointspow_12  \\\n",
       "0                   0.445483                   0.316496   \n",
       "1                  -0.114329                  -0.106956   \n",
       "2                   0.005736                  -0.027955   \n",
       "3                  -0.100476                  -0.099434   \n",
       "4                  -0.101740                  -0.100177   \n",
       "\n",
       "   mean concave pointspow_13  mean concave pointspow_14  \\\n",
       "0                   0.218139                   0.143749   \n",
       "1                  -0.100864                  -0.095749   \n",
       "2                  -0.049104                  -0.061956   \n",
       "3                  -0.096801                  -0.093564   \n",
       "4                  -0.097233                  -0.093812   \n",
       "\n",
       "   mean concave pointspow_15  mean concave pointspow_16  \\\n",
       "0                   0.087897                   0.046261   \n",
       "1                  -0.091384                  -0.087601   \n",
       "2                  -0.069387                  -0.073320   \n",
       "3                  -0.090213                  -0.086975   \n",
       "4                  -0.090355                  -0.087056   \n",
       "\n",
       "   mean concave pointspow_17  mean concave pointspow_18  \\\n",
       "0                   0.015447                  -0.007177   \n",
       "1                  -0.084277                  -0.081320   \n",
       "2                  -0.075027                  -0.075340   \n",
       "3                  -0.083943                  -0.081142   \n",
       "4                  -0.083989                  -0.081168   \n",
       "\n",
       "   mean concave pointspow_19  mean concave pointspow_20  \\\n",
       "0                  -0.023637                  -0.035478   \n",
       "1                  -0.078661                  -0.076248   \n",
       "2                  -0.074802                  -0.073762   \n",
       "3                  -0.078567                  -0.076198   \n",
       "4                  -0.078581                  -0.076206   \n",
       "\n",
       "   mean concave pointspow_21  mean concave pointspow_22  \\\n",
       "0                  -0.043878                  -0.049725   \n",
       "1                  -0.074043                  -0.072015   \n",
       "2                  -0.072444                  -0.070987   \n",
       "3                  -0.074017                  -0.072001   \n",
       "4                  -0.074021                  -0.072003   \n",
       "\n",
       "   mean concave pointspow_23  mean symmetrypow_2  mean symmetrypow_3  \\\n",
       "0                  -0.053689            2.366655            2.457679   \n",
       "1                  -0.070140           -0.069864           -0.132200   \n",
       "2                  -0.069481            0.876405            0.785477   \n",
       "3                  -0.070133            3.213718            3.518282   \n",
       "4                  -0.070134           -0.080170           -0.141512   \n",
       "\n",
       "   mean symmetrypow_4  mean symmetrypow_5  mean symmetrypow_6  \\\n",
       "0            2.477865            2.422410            2.296459   \n",
       "1           -0.181362           -0.215000           -0.233026   \n",
       "2            0.673811            0.550886            0.427059   \n",
       "3            3.752626            3.893384            3.928255   \n",
       "4           -0.189434           -0.221716           -0.238396   \n",
       "\n",
       "   mean symmetrypow_7  mean symmetrypow_8  mean symmetrypow_9  \\\n",
       "0            2.114066            1.894525            1.657852   \n",
       "1           -0.237370           -0.231230           -0.218169   \n",
       "2            0.311518            0.210714            0.127801   \n",
       "3            3.858837            3.699122            3.470813   \n",
       "4           -0.241506           -0.234310           -0.220397   \n",
       "\n",
       "   mean symmetrypow_10  mean symmetrypow_11  mean symmetrypow_12  \\\n",
       "0             1.421215             1.197153             0.993397   \n",
       "1            -0.201390            -0.183354            -0.165709   \n",
       "2             0.063055             0.014792            -0.019652   \n",
       "3             3.197880             2.902328             2.601905   \n",
       "4            -0.202961            -0.184438            -0.166444   \n",
       "\n",
       "   mean symmetrypow_13  mean symmetrypow_14  mean symmetrypow_15  \\\n",
       "0             0.813646             0.658678             0.527400   \n",
       "1            -0.149409            -0.134898            -0.122288   \n",
       "2            -0.043177            -0.058468            -0.067783   \n",
       "3             2.309490             2.033516             1.778843   \n",
       "4            -0.149900            -0.135222            -0.122500   \n",
       "\n",
       "   mean symmetrypow_16  mean symmetrypow_17  mean symmetrypow_18  \\\n",
       "0             0.417684             0.326949             0.252530   \n",
       "1            -0.111498            -0.102350            -0.094632   \n",
       "2            -0.072907            -0.075188            -0.075607   \n",
       "3             1.547700             1.340510             1.156536   \n",
       "4            -0.111635            -0.102438            -0.094689   \n",
       "\n",
       "   mean symmetrypow_19  mean symmetrypow_20  mean symmetrypow_21  \\\n",
       "0             0.191900             0.142771             0.103144   \n",
       "1            -0.088132            -0.082652            -0.078022   \n",
       "2            -0.074859            -0.073424            -0.071624   \n",
       "3             0.994358             0.852196             0.728127   \n",
       "4            -0.088168            -0.082675            -0.078037   \n",
       "\n",
       "   mean symmetrypow_22  mean symmetrypow_23  mean fractal dimensionpow_2  \\\n",
       "0             0.071306             0.045818                     2.305800   \n",
       "1            -0.074096            -0.070753                    -0.818680   \n",
       "2            -0.069671            -0.067698                    -0.413104   \n",
       "3             0.620229             0.526659                     5.760674   \n",
       "4            -0.074106            -0.070758                    -0.557435   \n",
       "\n",
       "   mean fractal dimensionpow_3  mean fractal dimensionpow_4  \\\n",
       "0                     2.310406                     2.262748   \n",
       "1                    -0.757722                    -0.688064   \n",
       "2                    -0.417446                    -0.410757   \n",
       "3                     6.702479                     7.704943   \n",
       "4                    -0.540751                    -0.513057   \n",
       "\n",
       "   mean fractal dimensionpow_5  mean fractal dimensionpow_6  \\\n",
       "0                     2.161831                     2.013695   \n",
       "1                    -0.613145                    -0.537124   \n",
       "2                    -0.393930                    -0.369024   \n",
       "3                     8.725247                     9.717738   \n",
       "4                    -0.476238                    -0.433247   \n",
       "\n",
       "   mean fractal dimensionpow_7  mean fractal dimensionpow_8  \\\n",
       "0                     1.830364                     1.626859   \n",
       "1                    -0.464112                    -0.397382   \n",
       "2                    -0.338880                    -0.306495   \n",
       "3                    10.644172                    11.480753   \n",
       "4                    -0.387554                    -0.342423   \n",
       "\n",
       "   mean fractal dimensionpow_9  mean fractal dimensionpow_10  \\\n",
       "0                     1.417777                      1.214863   \n",
       "1                    -0.338916                     -0.289403   \n",
       "2                    -0.274439                     -0.244532   \n",
       "3                    12.219357                     12.864032   \n",
       "4                    -0.300356                     -0.262867   \n",
       "\n",
       "   mean fractal dimensionpow_11  mean fractal dimensionpow_12  \\\n",
       "0                      1.026079                      0.855854   \n",
       "1                     -0.248539                     -0.215429   \n",
       "2                     -0.217805                     -0.194651   \n",
       "3                     13.425793                     13.918119   \n",
       "4                     -0.230569                     -0.203419   \n",
       "\n",
       "   mean fractal dimensionpow_13  mean fractal dimensionpow_14  \\\n",
       "0                      0.705880                      0.576006   \n",
       "1                     -0.188923                     -0.167852   \n",
       "2                     -0.175026                     -0.158638   \n",
       "3                     14.354104                     14.745089   \n",
       "4                     -0.180984                     -0.162650   \n",
       "\n",
       "   mean fractal dimensionpow_15  mean fractal dimensionpow_16  \\\n",
       "0                      0.464983                      0.371002   \n",
       "1                     -0.151146                     -0.137894   \n",
       "2                     -0.145083                     -0.133928   \n",
       "3                     15.100281                     15.426875   \n",
       "4                     -0.147763                     -0.135708   \n",
       "\n",
       "   mean fractal dimensionpow_17  mean fractal dimensionpow_18  \\\n",
       "0                      0.292050                      0.226121   \n",
       "1                     -0.127347                     -0.118907   \n",
       "2                     -0.124767                     -0.117237   \n",
       "3                     15.730371                     16.014932   \n",
       "4                     -0.125942                     -0.118009   \n",
       "\n",
       "   mean fractal dimensionpow_19  mean fractal dimensionpow_20  \\\n",
       "0                      0.171334                      0.125991   \n",
       "1                     -0.112106                     -0.106578   \n",
       "2                     -0.111028                     -0.105885   \n",
       "3                     16.283696                     16.539036   \n",
       "4                     -0.111534                     -0.106215   \n",
       "\n",
       "   mean fractal dimensionpow_21  mean fractal dimensionpow_22  \\\n",
       "0                      0.088596                      0.057851   \n",
       "1                     -0.102042                     -0.098280   \n",
       "2                     -0.101598                     -0.097997   \n",
       "3                     16.782757                     17.016241   \n",
       "4                     -0.101812                     -0.098135   \n",
       "\n",
       "   mean fractal dimensionpow_23  radius errorpow_2  radius errorpow_3  \\\n",
       "0                      0.032648           1.838274           0.869136   \n",
       "1                     -0.095127           0.104493          -0.051786   \n",
       "2                     -0.094946           0.604361           0.151155   \n",
       "3                     17.240563           0.008994          -0.082806   \n",
       "4                     -0.095036           0.637808           0.166857   \n",
       "\n",
       "   radius errorpow_4  radius errorpow_5  radius errorpow_6  radius errorpow_7  \\\n",
       "0           0.328606           0.096865           0.004095          -0.031859   \n",
       "1          -0.071901          -0.066442          -0.060795          -0.057306   \n",
       "2          -0.006122          -0.046868          -0.055214          -0.055756   \n",
       "3          -0.079888          -0.068316          -0.061214          -0.057397   \n",
       "4          -0.000284          -0.044890          -0.054577          -0.055558   \n",
       "\n",
       "   radius errorpow_8  radius errorpow_9  radius errorpow_10  \\\n",
       "0          -0.045250          -0.049818           -0.050986   \n",
       "1          -0.055152          -0.053651           -0.052465   \n",
       "2          -0.054729          -0.053538           -0.052434   \n",
       "3          -0.055171          -0.053655           -0.052466   \n",
       "4          -0.054669          -0.053520           -0.052429   \n",
       "\n",
       "   radius errorpow_11  radius errorpow_12  radius errorpow_13  \\\n",
       "0           -0.050875           -0.050309           -0.049608   \n",
       "1           -0.051444           -0.050528           -0.049691   \n",
       "2           -0.051436           -0.050526           -0.049691   \n",
       "3           -0.051444           -0.050528           -0.049691   \n",
       "4           -0.051434           -0.050525           -0.049691   \n",
       "\n",
       "   radius errorpow_14  radius errorpow_15  radius errorpow_16  \\\n",
       "0           -0.048892           -0.048210           -0.047576   \n",
       "1           -0.048924           -0.048222           -0.047580   \n",
       "2           -0.048924           -0.048222           -0.047580   \n",
       "3           -0.048924           -0.048222           -0.047580   \n",
       "4           -0.048924           -0.048222           -0.047580   \n",
       "\n",
       "   radius errorpow_17  radius errorpow_18  radius errorpow_19  \\\n",
       "0           -0.046994           -0.046466           -0.045987   \n",
       "1           -0.046996           -0.046467           -0.045988   \n",
       "2           -0.046996           -0.046467           -0.045988   \n",
       "3           -0.046996           -0.046467           -0.045988   \n",
       "4           -0.046996           -0.046467           -0.045988   \n",
       "\n",
       "   radius errorpow_20  radius errorpow_21  radius errorpow_22  \\\n",
       "0           -0.045556           -0.045167           -0.044818   \n",
       "1           -0.045556           -0.045167           -0.044818   \n",
       "2           -0.045556           -0.045167           -0.044818   \n",
       "3           -0.045556           -0.045167           -0.044818   \n",
       "4           -0.045556           -0.045167           -0.044818   \n",
       "\n",
       "   radius errorpow_23  texture errorpow_2  texture errorpow_3  \\\n",
       "0           -0.044506           -0.494328           -0.344461   \n",
       "1           -0.044506           -0.638260           -0.393326   \n",
       "2           -0.044506           -0.596968           -0.380362   \n",
       "3           -0.044506           -0.229595           -0.231297   \n",
       "4           -0.044506           -0.601467           -0.381818   \n",
       "\n",
       "   texture errorpow_4  texture errorpow_5  texture errorpow_6  \\\n",
       "0           -0.216954           -0.140127           -0.098995   \n",
       "1           -0.230047           -0.143167           -0.099646   \n",
       "2           -0.226845           -0.142484           -0.099512   \n",
       "3           -0.178729           -0.128925           -0.095962   \n",
       "4           -0.227216           -0.142565           -0.099529   \n",
       "\n",
       "   texture errorpow_7  texture errorpow_8  texture errorpow_9  \\\n",
       "0           -0.077033           -0.064746           -0.057444   \n",
       "1           -0.077166           -0.064772           -0.057449   \n",
       "2           -0.077141           -0.064768           -0.057448   \n",
       "3           -0.076248           -0.064548           -0.057395   \n",
       "4           -0.077144           -0.064768           -0.057448   \n",
       "\n",
       "   texture errorpow_10  texture errorpow_11  texture errorpow_12  \\\n",
       "0            -0.052848            -0.049813             -0.04773   \n",
       "1            -0.052849            -0.049813             -0.04773   \n",
       "2            -0.052849            -0.049813             -0.04773   \n",
       "3            -0.052836            -0.049810             -0.04773   \n",
       "4            -0.052849            -0.049813             -0.04773   \n",
       "\n",
       "   texture errorpow_13  texture errorpow_14  texture errorpow_15  \\\n",
       "0             -0.04626            -0.045198            -0.044417   \n",
       "1             -0.04626            -0.045198            -0.044417   \n",
       "2             -0.04626            -0.045198            -0.044417   \n",
       "3             -0.04626            -0.045197            -0.044417   \n",
       "4             -0.04626            -0.045198            -0.044417   \n",
       "\n",
       "   texture errorpow_16  texture errorpow_17  texture errorpow_18  \\\n",
       "0            -0.043837            -0.043401             -0.04307   \n",
       "1            -0.043837            -0.043401             -0.04307   \n",
       "2            -0.043837            -0.043401             -0.04307   \n",
       "3            -0.043837            -0.043401             -0.04307   \n",
       "4            -0.043837            -0.043401             -0.04307   \n",
       "\n",
       "   texture errorpow_19  texture errorpow_20  texture errorpow_21  \\\n",
       "0            -0.042818            -0.042625            -0.042477   \n",
       "1            -0.042818            -0.042625            -0.042477   \n",
       "2            -0.042818            -0.042625            -0.042477   \n",
       "3            -0.042818            -0.042625            -0.042477   \n",
       "4            -0.042818            -0.042625            -0.042477   \n",
       "\n",
       "   texture errorpow_22  texture errorpow_23  perimeter errorpow_2  \\\n",
       "0            -0.042362            -0.042274              2.114772   \n",
       "1            -0.042362            -0.042274             -0.025752   \n",
       "2            -0.042362            -0.042274              0.300216   \n",
       "3            -0.042362            -0.042274             -0.014688   \n",
       "4            -0.042362            -0.042274              0.594323   \n",
       "\n",
       "   perimeter errorpow_3  perimeter errorpow_4  perimeter errorpow_5  \\\n",
       "0              1.018757              0.401959              0.131759   \n",
       "1             -0.088904             -0.078015             -0.065405   \n",
       "2              0.017602             -0.050113             -0.058704   \n",
       "3             -0.085827             -0.077334             -0.065268   \n",
       "4              0.137661             -0.011005             -0.047079   \n",
       "\n",
       "   perimeter errorpow_6  perimeter errorpow_7  perimeter errorpow_8  \\\n",
       "0              0.021030             -0.022894             -0.039681   \n",
       "1             -0.058344             -0.054529             -0.052215   \n",
       "2             -0.056805             -0.054185             -0.052140   \n",
       "3             -0.058317             -0.054524             -0.052214   \n",
       "4             -0.053517             -0.053285             -0.051898   \n",
       "\n",
       "   perimeter errorpow_9  perimeter errorpow_10  perimeter errorpow_11  \\\n",
       "0             -0.045648              -0.047383              -0.047516   \n",
       "1             -0.050594              -0.049329              -0.048281   \n",
       "2             -0.050578              -0.049326              -0.048280   \n",
       "3             -0.050594              -0.049329              -0.048281   \n",
       "4             -0.050514              -0.049309              -0.048276   \n",
       "\n",
       "   perimeter errorpow_12  perimeter errorpow_13  perimeter errorpow_14  \\\n",
       "0              -0.047087              -0.046499              -0.045904   \n",
       "1              -0.047387              -0.046616              -0.045950   \n",
       "2              -0.047387              -0.046616              -0.045950   \n",
       "3              -0.047387              -0.046616              -0.045950   \n",
       "4              -0.047386              -0.046616              -0.045950   \n",
       "\n",
       "   perimeter errorpow_15  perimeter errorpow_16  perimeter errorpow_17  \\\n",
       "0              -0.045356              -0.044871              -0.044448   \n",
       "1              -0.045374              -0.044878              -0.044451   \n",
       "2              -0.045374              -0.044878              -0.044451   \n",
       "3              -0.045374              -0.044878              -0.044451   \n",
       "4              -0.045374              -0.044878              -0.044451   \n",
       "\n",
       "   perimeter errorpow_18  perimeter errorpow_19  perimeter errorpow_20  \\\n",
       "0              -0.044083               -0.04377              -0.043501   \n",
       "1              -0.044084               -0.04377              -0.043501   \n",
       "2              -0.044084               -0.04377              -0.043501   \n",
       "3              -0.044084               -0.04377              -0.043501   \n",
       "4              -0.044084               -0.04377              -0.043501   \n",
       "\n",
       "   perimeter errorpow_21  perimeter errorpow_22  perimeter errorpow_23  \\\n",
       "0              -0.043272              -0.043076              -0.042909   \n",
       "1              -0.043272              -0.043076              -0.042909   \n",
       "2              -0.043272              -0.043076              -0.042909   \n",
       "3              -0.043272              -0.043076              -0.042909   \n",
       "4              -0.043272              -0.043076              -0.042909   \n",
       "\n",
       "   area errorpow_2  area errorpow_3  area errorpow_4  area errorpow_5  \\\n",
       "0         1.122429         0.307163         0.047173        -0.028782   \n",
       "1         0.101556        -0.046248        -0.061306        -0.060825   \n",
       "2         0.291306         0.000625        -0.051350        -0.058841   \n",
       "3        -0.166984        -0.088874        -0.067431        -0.061683   \n",
       "4         0.295678         0.001830        -0.051065        -0.058779   \n",
       "\n",
       "   area errorpow_6  area errorpow_7  area errorpow_8  area errorpow_9  \\\n",
       "0        -0.050521        -0.056632        -0.058274        -0.058644   \n",
       "1        -0.059833        -0.059317        -0.059045        -0.058865   \n",
       "2        -0.059452        -0.059245        -0.059032        -0.058862   \n",
       "3        -0.059952        -0.059333        -0.059048        -0.058865   \n",
       "4        -0.059439        -0.059243        -0.059032        -0.058862   \n",
       "\n",
       "   area errorpow_10  area errorpow_11  area errorpow_12  area errorpow_13  \\\n",
       "0         -0.058648         -0.058543         -0.058400         -0.058240   \n",
       "1         -0.058711         -0.058561         -0.058406         -0.058242   \n",
       "2         -0.058711         -0.058561         -0.058406         -0.058242   \n",
       "3         -0.058711         -0.058561         -0.058406         -0.058242   \n",
       "4         -0.058711         -0.058561         -0.058406         -0.058242   \n",
       "\n",
       "   area errorpow_14  area errorpow_15  area errorpow_16  area errorpow_17  \\\n",
       "0         -0.058069         -0.057887         -0.057696         -0.057498   \n",
       "1         -0.058069         -0.057887         -0.057696         -0.057498   \n",
       "2         -0.058069         -0.057887         -0.057696         -0.057498   \n",
       "3         -0.058069         -0.057887         -0.057696         -0.057498   \n",
       "4         -0.058069         -0.057887         -0.057696         -0.057498   \n",
       "\n",
       "   area errorpow_18  area errorpow_19  area errorpow_20  area errorpow_21  \\\n",
       "0         -0.057291         -0.057078         -0.056858         -0.056632   \n",
       "1         -0.057291         -0.057078         -0.056858         -0.056632   \n",
       "2         -0.057291         -0.057078         -0.056858         -0.056632   \n",
       "3         -0.057291         -0.057078         -0.056858         -0.056632   \n",
       "4         -0.057291         -0.057078         -0.056858         -0.056632   \n",
       "\n",
       "   area errorpow_22  area errorpow_23  smoothness errorpow_2  \\\n",
       "0         -0.056402         -0.056167              -0.261577   \n",
       "1         -0.056402         -0.056167              -0.464082   \n",
       "2         -0.056402         -0.056167              -0.307945   \n",
       "3         -0.056402         -0.056167               0.362335   \n",
       "4         -0.056402         -0.056167               1.089872   \n",
       "\n",
       "   smoothness errorpow_3  smoothness errorpow_4  smoothness errorpow_5  \\\n",
       "0              -0.210715              -0.143048              -0.098239   \n",
       "1              -0.284819              -0.164210              -0.103528   \n",
       "2              -0.228973              -0.148640              -0.099733   \n",
       "3               0.095963              -0.024644              -0.057979   \n",
       "4               0.568271               0.214881               0.048451   \n",
       "\n",
       "   smoothness errorpow_6  smoothness errorpow_7  smoothness errorpow_8  \\\n",
       "0              -0.073777              -0.060812              -0.053703   \n",
       "1              -0.075011              -0.061089              -0.053763   \n",
       "2              -0.074149              -0.060901              -0.053723   \n",
       "3              -0.060929              -0.056848              -0.052503   \n",
       "4              -0.016753              -0.039197              -0.045612   \n",
       "\n",
       "   smoothness errorpow_9  smoothness errorpow_10  smoothness errorpow_11  \\\n",
       "0              -0.049587               -0.047073               -0.045467   \n",
       "1              -0.049600               -0.047076               -0.045468   \n",
       "2              -0.049591               -0.047074               -0.045468   \n",
       "3              -0.049228               -0.046966               -0.045436   \n",
       "4              -0.046578               -0.045958               -0.045055   \n",
       "\n",
       "   smoothness errorpow_12  smoothness errorpow_13  smoothness errorpow_14  \\\n",
       "0               -0.044406               -0.043687               -0.043190   \n",
       "1               -0.044406               -0.043687               -0.043190   \n",
       "2               -0.044406               -0.043687               -0.043190   \n",
       "3               -0.044397               -0.043684               -0.043189   \n",
       "4               -0.044254               -0.043631               -0.043169   \n",
       "\n",
       "   smoothness errorpow_15  smoothness errorpow_16  smoothness errorpow_17  \\\n",
       "0               -0.042842               -0.042596               -0.042420   \n",
       "1               -0.042842               -0.042596               -0.042420   \n",
       "2               -0.042842               -0.042596               -0.042420   \n",
       "3               -0.042842               -0.042596               -0.042420   \n",
       "4               -0.042834               -0.042593               -0.042419   \n",
       "\n",
       "   smoothness errorpow_18  smoothness errorpow_19  smoothness errorpow_20  \\\n",
       "0               -0.042294               -0.042204               -0.042138   \n",
       "1               -0.042294               -0.042204               -0.042138   \n",
       "2               -0.042294               -0.042204               -0.042138   \n",
       "3               -0.042294               -0.042204               -0.042138   \n",
       "4               -0.042294               -0.042203               -0.042138   \n",
       "\n",
       "   smoothness errorpow_21  smoothness errorpow_22  smoothness errorpow_23  \\\n",
       "0                -0.04209               -0.042055                -0.04203   \n",
       "1                -0.04209               -0.042055                -0.04203   \n",
       "2                -0.04209               -0.042055                -0.04203   \n",
       "3                -0.04209               -0.042055                -0.04203   \n",
       "4                -0.04209               -0.042055                -0.04203   \n",
       "\n",
       "   compactness errorpow_2  compactness errorpow_3  compactness errorpow_4  \\\n",
       "0                0.880017                0.410043                0.121611   \n",
       "1               -0.489270               -0.308102               -0.198994   \n",
       "2                0.389564                0.077045               -0.057137   \n",
       "3                2.815338                2.252833                1.523076   \n",
       "4               -0.222892               -0.229476               -0.180188   \n",
       "\n",
       "   compactness errorpow_5  compactness errorpow_6  compactness errorpow_7  \\\n",
       "0               -0.007938               -0.053169               -0.063647   \n",
       "1               -0.138166               -0.103331               -0.082421   \n",
       "2               -0.090908               -0.088438               -0.077866   \n",
       "3                0.922499                0.517459                0.270843   \n",
       "4               -0.134192               -0.102547               -0.082273   \n",
       "\n",
       "   compactness errorpow_8  compactness errorpow_9  compactness errorpow_10  \\\n",
       "0               -0.062411               -0.058323                -0.054292   \n",
       "1               -0.069331               -0.060853                -0.055213   \n",
       "2               -0.067959               -0.060443                -0.055091   \n",
       "3                0.128691                0.049261                 0.005756   \n",
       "4               -0.069303               -0.060848                -0.055212   \n",
       "\n",
       "   compactness errorpow_11  compactness errorpow_12  compactness errorpow_13  \\\n",
       "0                -0.051045                -0.048606                -0.046822   \n",
       "1                -0.051379                -0.048727                -0.046866   \n",
       "2                -0.051343                -0.048717                -0.046863   \n",
       "3                -0.017700                -0.030146                -0.036622   \n",
       "4                -0.051379                -0.048727                -0.046866   \n",
       "\n",
       "   compactness errorpow_14  compactness errorpow_15  compactness errorpow_16  \\\n",
       "0                -0.045528                -0.044590                -0.043908   \n",
       "1                -0.045544                -0.044596                -0.043910   \n",
       "2                -0.045543                -0.044596                -0.043910   \n",
       "3                -0.039899                -0.041486                -0.042196   \n",
       "4                -0.045544                -0.044596                -0.043910   \n",
       "\n",
       "   compactness errorpow_17  compactness errorpow_18  compactness errorpow_19  \\\n",
       "0                -0.043409                -0.043042                -0.042771   \n",
       "1                -0.043410                -0.043042                -0.042772   \n",
       "2                -0.043410                -0.043042                -0.042772   \n",
       "3                -0.042466                -0.042523                -0.042485   \n",
       "4                -0.043410                -0.043042                -0.042772   \n",
       "\n",
       "   compactness errorpow_20  compactness errorpow_21  compactness errorpow_22  \\\n",
       "0                -0.042571                -0.042421                -0.042309   \n",
       "1                -0.042571                -0.042421                -0.042309   \n",
       "2                -0.042571                -0.042421                -0.042309   \n",
       "3                -0.042413                -0.042334                -0.042261   \n",
       "4                -0.042571                -0.042421                -0.042309   \n",
       "\n",
       "   compactness errorpow_23  concavity errorpow_2  concavity errorpow_3  \\\n",
       "0                -0.042225              0.120716             -0.036389   \n",
       "1                -0.042225             -0.198763             -0.088319   \n",
       "2                -0.042225             -0.057633             -0.070913   \n",
       "3                -0.042198              0.160671             -0.027202   \n",
       "4                -0.042225              0.164524             -0.026291   \n",
       "\n",
       "   concavity errorpow_4  concavity errorpow_5  concavity errorpow_6  \\\n",
       "0             -0.053806             -0.052445             -0.050007   \n",
       "1             -0.061344             -0.053501             -0.050153   \n",
       "2             -0.059475             -0.053310             -0.050134   \n",
       "3             -0.052030             -0.052128             -0.049953   \n",
       "4             -0.051849             -0.052095             -0.049947   \n",
       "\n",
       "   concavity errorpow_7  concavity errorpow_8  concavity errorpow_9  \\\n",
       "0             -0.048136             -0.046734             -0.045659   \n",
       "1             -0.048156             -0.046737             -0.045659   \n",
       "2             -0.048154             -0.046736             -0.045659   \n",
       "3             -0.048127             -0.046732             -0.045659   \n",
       "4             -0.048126             -0.046732             -0.045659   \n",
       "\n",
       "   concavity errorpow_10  concavity errorpow_11  concavity errorpow_12  \\\n",
       "0              -0.044824              -0.044175               -0.04367   \n",
       "1              -0.044824              -0.044175               -0.04367   \n",
       "2              -0.044824              -0.044175               -0.04367   \n",
       "3              -0.044824              -0.044175               -0.04367   \n",
       "4              -0.044824              -0.044175               -0.04367   \n",
       "\n",
       "   concavity errorpow_13  concavity errorpow_14  concavity errorpow_15  \\\n",
       "0              -0.043278              -0.042975               -0.04274   \n",
       "1              -0.043278              -0.042975               -0.04274   \n",
       "2              -0.043278              -0.042975               -0.04274   \n",
       "3              -0.043278              -0.042975               -0.04274   \n",
       "4              -0.043278              -0.042975               -0.04274   \n",
       "\n",
       "   concavity errorpow_16  concavity errorpow_17  concavity errorpow_18  \\\n",
       "0               -0.04256              -0.042421              -0.042314   \n",
       "1               -0.04256              -0.042421              -0.042314   \n",
       "2               -0.04256              -0.042421              -0.042314   \n",
       "3               -0.04256              -0.042421              -0.042314   \n",
       "4               -0.04256              -0.042421              -0.042314   \n",
       "\n",
       "   concavity errorpow_19  concavity errorpow_20  concavity errorpow_21  \\\n",
       "0              -0.042231              -0.042168               -0.04212   \n",
       "1              -0.042231              -0.042168               -0.04212   \n",
       "2              -0.042231              -0.042168               -0.04212   \n",
       "3              -0.042231              -0.042168               -0.04212   \n",
       "4              -0.042231              -0.042168               -0.04212   \n",
       "\n",
       "   concavity errorpow_22  concavity errorpow_23  concave points errorpow_2  \\\n",
       "0              -0.042082              -0.042054                   0.343497   \n",
       "1              -0.042082              -0.042054                   0.011062   \n",
       "2              -0.042082              -0.042054                   1.132912   \n",
       "3              -0.042082              -0.042054                   0.788197   \n",
       "4              -0.042082              -0.042054                   0.819252   \n",
       "\n",
       "   concave points errorpow_3  concave points errorpow_4  \\\n",
       "0                   0.079206                  -0.039885   \n",
       "1                  -0.108024                  -0.121472   \n",
       "2                   0.634639                   0.263418   \n",
       "3                   0.374707                   0.112009   \n",
       "4                   0.397074                   0.124444   \n",
       "\n",
       "   concave points errorpow_5  concave points errorpow_6  \\\n",
       "0                  -0.070927                  -0.070982   \n",
       "1                  -0.101715                  -0.081731   \n",
       "2                   0.072932                  -0.007671   \n",
       "3                  -0.003325                  -0.043151   \n",
       "4                   0.002648                  -0.040502   \n",
       "\n",
       "   concave points errorpow_7  concave points errorpow_8  \\\n",
       "0                  -0.064285                  -0.057924   \n",
       "1                  -0.067874                  -0.059089   \n",
       "2                  -0.037566                  -0.046928   \n",
       "3                  -0.053329                  -0.053730   \n",
       "4                  -0.052209                  -0.053270   \n",
       "\n",
       "   concave points errorpow_9  concave points errorpow_10  \\\n",
       "0                  -0.053192                   -0.049895   \n",
       "1                  -0.053563                   -0.050012   \n",
       "2                  -0.048738                   -0.048111   \n",
       "3                  -0.051616                   -0.049311   \n",
       "4                  -0.051431                   -0.049238   \n",
       "\n",
       "   concave points errorpow_11  concave points errorpow_12  \\\n",
       "0                   -0.047627                   -0.046054   \n",
       "1                   -0.047663                   -0.046066   \n",
       "2                   -0.046917                   -0.045773   \n",
       "3                   -0.047412                   -0.045976   \n",
       "4                   -0.047384                   -0.045965   \n",
       "\n",
       "   concave points errorpow_13  concave points errorpow_14  \\\n",
       "0                   -0.044949                   -0.044161   \n",
       "1                   -0.044952                   -0.044162   \n",
       "2                   -0.044838                   -0.044118   \n",
       "3                   -0.044921                   -0.044151   \n",
       "4                   -0.044916                   -0.044149   \n",
       "\n",
       "   concave points errorpow_15  concave points errorpow_16  \\\n",
       "0                   -0.043592                   -0.043177   \n",
       "1                   -0.043593                   -0.043177   \n",
       "2                   -0.043575                   -0.043171   \n",
       "3                   -0.043589                   -0.043176   \n",
       "4                   -0.043588                   -0.043176   \n",
       "\n",
       "   concave points errorpow_17  concave points errorpow_18  \\\n",
       "0                   -0.042872                   -0.042646   \n",
       "1                   -0.042872                   -0.042646   \n",
       "2                   -0.042869                   -0.042645   \n",
       "3                   -0.042872                   -0.042646   \n",
       "4                   -0.042871                   -0.042646   \n",
       "\n",
       "   concave points errorpow_19  concave points errorpow_20  \\\n",
       "0                   -0.042477                   -0.042351   \n",
       "1                   -0.042477                   -0.042351   \n",
       "2                   -0.042477                   -0.042351   \n",
       "3                   -0.042477                   -0.042351   \n",
       "4                   -0.042477                   -0.042351   \n",
       "\n",
       "   concave points errorpow_21  concave points errorpow_22  \\\n",
       "0                   -0.042256                   -0.042185   \n",
       "1                   -0.042256                   -0.042185   \n",
       "2                   -0.042256                   -0.042185   \n",
       "3                   -0.042256                   -0.042185   \n",
       "4                   -0.042256                   -0.042185   \n",
       "\n",
       "   concave points errorpow_23  symmetry errorpow_2  symmetry errorpow_3  \\\n",
       "0                   -0.042131             0.803879             0.420721   \n",
       "1                   -0.042131            -0.580577            -0.370481   \n",
       "2                   -0.042131             0.031349            -0.088036   \n",
       "3                   -0.042131             5.987146             6.417572   \n",
       "4                   -0.042131            -0.355153            -0.281804   \n",
       "\n",
       "   symmetry errorpow_4  symmetry errorpow_5  symmetry errorpow_6  \\\n",
       "0             0.152619             0.016348            -0.038466   \n",
       "1            -0.228466            -0.148382            -0.105495   \n",
       "2            -0.120888            -0.112208            -0.094182   \n",
       "3             5.962052             5.043404             4.043356   \n",
       "4            -0.200053            -0.140440            -0.103452   \n",
       "\n",
       "   symmetry errorpow_7  symmetry errorpow_8  symmetry errorpow_9  \\\n",
       "0            -0.055502            -0.057971            -0.055842   \n",
       "1            -0.081916            -0.068207            -0.059775   \n",
       "2            -0.078519            -0.067210            -0.059485   \n",
       "3             3.147704             2.410992             1.829285   \n",
       "4            -0.081415            -0.068089            -0.059747   \n",
       "\n",
       "   symmetry errorpow_10  symmetry errorpow_11  symmetry errorpow_12  \\\n",
       "0             -0.052837             -0.050142             -0.048015   \n",
       "1             -0.054341             -0.050716             -0.048233   \n",
       "2             -0.054258             -0.050692             -0.048227   \n",
       "3              1.379334              1.035009              0.773018   \n",
       "4             -0.054335             -0.050714             -0.048233   \n",
       "\n",
       "   symmetry errorpow_13  symmetry errorpow_14  symmetry errorpow_15  \\\n",
       "0             -0.046418             -0.045242             -0.044382   \n",
       "1             -0.046501             -0.045273             -0.044394   \n",
       "2             -0.046499             -0.045273             -0.044394   \n",
       "3              0.574295              0.423825              0.310004   \n",
       "4             -0.046501             -0.045273             -0.044394   \n",
       "\n",
       "   symmetry errorpow_16  symmetry errorpow_17  symmetry errorpow_18  \\\n",
       "0             -0.043753             -0.043292             -0.042953   \n",
       "1             -0.043758             -0.043294             -0.042954   \n",
       "2             -0.043758             -0.043294             -0.042954   \n",
       "3              0.223954              0.158922              0.109784   \n",
       "4             -0.043758             -0.043294             -0.042954   \n",
       "\n",
       "   symmetry errorpow_19  symmetry errorpow_20  symmetry errorpow_21  \\\n",
       "0             -0.042703             -0.042517             -0.042379   \n",
       "1             -0.042703             -0.042517             -0.042379   \n",
       "2             -0.042703             -0.042517             -0.042379   \n",
       "3              0.072661              0.044617              0.023433   \n",
       "4             -0.042703             -0.042517             -0.042379   \n",
       "\n",
       "   symmetry errorpow_22  symmetry errorpow_23  fractal dimension errorpow_2  \\\n",
       "0             -0.042276             -0.042199                      0.316620   \n",
       "1             -0.042276             -0.042199                     -0.166418   \n",
       "2             -0.042276             -0.042199                     -0.009270   \n",
       "3              0.007431             -0.004656                      1.183350   \n",
       "4             -0.042276             -0.042199                      0.089083   \n",
       "\n",
       "   fractal dimension errorpow_3  fractal dimension errorpow_4  \\\n",
       "0                      0.023195                     -0.050581   \n",
       "1                     -0.121644                     -0.086413   \n",
       "2                     -0.083129                     -0.078760   \n",
       "3                      0.429878                      0.105184   \n",
       "4                     -0.054440                     -0.072005   \n",
       "\n",
       "   fractal dimension errorpow_5  fractal dimension errorpow_6  \\\n",
       "0                     -0.060641                     -0.057979   \n",
       "1                     -0.068804                     -0.059764   \n",
       "2                     -0.067425                     -0.059528   \n",
       "3                     -0.006200                     -0.039864   \n",
       "4                     -0.065989                     -0.059241   \n",
       "\n",
       "   fractal dimension errorpow_7  fractal dimension errorpow_8  \\\n",
       "0                     -0.054115                     -0.050990   \n",
       "1                     -0.054496                     -0.051071   \n",
       "2                     -0.054457                     -0.051064   \n",
       "3                     -0.048257                     -0.049129   \n",
       "4                     -0.054402                     -0.051054   \n",
       "\n",
       "   fractal dimension errorpow_9  fractal dimension errorpow_10  \\\n",
       "0                     -0.048672                      -0.046967   \n",
       "1                     -0.048688                      -0.046970   \n",
       "2                     -0.048687                      -0.046970   \n",
       "3                     -0.048086                      -0.046784   \n",
       "4                     -0.048685                      -0.046970   \n",
       "\n",
       "   fractal dimension errorpow_11  fractal dimension errorpow_12  \\\n",
       "0                      -0.045707                      -0.044771   \n",
       "1                      -0.045708                      -0.044771   \n",
       "2                      -0.045708                      -0.044771   \n",
       "3                      -0.045651                      -0.044754   \n",
       "4                      -0.045708                      -0.044771   \n",
       "\n",
       "   fractal dimension errorpow_13  fractal dimension errorpow_14  \\\n",
       "0                      -0.044072                      -0.043549   \n",
       "1                      -0.044072                      -0.043549   \n",
       "2                      -0.044072                      -0.043549   \n",
       "3                      -0.044067                      -0.043548   \n",
       "4                      -0.044072                      -0.043549   \n",
       "\n",
       "   fractal dimension errorpow_15  fractal dimension errorpow_16  \\\n",
       "0                      -0.043157                      -0.042862   \n",
       "1                      -0.043157                      -0.042862   \n",
       "2                      -0.043157                      -0.042862   \n",
       "3                      -0.043156                      -0.042862   \n",
       "4                      -0.043157                      -0.042862   \n",
       "\n",
       "   fractal dimension errorpow_17  fractal dimension errorpow_18  \\\n",
       "0                       -0.04264                      -0.042473   \n",
       "1                       -0.04264                      -0.042473   \n",
       "2                       -0.04264                      -0.042473   \n",
       "3                       -0.04264                      -0.042473   \n",
       "4                       -0.04264                      -0.042473   \n",
       "\n",
       "   fractal dimension errorpow_19  fractal dimension errorpow_20  \\\n",
       "0                      -0.042347                      -0.042253   \n",
       "1                      -0.042347                      -0.042253   \n",
       "2                      -0.042347                      -0.042253   \n",
       "3                      -0.042347                      -0.042253   \n",
       "4                      -0.042347                      -0.042253   \n",
       "\n",
       "   fractal dimension errorpow_21  fractal dimension errorpow_22  \\\n",
       "0                      -0.042181                      -0.042127   \n",
       "1                      -0.042181                      -0.042127   \n",
       "2                      -0.042181                      -0.042127   \n",
       "3                      -0.042181                      -0.042127   \n",
       "4                      -0.042181                      -0.042127   \n",
       "\n",
       "   fractal dimension errorpow_23  worst radiuspow_2  worst radiuspow_3  \\\n",
       "0                      -0.042086           1.921784           1.847893   \n",
       "1                      -0.042086           1.815780           1.720680   \n",
       "2                      -0.042086           1.443686           1.290070   \n",
       "3                      -0.042086          -0.354515          -0.386317   \n",
       "4                      -0.042086           1.187404           1.008481   \n",
       "\n",
       "   worst radiuspow_4  worst radiuspow_5  worst radiuspow_6  worst radiuspow_7  \\\n",
       "0           1.677322           1.441883           1.180547           0.926443   \n",
       "1           1.536875           1.297951           1.042112           0.800044   \n",
       "2           1.078309           0.844533           0.621236           0.429078   \n",
       "3          -0.382477          -0.354740          -0.315531          -0.274235   \n",
       "4           0.793636           0.577353           0.385856           0.232194   \n",
       "\n",
       "   worst radiuspow_8  worst radiuspow_9  worst radiuspow_10  \\\n",
       "0           0.700411           0.511443            0.360330   \n",
       "1           0.589707           0.417638            0.282911   \n",
       "2           0.275983           0.160884            0.078193   \n",
       "3          -0.236206          -0.203597           -0.176670   \n",
       "4           0.117992           0.038207           -0.014599   \n",
       "\n",
       "   worst radiuspow_11  worst radiuspow_12  worst radiuspow_13  \\\n",
       "0            0.243414            0.155250            0.090159   \n",
       "1            0.180860            0.105573            0.051265   \n",
       "2            0.021015           -0.017129           -0.041618   \n",
       "3           -0.154822           -0.137189           -0.122927   \n",
       "4           -0.047709           -0.067163           -0.077535   \n",
       "\n",
       "   worst radiuspow_14  worst radiuspow_15  worst radiuspow_16  \\\n",
       "0            0.042985            0.009389           -0.014114   \n",
       "1            0.012892           -0.013664           -0.031626   \n",
       "2           -0.056608           -0.065167           -0.069482   \n",
       "3           -0.111318           -0.101788           -0.093893   \n",
       "4           -0.082092           -0.083072           -0.081959   \n",
       "\n",
       "   worst radiuspow_17  worst radiuspow_18  worst radiuspow_19  \\\n",
       "0           -0.030232           -0.041024           -0.048023   \n",
       "1           -0.043440           -0.050925           -0.055406   \n",
       "2           -0.071075           -0.070980           -0.069887   \n",
       "3           -0.087292           -0.081723           -0.076988   \n",
       "4           -0.079708           -0.076918           -0.073951   \n",
       "\n",
       "   worst radiuspow_20  worst radiuspow_21  worst radiuspow_22  \\\n",
       "0           -0.052356           -0.054841           -0.056065   \n",
       "1           -0.057836           -0.058893           -0.059050   \n",
       "2           -0.068248           -0.066350           -0.064375   \n",
       "3           -0.072933           -0.069436           -0.066405   \n",
       "4           -0.071016           -0.068229           -0.065645   \n",
       "\n",
       "   worst radiuspow_23  worst texturepow_2  worst texturepow_3  \\\n",
       "0           -0.056445           -1.172777           -0.979019   \n",
       "1           -0.058638           -0.440498           -0.472761   \n",
       "2           -0.062429           -0.133771           -0.219743   \n",
       "3           -0.063764            0.015432           -0.088962   \n",
       "4           -0.063286           -1.239117           -1.017018   \n",
       "\n",
       "   worst texturepow_4  worst texturepow_5  worst texturepow_6  \\\n",
       "0           -0.796102           -0.635755           -0.503246   \n",
       "1           -0.468127           -0.435678           -0.387476   \n",
       "2           -0.273838           -0.296086           -0.292929   \n",
       "3           -0.167180           -0.214741           -0.234473   \n",
       "4           -0.816354           -0.645848           -0.507986   \n",
       "\n",
       "   worst texturepow_7  worst texturepow_8  worst texturepow_9  \\\n",
       "0           -0.398567           -0.318409           -0.258136   \n",
       "1           -0.334470           -0.284149           -0.240315   \n",
       "2           -0.273551           -0.246463           -0.217744   \n",
       "3           -0.233610           -0.220274           -0.201127   \n",
       "4           -0.400683           -0.319316           -0.258512   \n",
       "\n",
       "   worst texturepow_10  worst texturepow_11  worst texturepow_12  \\\n",
       "0            -0.213145            -0.179533            -0.154254   \n",
       "1            -0.204065            -0.174978            -0.151996   \n",
       "2            -0.190887            -0.167436            -0.147748   \n",
       "3            -0.180614            -0.161214            -0.144041   \n",
       "4            -0.213297            -0.179593            -0.154278   \n",
       "\n",
       "   worst texturepow_13  worst texturepow_14  worst texturepow_15  \\\n",
       "0            -0.135045            -0.120262            -0.108728   \n",
       "1            -0.133935            -0.119721            -0.108465   \n",
       "2            -0.131573            -0.118421            -0.107756   \n",
       "3            -0.129393            -0.117153            -0.107025   \n",
       "4            -0.135054            -0.120266            -0.108729   \n",
       "\n",
       "   worst texturepow_16  worst texturepow_17  worst texturepow_18  \\\n",
       "0            -0.099597            -0.092266            -0.086296   \n",
       "1            -0.099471            -0.092205            -0.086266   \n",
       "2            -0.099086            -0.091998            -0.086155   \n",
       "3            -0.098668            -0.091760            -0.086021   \n",
       "4            -0.099598            -0.092266            -0.086296   \n",
       "\n",
       "   worst texturepow_19  worst texturepow_20  worst texturepow_21  \\\n",
       "0            -0.081369            -0.077251            -0.073768   \n",
       "1            -0.081355            -0.077244            -0.073765   \n",
       "2            -0.081295            -0.077212            -0.073748   \n",
       "3            -0.081220            -0.077170            -0.073724   \n",
       "4            -0.081369            -0.077251            -0.073768   \n",
       "\n",
       "   worst texturepow_22  worst texturepow_23  worst perimeterpow_2  \\\n",
       "0            -0.070790            -0.068219              2.492689   \n",
       "1            -0.070789            -0.068218              1.462870   \n",
       "2            -0.070780            -0.068214              1.234909   \n",
       "3            -0.070767            -0.068207             -0.332068   \n",
       "4            -0.070790            -0.068219              1.224283   \n",
       "\n",
       "   worst perimeterpow_3  worst perimeterpow_4  worst perimeterpow_5  \\\n",
       "0              2.543999              2.445668              2.222294   \n",
       "1              1.293632              1.060699              0.808032   \n",
       "2              1.043160              0.810070              0.577228   \n",
       "3             -0.367998             -0.363894             -0.333727   \n",
       "4              1.031734              0.798883              0.567149   \n",
       "\n",
       "   worst perimeterpow_6  worst perimeterpow_7  worst perimeterpow_8  \\\n",
       "0              1.921809              1.594595              1.279107   \n",
       "1              0.573302              0.378247              0.229063   \n",
       "2              0.375171              0.217623              0.104640   \n",
       "3             -0.291987             -0.249090             -0.210548   \n",
       "4              0.366707              0.210911              0.099555   \n",
       "\n",
       "   worst perimeterpow_9  worst perimeterpow_10  worst perimeterpow_11  \\\n",
       "0              0.997964               0.760563               0.567601   \n",
       "1              0.121982               0.048953               0.001324   \n",
       "2              0.028995              -0.018611              -0.046690   \n",
       "3             -0.178276              -0.152228              -0.131557   \n",
       "4              0.025279              -0.021251              -0.048524   \n",
       "\n",
       "   worst perimeterpow_12  worst perimeterpow_13  worst perimeterpow_14  \\\n",
       "0               0.415048               0.296902               0.206825   \n",
       "1              -0.028400              -0.046032              -0.055781   \n",
       "2              -0.061927              -0.069116              -0.071497   \n",
       "3              -0.115236              -0.102328              -0.092061   \n",
       "4              -0.063178              -0.069959              -0.072058   \n",
       "\n",
       "   worst perimeterpow_15  worst perimeterpow_16  worst perimeterpow_17  \\\n",
       "0               0.138982               0.088385               0.050959   \n",
       "1              -0.060558              -0.062305              -0.062282   \n",
       "2              -0.071160              -0.069404              -0.067006   \n",
       "3              -0.083834              -0.077188              -0.071774   \n",
       "4              -0.071530              -0.069646              -0.067163   \n",
       "\n",
       "   worst perimeterpow_18  worst perimeterpow_19  worst perimeterpow_20  \\\n",
       "0               0.023477               0.003434              -0.011086   \n",
       "1              -0.061288              -0.059815              -0.058158   \n",
       "2              -0.064415              -0.061876              -0.059511   \n",
       "3              -0.067330              -0.063655              -0.060596   \n",
       "4              -0.064517              -0.061941              -0.059553   \n",
       "\n",
       "   worst perimeterpow_21  worst perimeterpow_22  worst perimeterpow_23  \\\n",
       "0              -0.021527              -0.028975              -0.034237   \n",
       "1              -0.056487              -0.054894              -0.053425   \n",
       "2              -0.057372              -0.055472              -0.053801   \n",
       "3              -0.058033              -0.055874              -0.054046   \n",
       "4              -0.057399              -0.055489              -0.053812   \n",
       "\n",
       "   worst areapow_2  worst areapow_3  worst areapow_4  worst areapow_5  \\\n",
       "0         1.757224         1.213453         0.689612         0.335015   \n",
       "1         1.609423         1.070798         0.580768         0.263443   \n",
       "2         1.075141         0.594656         0.244852         0.058910   \n",
       "3        -0.458432        -0.324060        -0.218619        -0.152411   \n",
       "4         0.815420         0.387458         0.114120        -0.012212   \n",
       "\n",
       "   worst areapow_6  worst areapow_7  worst areapow_8  worst areapow_9  \\\n",
       "0         0.134830         0.032932        -0.015311        -0.036591   \n",
       "1         0.091857         0.008558        -0.028633        -0.043692   \n",
       "2        -0.022014        -0.051414        -0.059111        -0.058816   \n",
       "3        -0.113148        -0.089530        -0.074782        -0.065198   \n",
       "4        -0.057360        -0.068015        -0.066628        -0.062138   \n",
       "\n",
       "   worst areapow_10  worst areapow_11  worst areapow_12  worst areapow_13  \\\n",
       "0         -0.045060         -0.047748         -0.047996         -0.047336   \n",
       "1         -0.048778         -0.049669         -0.048979         -0.047835   \n",
       "2         -0.056161         -0.053230         -0.050682         -0.048643   \n",
       "3         -0.058745         -0.054273         -0.051102         -0.048812   \n",
       "4         -0.057603         -0.053848         -0.050944         -0.048754   \n",
       "\n",
       "   worst areapow_14  worst areapow_15  worst areapow_16  worst areapow_17  \\\n",
       "0         -0.046434         -0.045561         -0.044808         -0.044192   \n",
       "1         -0.046686         -0.045687         -0.044871         -0.044223   \n",
       "2         -0.047068         -0.045867         -0.044955         -0.044262   \n",
       "3         -0.047136         -0.045894         -0.044966         -0.044267   \n",
       "4         -0.047114         -0.045886         -0.044963         -0.044266   \n",
       "\n",
       "   worst areapow_18  worst areapow_19  worst areapow_20  worst areapow_21  \\\n",
       "0         -0.043701         -0.043317         -0.043017         -0.042784   \n",
       "1         -0.043717         -0.043324         -0.043021         -0.042786   \n",
       "2         -0.043735         -0.043333         -0.043025         -0.042788   \n",
       "3         -0.043737         -0.043334         -0.043025         -0.042788   \n",
       "4         -0.043737         -0.043333         -0.043025         -0.042788   \n",
       "\n",
       "   worst areapow_22  worst areapow_23  worst smoothnesspow_2  \\\n",
       "0         -0.042603         -0.042463               1.311147   \n",
       "1         -0.042604         -0.042463              -0.430664   \n",
       "2         -0.042605         -0.042463               0.445589   \n",
       "3         -0.042605         -0.042463               4.119513   \n",
       "4         -0.042605         -0.042463               0.132734   \n",
       "\n",
       "   worst smoothnesspow_3  worst smoothnesspow_4  worst smoothnesspow_5  \\\n",
       "0               1.267484               1.178654               1.052959   \n",
       "1              -0.462378              -0.470044              -0.456249   \n",
       "2               0.350423               0.250649               0.155176   \n",
       "3               4.893276               5.668602               6.390467   \n",
       "4               0.046043              -0.031931              -0.095401   \n",
       "\n",
       "   worst smoothnesspow_6  worst smoothnesspow_7  worst smoothnesspow_8  \\\n",
       "0               0.903565               0.745462               0.592110   \n",
       "1              -0.426126              -0.385987              -0.341856   \n",
       "2               0.071321               0.003531              -0.046938   \n",
       "3               7.007684               7.484511               7.806672   \n",
       "4              -0.141399              -0.169978              -0.183555   \n",
       "\n",
       "   worst smoothnesspow_9  worst smoothnesspow_10  worst smoothnesspow_11  \\\n",
       "0               0.453158                0.333811                0.235502   \n",
       "1              -0.298417               -0.258645               -0.223979   \n",
       "2              -0.081399               -0.102654               -0.113952   \n",
       "3               7.979895                8.023386                7.962280   \n",
       "4              -0.185775               -0.180425               -0.170726   \n",
       "\n",
       "   worst smoothnesspow_12  worst smoothnesspow_13  worst smoothnesspow_14  \\\n",
       "0                0.157129                0.096238                0.049903   \n",
       "1               -0.194751               -0.170640               -0.151015   \n",
       "2               -0.118302               -0.118148               -0.115308   \n",
       "3                7.821877                7.624445                7.388057   \n",
       "4               -0.159068               -0.147032               -0.135553   \n",
       "\n",
       "   worst smoothnesspow_15  worst smoothnesspow_16  worst smoothnesspow_17  \\\n",
       "0                0.015254               -0.010259               -0.028770   \n",
       "1               -0.135153               -0.122367               -0.112051   \n",
       "2               -0.111045               -0.106185               -0.101242   \n",
       "3                7.126642                6.850579                6.567429   \n",
       "4               -0.125110               -0.115887               -0.107893   \n",
       "\n",
       "   worst smoothnesspow_18  worst smoothnesspow_19  worst smoothnesspow_20  \\\n",
       "0               -0.041996               -0.051284               -0.057671   \n",
       "1               -0.103702               -0.096911               -0.091352   \n",
       "2               -0.096509               -0.092140               -0.088196   \n",
       "3                6.282608                5.999950                5.722128   \n",
       "4               -0.101046               -0.095220               -0.090280   \n",
       "\n",
       "   worst smoothnesspow_21  worst smoothnesspow_22  worst smoothnesspow_23  \\\n",
       "0               -0.061940               -0.064680               -0.066327   \n",
       "1               -0.086771               -0.082967               -0.079782   \n",
       "2               -0.084687               -0.081594               -0.078879   \n",
       "3                5.450984                5.187753                4.933236   \n",
       "4               -0.086093               -0.082539               -0.079513   \n",
       "\n",
       "   worst compactnesspow_2  worst compactnesspow_3  worst compactnesspow_4  \\\n",
       "0                2.863740                2.553610                1.990057   \n",
       "1               -0.441652               -0.347011               -0.253305   \n",
       "2                0.735554                0.357051                0.106215   \n",
       "3                5.353306                6.126952                6.210295   \n",
       "4               -0.383307               -0.325709               -0.246937   \n",
       "\n",
       "   worst compactnesspow_5  worst compactnesspow_6  worst compactnesspow_7  \\\n",
       "0                1.427492                0.969235                0.630439   \n",
       "1               -0.188844               -0.148147               -0.122127   \n",
       "2               -0.020801               -0.073458               -0.089926   \n",
       "3                5.855624                5.285596                4.639764   \n",
       "4               -0.187160               -0.147735               -0.122032   \n",
       "\n",
       "   worst compactnesspow_8  worst compactnesspow_9  worst compactnesspow_10  \\\n",
       "0                0.393303                0.233041                 0.127406   \n",
       "1               -0.104701               -0.092411                -0.083340   \n",
       "2               -0.091088               -0.086733                -0.080994   \n",
       "3                3.996275                3.395664                 2.856417   \n",
       "4               -0.104680               -0.092407                -0.083339   \n",
       "\n",
       "   worst compactnesspow_11  worst compactnesspow_12  worst compactnesspow_13  \\\n",
       "0                 0.059144                 0.015796                -0.011252   \n",
       "1                -0.076395                -0.070924                -0.066520   \n",
       "2                -0.075433                -0.070531                -0.066361   \n",
       "3                 2.384358                 1.978263                 1.633249   \n",
       "4                -0.076395                -0.070924                -0.066520   \n",
       "\n",
       "   worst compactnesspow_14  worst compactnesspow_15  worst compactnesspow_16  \\\n",
       "0                -0.027798                -0.037665                -0.043338   \n",
       "1                -0.062916                -0.059928                -0.057427   \n",
       "2                -0.062851                -0.059902                -0.057416   \n",
       "3                 1.342798                 1.099938                 0.897906   \n",
       "4                -0.062916                -0.059928                -0.057427   \n",
       "\n",
       "   worst compactnesspow_17  worst compactnesspow_18  worst compactnesspow_19  \\\n",
       "0                -0.046412                -0.047902                -0.048448   \n",
       "1                -0.055316                -0.053524                -0.051994   \n",
       "2                -0.055312                -0.053522                -0.051993   \n",
       "3                 0.730489                 0.592166                 0.478140   \n",
       "4                -0.055316                -0.053524                -0.051994   \n",
       "\n",
       "   worst compactnesspow_20  worst compactnesspow_21  worst compactnesspow_22  \\\n",
       "0                -0.048448                -0.048147                -0.047696   \n",
       "1                -0.050683                -0.049556                -0.048583   \n",
       "2                -0.050683                -0.049556                -0.048583   \n",
       "3                 0.384308                 0.307197                 0.243897   \n",
       "4                -0.050683                -0.049556                -0.048583   \n",
       "\n",
       "   worst compactnesspow_23  worst concavitypow_2  worst concavitypow_3  \\\n",
       "0                -0.047184              2.212144              1.811126   \n",
       "1                -0.047743             -0.336217             -0.319082   \n",
       "2                -0.047743              0.484894              0.155672   \n",
       "3                 0.191976              2.013415              1.585682   \n",
       "4                -0.047743              0.241326             -0.012490   \n",
       "\n",
       "   worst concavitypow_4  worst concavitypow_5  worst concavitypow_6  \\\n",
       "0              1.260063              0.788724              0.457020   \n",
       "1             -0.245823             -0.183034             -0.141025   \n",
       "2             -0.021550             -0.088479             -0.103528   \n",
       "3              1.056719              0.628947              0.341391   \n",
       "4             -0.113958             -0.132762             -0.123093   \n",
       "\n",
       "   worst concavitypow_7  worst concavitypow_8  worst concavitypow_9  \\\n",
       "0              0.244441              0.114780              0.038065   \n",
       "1             -0.114510             -0.097640             -0.086547   \n",
       "2             -0.100124             -0.092223             -0.084531   \n",
       "3              0.164933              0.061936              0.003781   \n",
       "4             -0.108347             -0.095567             -0.085859   \n",
       "\n",
       "   worst concavitypow_10  worst concavitypow_11  worst concavitypow_12  \\\n",
       "0              -0.006273              -0.031308              -0.045029   \n",
       "1              -0.078946              -0.073508              -0.069454   \n",
       "2              -0.078200              -0.073234              -0.069353   \n",
       "3              -0.028117              -0.045029              -0.053549   \n",
       "4              -0.078719              -0.073434              -0.069429   \n",
       "\n",
       "   worst concavitypow_13  worst concavitypow_14  worst concavitypow_15  \\\n",
       "0              -0.052213              -0.055672              -0.057043   \n",
       "1              -0.066312              -0.063793              -0.061712   \n",
       "2              -0.066275              -0.063780              -0.061708   \n",
       "3              -0.057453              -0.058870              -0.058981   \n",
       "4              -0.066304              -0.063790              -0.061712   \n",
       "\n",
       "   worst concavitypow_16  worst concavitypow_17  worst concavitypow_18  \\\n",
       "0              -0.057270              -0.056892              -0.056213   \n",
       "1              -0.059951              -0.058429              -0.057093   \n",
       "2              -0.059949              -0.058429              -0.057093   \n",
       "3              -0.058438              -0.057592              -0.056630   \n",
       "4              -0.059951              -0.058429              -0.057093   \n",
       "\n",
       "   worst concavitypow_19  worst concavitypow_20  worst concavitypow_21  \\\n",
       "0              -0.055401              -0.054549              -0.053706   \n",
       "1              -0.055904              -0.054837              -0.053870   \n",
       "2              -0.055904              -0.054837              -0.053870   \n",
       "3              -0.055649              -0.054696              -0.053792   \n",
       "4              -0.055904              -0.054837              -0.053870   \n",
       "\n",
       "   worst concavitypow_22  worst concavitypow_23  worst concave pointspow_2  \\\n",
       "0              -0.052896              -0.052131                   2.973647   \n",
       "1              -0.052990              -0.052184                   0.962322   \n",
       "2              -0.052990              -0.052184                   2.334569   \n",
       "3              -0.052947              -0.052161                   2.741830   \n",
       "4              -0.052990              -0.052184                   0.502732   \n",
       "\n",
       "   worst concave pointspow_3  worst concave pointspow_4  \\\n",
       "0                   3.488012                   3.855071   \n",
       "1                   0.741098                   0.510748   \n",
       "2                   2.514401                   2.545055   \n",
       "3                   3.124981                   3.353247   \n",
       "4                   0.260728                   0.066918   \n",
       "\n",
       "   worst concave pointspow_5  worst concave pointspow_6  \\\n",
       "0                   4.087752                   4.207423   \n",
       "1                   0.310799                   0.154067   \n",
       "2                   2.467157                   2.318299   \n",
       "3                   3.450339                   3.444936   \n",
       "4                  -0.066542                  -0.148489   \n",
       "\n",
       "   worst concave pointspow_7  worst concave pointspow_8  \\\n",
       "0                   4.236912                   4.196573   \n",
       "1                   0.039287                  -0.040461   \n",
       "2                   2.128547                   1.919724   \n",
       "3                   3.364143                   3.230465   \n",
       "4                  -0.193167                  -0.213414   \n",
       "\n",
       "   worst concave pointspow_9  worst concave pointspow_10  \\\n",
       "0                   4.103310                    3.970828   \n",
       "1                  -0.093248                   -0.126343   \n",
       "2                   1.706768                    1.499452   \n",
       "3                   3.061538                    2.870852   \n",
       "4                  -0.218774                   -0.215670   \n",
       "\n",
       "   worst concave pointspow_11  worst concave pointspow_12  \\\n",
       "0                    3.810177                    3.630261   \n",
       "1                   -0.145595                   -0.155422   \n",
       "2                    1.303848                    1.123423   \n",
       "3                    2.668611                    2.462451   \n",
       "4                   -0.208156                   -0.198668   \n",
       "\n",
       "   worst concave pointspow_13  worst concave pointspow_14  \\\n",
       "0                    3.438237                    3.239823   \n",
       "1                   -0.159031                   -0.158674   \n",
       "2                    0.959837                    0.813517   \n",
       "3                    2.258007                    2.059340   \n",
       "4                   -0.188601                   -0.178710   \n",
       "\n",
       "   worst concave pointspow_15  worst concave pointspow_16  \\\n",
       "0                    3.039532                    2.840869   \n",
       "1                   -0.155901                   -0.151748   \n",
       "2                    0.684070                    0.570587   \n",
       "3                    1.869278                    1.689675   \n",
       "4                   -0.169372                   -0.160746   \n",
       "\n",
       "   worst concave pointspow_17  worst concave pointspow_18  \\\n",
       "0                    2.646498                    2.458384   \n",
       "1                   -0.146897                   -0.141783   \n",
       "2                    0.471854                    0.386508   \n",
       "3                    1.521638                    1.365697   \n",
       "4                   -0.152874                   -0.145735   \n",
       "\n",
       "   worst concave pointspow_19  worst concave pointspow_20  \\\n",
       "0                    2.277920                    2.106040   \n",
       "1                   -0.136678                   -0.131742   \n",
       "2                    0.313144                    0.250383   \n",
       "3                    1.221953                    1.090196   \n",
       "4                   -0.139280                   -0.133449   \n",
       "\n",
       "   worst concave pointspow_21  worst concave pointspow_22  \\\n",
       "0                    1.943305                    1.789992   \n",
       "1                   -0.127063                   -0.122684   \n",
       "2                    0.196920                    0.151549   \n",
       "3                    0.969995                    0.860774   \n",
       "4                   -0.128179                   -0.123412   \n",
       "\n",
       "   worst concave pointspow_23  worst symmetrypow_2  worst symmetrypow_3  \\\n",
       "0                    1.646154             2.939826             2.909341   \n",
       "1                   -0.118620            -0.293198            -0.305249   \n",
       "2                    0.113176             1.011557             0.801203   \n",
       "3                    0.761865             8.379523            11.096233   \n",
       "4                   -0.119094            -0.762231            -0.623577   \n",
       "\n",
       "   worst symmetrypow_4  worst symmetrypow_5  worst symmetrypow_6  \\\n",
       "0             2.653515             2.242743             1.779484   \n",
       "1            -0.284855            -0.245668            -0.202073   \n",
       "2             0.566038             0.353222             0.190087   \n",
       "3            13.878178            16.387452            18.426565   \n",
       "4            -0.479973            -0.354692            -0.258533   \n",
       "\n",
       "   worst symmetrypow_7  worst symmetrypow_8  worst symmetrypow_9  \\\n",
       "0             1.345154             0.980702             0.695227   \n",
       "1            -0.163165            -0.132238            -0.109112   \n",
       "2             0.080080             0.012915            -0.024798   \n",
       "3            19.968341            21.085868            21.879452   \n",
       "4            -0.190760            -0.145170            -0.114992   \n",
       "\n",
       "   worst symmetrypow_10  worst symmetrypow_11  worst symmetrypow_12  \\\n",
       "0              0.481115              0.324951              0.213136   \n",
       "1             -0.092297             -0.080164             -0.071368   \n",
       "2             -0.044230             -0.053116             -0.056287   \n",
       "3             22.439050             22.833782             23.113291   \n",
       "4             -0.094914             -0.081310             -0.071864   \n",
       "\n",
       "   worst symmetrypow_13  worst symmetrypow_14  worst symmetrypow_15  \\\n",
       "0              0.134083              0.078699              0.040167   \n",
       "1             -0.064917             -0.060114             -0.056481   \n",
       "2             -0.056562             -0.055507             -0.053950   \n",
       "3             23.312237             23.454612             23.557026   \n",
       "4             -0.065129             -0.060204             -0.056520   \n",
       "\n",
       "   worst symmetrypow_16  worst symmetrypow_17  worst symmetrypow_18  \\\n",
       "0              0.013512             -0.004831             -0.017391   \n",
       "1             -0.053692             -0.051519             -0.049805   \n",
       "2             -0.052304             -0.050759             -0.049390   \n",
       "3             23.631041             23.684756             23.723882   \n",
       "4             -0.053708             -0.051525             -0.049808   \n",
       "\n",
       "   worst symmetrypow_19  worst symmetrypow_20  worst symmetrypow_21  \\\n",
       "0             -0.025945             -0.031733             -0.035621   \n",
       "1             -0.048438             -0.047337             -0.046444   \n",
       "2             -0.048211             -0.047214             -0.046376   \n",
       "3             23.752476             23.773435             23.788837   \n",
       "4             -0.048439             -0.047338             -0.046444   \n",
       "\n",
       "   worst symmetrypow_22  worst symmetrypow_23  worst fractal dimensionpow_2  \\\n",
       "0             -0.038208             -0.039908                      1.861001   \n",
       "1             -0.045713             -0.045112                      0.151865   \n",
       "2             -0.045676             -0.045092                      0.081905   \n",
       "3             23.800183             23.808559                      6.205415   \n",
       "4             -0.045713             -0.045112                     -0.406433   \n",
       "\n",
       "   worst fractal dimensionpow_3  worst fractal dimensionpow_4  \\\n",
       "0                      1.621831                      1.253440   \n",
       "1                      0.035986                     -0.045181   \n",
       "2                     -0.018774                     -0.082756   \n",
       "3                      7.306666                      7.846732   \n",
       "4                     -0.375019                     -0.310905   \n",
       "\n",
       "   worst fractal dimensionpow_5  worst fractal dimensionpow_6  \\\n",
       "0                      0.860256                      0.535568   \n",
       "1                     -0.084802                     -0.094018   \n",
       "2                     -0.107567                     -0.106564   \n",
       "3                      7.683086                      7.022125   \n",
       "4                     -0.236755                     -0.173203   \n",
       "\n",
       "   worst fractal dimensionpow_7  worst fractal dimensionpow_8  \\\n",
       "0                      0.307886                      0.162516   \n",
       "1                     -0.088561                     -0.078855   \n",
       "2                     -0.095058                     -0.082089   \n",
       "3                      6.155694                      5.274238   \n",
       "4                     -0.127398                     -0.097198   \n",
       "\n",
       "   worst fractal dimensionpow_9  worst fractal dimensionpow_10  \\\n",
       "0                      0.074439                       0.022708   \n",
       "1                     -0.069571                      -0.062133   \n",
       "2                     -0.071140                      -0.062881   \n",
       "3                      4.463781                       3.752088   \n",
       "4                     -0.078029                      -0.065971   \n",
       "\n",
       "   worst fractal dimensionpow_11  worst fractal dimensionpow_12  \\\n",
       "0                      -0.007036                      -0.023838   \n",
       "1                      -0.056608                      -0.052642   \n",
       "2                      -0.056960                      -0.052806   \n",
       "3                       3.141055                       2.622602   \n",
       "4                      -0.058330                      -0.053408   \n",
       "\n",
       "   worst fractal dimensionpow_13  worst fractal dimensionpow_14  \\\n",
       "0                      -0.033157                      -0.038209   \n",
       "1                      -0.049829                      -0.047833   \n",
       "2                      -0.049904                      -0.047868   \n",
       "3                       2.185586                       1.818635   \n",
       "4                      -0.050167                      -0.047982   \n",
       "\n",
       "   worst fractal dimensionpow_15  worst fractal dimensionpow_16  \\\n",
       "0                      -0.040862                      -0.042183   \n",
       "1                      -0.046406                      -0.045373   \n",
       "2                      -0.046422                      -0.045380   \n",
       "3                       1.511249                       1.254150   \n",
       "4                      -0.046471                      -0.045401   \n",
       "\n",
       "   worst fractal dimensionpow_17  worst fractal dimensionpow_18  \\\n",
       "0                      -0.042781                      -0.042994   \n",
       "1                      -0.044613                      -0.044047   \n",
       "2                      -0.044617                      -0.044048   \n",
       "3                       1.039325                       0.859944   \n",
       "4                      -0.044626                      -0.044052   \n",
       "\n",
       "   worst fractal dimensionpow_19  worst fractal dimensionpow_20  \\\n",
       "0                      -0.043014                      -0.042942   \n",
       "1                      -0.043618                      -0.043288   \n",
       "2                      -0.043619                      -0.043288   \n",
       "3                       0.710226                       0.585307   \n",
       "4                      -0.043620                      -0.043289   \n",
       "\n",
       "   worst fractal dimensionpow_21  worst fractal dimensionpow_22  \\\n",
       "0                      -0.042833                      -0.042716   \n",
       "1                      -0.043032                      -0.042830   \n",
       "2                      -0.043032                      -0.042830   \n",
       "3                       0.481100                       0.394186   \n",
       "4                      -0.043032                      -0.042830   \n",
       "\n",
       "   worst fractal dimensionpow_23  \n",
       "0                      -0.042604  \n",
       "1                      -0.042669  \n",
       "2                      -0.042669  \n",
       "3                       0.321702  \n",
       "4                      -0.042669  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 690)\n"
     ]
    }
   ],
   "source": [
    "X,y = load_breast_cancer(as_frame=True,return_X_y=True)\n",
    "display(X)\n",
    "display(y.value_counts())\n",
    "# df = pd.DataFrame(data = X[\"data\"])\n",
    "# df = pd.Dataframe(df)\n",
    "# display(df)\n",
    "# log = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "log=LogisticRegression()\n",
    "for cols in X.columns:\n",
    "    powers= [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "    for p in powers:\n",
    "        name = cols + \"pow_\" + str(p)\n",
    "        X[name] = X[cols].map(lambda x : x ** p)\n",
    "        #display(X.head())\n",
    "\n",
    "Xx= scaler.fit_transform(X)\n",
    "X = pd.DataFrame(Xx,columns=X.columns)\n",
    "\n",
    "display(X.head())\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "['mean smoothness', 'mean symmetry', 'smoothness error', 'symmetry error', 'worst smoothness', 'worst symmetry', 'mean smoothnesspow_2', 'mean smoothnesspow_3', 'mean smoothnesspow_4', 'mean smoothnesspow_5', 'mean smoothnesspow_6', 'mean smoothnesspow_7', 'mean smoothnesspow_8', 'mean smoothnesspow_9', 'mean smoothnesspow_10', 'mean smoothnesspow_11', 'mean smoothnesspow_12', 'mean smoothnesspow_13', 'mean smoothnesspow_14', 'mean smoothnesspow_15', 'mean smoothnesspow_16', 'mean smoothnesspow_17', 'mean smoothnesspow_18', 'mean smoothnesspow_19', 'mean smoothnesspow_20', 'mean smoothnesspow_21', 'mean smoothnesspow_22', 'mean smoothnesspow_23', 'mean symmetrypow_2', 'mean symmetrypow_3', 'mean symmetrypow_4', 'mean symmetrypow_5', 'mean symmetrypow_6', 'mean symmetrypow_7', 'mean symmetrypow_8', 'mean symmetrypow_9', 'mean symmetrypow_10', 'mean symmetrypow_11', 'mean symmetrypow_12', 'mean symmetrypow_13', 'mean symmetrypow_14', 'mean symmetrypow_15', 'mean symmetrypow_16', 'mean symmetrypow_17', 'mean symmetrypow_18', 'mean symmetrypow_19', 'mean symmetrypow_20', 'mean symmetrypow_21', 'mean symmetrypow_22', 'mean symmetrypow_23', 'smoothness errorpow_2', 'smoothness errorpow_3', 'smoothness errorpow_4', 'smoothness errorpow_5', 'smoothness errorpow_6', 'smoothness errorpow_7', 'smoothness errorpow_8', 'smoothness errorpow_9', 'smoothness errorpow_10', 'smoothness errorpow_11', 'smoothness errorpow_12', 'smoothness errorpow_13', 'smoothness errorpow_14', 'smoothness errorpow_15', 'smoothness errorpow_16', 'smoothness errorpow_17', 'smoothness errorpow_18', 'smoothness errorpow_19', 'smoothness errorpow_20', 'smoothness errorpow_21', 'smoothness errorpow_22', 'smoothness errorpow_23', 'symmetry errorpow_2', 'symmetry errorpow_3', 'symmetry errorpow_4', 'symmetry errorpow_5', 'symmetry errorpow_6', 'symmetry errorpow_7', 'symmetry errorpow_8', 'symmetry errorpow_9', 'symmetry errorpow_10', 'symmetry errorpow_11', 'symmetry errorpow_12', 'symmetry errorpow_13', 'symmetry errorpow_14', 'symmetry errorpow_15', 'symmetry errorpow_16', 'symmetry errorpow_17', 'symmetry errorpow_18', 'symmetry errorpow_19', 'symmetry errorpow_20', 'symmetry errorpow_21', 'symmetry errorpow_22', 'symmetry errorpow_23', 'worst smoothnesspow_2', 'worst smoothnesspow_3', 'worst smoothnesspow_4', 'worst smoothnesspow_5', 'worst smoothnesspow_6', 'worst smoothnesspow_7', 'worst smoothnesspow_8', 'worst smoothnesspow_9', 'worst smoothnesspow_10', 'worst smoothnesspow_11', 'worst smoothnesspow_12', 'worst smoothnesspow_13', 'worst smoothnesspow_14', 'worst smoothnesspow_15', 'worst smoothnesspow_16', 'worst smoothnesspow_17', 'worst smoothnesspow_18', 'worst smoothnesspow_19', 'worst smoothnesspow_20', 'worst smoothnesspow_21', 'worst smoothnesspow_22', 'worst smoothnesspow_23', 'worst symmetrypow_2', 'worst symmetrypow_3', 'worst symmetrypow_4', 'worst symmetrypow_5', 'worst symmetrypow_6', 'worst symmetrypow_7', 'worst symmetrypow_8', 'worst symmetrypow_9', 'worst symmetrypow_10', 'worst symmetrypow_11', 'worst symmetrypow_12', 'worst symmetrypow_13', 'worst symmetrypow_14', 'worst symmetrypow_15', 'worst symmetrypow_16', 'worst symmetrypow_17', 'worst symmetrypow_18', 'worst symmetrypow_19', 'worst symmetrypow_20', 'worst symmetrypow_21', 'worst symmetrypow_22', 'worst symmetrypow_23']\n",
      "0.8035714285714286\n",
      "0.7134502923976608\n",
      "0.7142857142857143\n",
      "0.746588693957115\n"
     ]
    }
   ],
   "source": [
    "columns = [cols for cols in X.columns if 'smoothness' in cols or 'symmetry' in cols]\n",
    "print(len(columns))\n",
    "print(columns)\n",
    "X = X[columns]\n",
    "\n",
    "Xt,Xv,yt,yv = train_test_split(X,y,test_size=0.9,random_state=0)\n",
    "log.fit(Xt,yt)\n",
    "print(log.score(Xt,yt))\n",
    "print(log.score(Xv,yv))\n",
    "\n",
    "rig = LogisticRegression(penalty='l2',C=0.01,random_state=0,solver='lbfgs')\n",
    "rig.fit(Xt,yt)\n",
    "print(rig.score(Xt,yt))\n",
    "print(rig.score(Xv,yv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
